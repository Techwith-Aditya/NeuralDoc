{'query': 'Neural Networks', 'user_based_search': {'pdf1': [{'text': '[1] J. Nicholson and A. Healey, "The present state of autonomous underwater vehicle (AUV) applications and technologies," Marine Technology Society Journal, vol. 42, no. 1, pp. 44‚Äì51, 2008.\n\n[2] G. Griffiths, Technology and applications of autonomous underwater vehicles, vol. 2. CRC Press, 2002.\n\n[3] P. A. Miller, J. A. Farrell, Y. Zhao, and V. Djapic, "Autonomous underwater vehicle navigation," IEEE Journal of Oceanic Engineering, vol. 35, no. 3, pp. 663‚Äì678, 2010.\n\n[4] D. Rudolph and T. A. Wilson, "Doppler Velocity Log theory and preliminary considerations for design and construction," in 2012 Proceedings of IEEE Southeastcon, pp. 1‚Äì7, IEEE, 2012.\n\n[5] N. Cohen and I. Klein, "Inertial navigation meets deep learning: A survey of current trends and future directions," Results in Engineering, p. 103565, 2024.\n\n[6] F. Zhang, S. Zhao, L. Li, and C. Cao, "Underwater DVL Optimization Network (UDON): A Learning-Based DVL Velocity Optimizing Method for Underwater Navigation," Drones, vol. 9, no. 1, p. 56, 2025.\n\n[7] Liu, Peijia and Wang, Bo and Li, Guanghua and Hou, Dongdong and Zhu, Zhengyu and Wang, Zhongyong, "Sins/dvl integrated navigation method with current compensation using rbf neural network," IEEE Sensors Journal, vol. 22, no. 14, pp. 14366‚Äì14377, 2022.\n\n[8] E. Topini, F. Fanelli, A. Topini, M. Pebody, A. Ridolfi, A. B. Phillips, and B. Allotta, "An experimental comparison of Deep Learning strategies for AUV navigation in DVL-denied environments," Ocean Engineering, vol. 274, p. 114034, 2023.\n\n[9] R. Makam, M. Pramuk, S. Thomas, and S. Sundaram, "Spectrally Normalized Memory Neuron Network Based Navigation for Autonomous Underwater Vehicles in DVL-Denied Environment," in OCEANS 2024-Singapore, pp. 1‚Äì6, IEEE, 2024.\n\n[10] Z. Yampolsky and I. Klein, "DCNet: A data-driven framework for DVL calibration," Applied Ocean Research, vol. 158, p. 104525, 2025.\n\n[11] M. Yona and I. Klein, "MissBeamNet: Learning missing Doppler velocity log beam measurements," Neural Computing and Applications, vol. 36, no. 9, pp. 4947‚Äì4958, 2024.\n\n[12] N. Cohen, Z. Yampolsky, and I. Klein, "Set-transformer BeamsNet for AUV velocity forecasting in complete DVL outage scenarios," in 2023 IEEE Underwater Technology (UT), pp. 1‚Äì6, IEEE, 2023.\n\n[13] N. Cohen and I. Klein, "BeamsNet: A data-driven approach enhancing Doppler velocity log measurements for autonomous underwater vehicle navigation," Engineering Applications of Artificial Intelligence, vol. 114, p. 105216, 2022.\n\n[14] N. Cohen and I. Klein, "Adaptive Kalman-Informed Transformer," Engineering Applications of Artificial Intelligence, vol. 146, p. 110221, 2025.\n\n[15] A. Levy and I. Klein, "Adaptive Neural Unscented Kalman Filter," arXiv preprint arXiv:2503.05490, 2025.\n\n[16] Y. Stolero and I. Klein, "AUV Acceleration Prediction Using DVL and Deep Learning ," arXiv preprint arXiv: 2503.16573, 2025.\n\n[17] D. Simon, Optimal state estimation: Kalman, H infinity, and nonlinear approaches. John Wiley & Sons, 2006.\n\n[18] Y. Bar-Shalom, X. R. Li, and T. Kirubarajan, Estimation with applications to tracking and navigation: theory algorithms and software. John Wiley & Sons, 2004.\n\n[19] P. Groves, Principles of GNSS, Inertial, and Multisensor Integrated Navigation Systems, Second Edition. GNSS/GPS, Artech House, 2013.\n\n[20] J. Farrell, Aided navigation: GPS with high rate sensors. McGraw-Hill, Inc., 2008.', 'sub_heading': 'REFERENCES', 'collection_name': 'pdf1', 'similarity': 0.8010231256484985}], 'pdf3': [{'text': 'An LSTM network (Hochreiter and Schmidhuber, 1997) is a type of recurrent neural network, which incorporates both short and long-term effects based on data-adaptive learning for estimation of a system, function, or process. The architecture of an LSTM cell including the inputs, outputs, and short and long-term memory components is in Figure 3.\n\n![Figure 3: Basic architecture of an LSTM cell]\n\nInside the cell, the circled functions labeled (f‚ÇÅ, f‚ÇÇ, f‚ÇÉ, f‚ÇÑ) are representative of an LSTM unit, and circled operators are component-based operations. Sigma (œÉ) is the sigmoid activation function, and tanh is the hyperbolic tangent activation. The size of the weight and bias matrices in the LSTM unit defines the size or dimensionality of the hidden and cell states.\n\nWeights are represented by (W,U), biases (b), and Hadamard product (‚óã). Based on the training of the neural network, each of the weights and biases are "learned" through an optimization process. The hidden state (h‚Çú) and cell state (c‚Çú) act as "memory", and change over time.\n\nThe following equations show the compact form of the operations inside of the cell.\n\n$$f_1 = œÉ(W_{f1} \\cdot x^{(t)} + U_{f1} \\cdot h^{(t-1)} + b_{f1})$$\n\n$$f_2 = œÉ(W_{f2} \\cdot x^{(t)} + U_{f2} \\cdot h^{(t-1)} + b_{f2})$$\n\n$$f_3 = tanh(W_{f3} \\cdot x^{(t)} + U_{f3} \\cdot h^{(t-1)} + b_{f3})$$\n\n$$f_4 = œÉ(W_{f4} \\cdot x^{(t)} + U_{f4} \\cdot h^{(t-1)} + b_{f4})$$\n\n$$c_t = f_1 \\circ c^{(t-1)} + f_2 \\circ f_3$$\n\n$$h_t = f_4 \\circ tanh(c^{(t)})$$\n\nFunction (ùëì1) is the "forget gate", which controls the parts of the long-term state that are deleted. Function (ùëì3) represents the input gate, which controls the information from (ùëì2) that is added to the long-term state. Function (ùëì4) controls the output gate, which determines the output of the long-term state.\n\nBy constructing layers of cells, the LSTM network is capable of forecasting a desired response to a provided input. An LSTM network effectively maps the input time-series to the desired output time-series or target(s). Adding more units to each cell or increasing the number of layers can enable the network to model more complex interactions or behaviors, but at greater computational cost.\n\nThe training process as well as the accuracy and deficiency of an LSTM network depend on the selection of hyperparameters. The accuracy and time-efficiency of an LSTM network depend on the hyperparameters. The hyperparameters are comprised of the number of inputs, number of network layers, training data sequence length, time resolution of the input time-series, hidden state size, bi-directionality, and dropout method. The length of the training data sequences is equivalent to the number of samples of the input time-series.\n\nTime resolution is based on uniform resampling of the input and target time-series. Through resampling, each time-series is reconfigured into a matrix of size [N/œÑ, œÑ]; where, N is the original time-series length, and œÑ is the time resolution factor. If N is not divisible by œÑ, then the time-series is reduced in length to the closest multiple of œÑ.\n\nThe network includes layers of LSTM cells that contain the hidden states. The hidden state size is the number of parameters (‚Ñéùë°), which affects the number of weights in an LSTM unit. Size of the weights vectors are W ‚àà R^hxd and U ‚àà R^hxd for hidden state size (h), and number of input time-series channels (d).\n\nThe basic architecture of the LSTM framework in this study is in Figure 4.\n\n```\n1st LSTM   2nd LSTM   3rd LSTM   Output\nlayer      layer      layer      layer\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ f1  ‚îÇ    ‚îÇ f1  ‚îÇ    ‚îÇ f1  ‚îÇ    ‚îÇO3 ‚îÇ    ‚îÇ Œ∑3,1^LAMP Œ∑1,1^LAMP Œ∑5,1^LAMP ‚îÇ\n‚îÇ     ‚îÇ    ‚îÇ     ‚îÇ    ‚îÇ     ‚îÇ    ‚îÇ   ‚îÇ    ‚îÇ                 ‚îÇ\n‚îÇ f2  ‚îÇ -> ‚îÇ f2  ‚îÇ -> ‚îÇ f2  ‚îÇ -> ‚îÇO4 ‚îÇ -> ‚îÇ Œ∑3,2^LAMP Œ∑1,2^LAMP Œ∑5,2^LAMP ‚îÇ\n‚îÇ     ‚îÇ    ‚îÇ     ‚îÇ    ‚îÇ     ‚îÇ    ‚îÇ   ‚îÇ    ‚îÇ     ...         ‚îÇ\n‚îÇ f3  ‚îÇ    ‚îÇ f3  ‚îÇ    ‚îÇ f3  ‚îÇ    ‚îÇO5 ‚îÇ    ‚îÇ Œ∑3,4^LAMP Œ∑1,4^LAMP Œ∑5,4^LAMP ‚îÇ\n‚îÇ     ‚îÇ    ‚îÇ     ‚îÇ    ‚îÇ     ‚îÇ    ‚îÇ   ‚îÇ    ‚îÇ                 ‚îÇ\n‚îÇ f4  ‚îÇ    ‚îÇ f4  ‚îÇ    ‚îÇ f4  ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\nFigure 4: LSTM Architecture\n\nAn additional fully connected linear output layer has been inserted after the three LSTM layers to parse the output into individual time-series channels for the 3-DOF motions for roll, pitch and heave. Also the labels "SC" and "LAMP" indicate the source of the time-series values. Definitions of the parameters are in Table 1.\n\n| Parameter Definition | Variable |\n|----------------------|----------|\n| Input wave at time-step j | Œ∑_o,j |\n| Total number time steps | T |\n| i^th degree-of-freedom at time-step j | Œ∑_i,j |\n| k^th gate for LSTM layer | f_k |\n| Number of LSTM units per layer | n |\n| Output layer cell for DOF m | O_m |\n\nTable 1: Parameters for LSTM Architecture\n\nThe LSTM framework is comprised of two-stages with SimpleCode as the first stage and LSTM network as the second. In this architecture, four time-series channels are applied as inputs to the LSTM network.\n\nThe input channels encompass the 3-DOF motion responses from SimpleCode, and corresponding input wave time-series data. The output response time-series from the two-stage LSTM-SimpleCode model are then compared to 3-DOF motion time-series target from LAMP. The result of training is a set of weights and biases that can be insert directly into Equations 1-6 or into LSTM configurations in existing machine learning packages such as PyTorch in python.\n\npoints per realization (N), and time resolution factor (œÑ). Each LSTM layer consisted of a single LSTM cell with its own set of gates (f‚ÇÅ, f‚ÇÇ, f‚ÇÉ, f‚ÇÑ), distinct weights, and biases.\n\nThe training values for the hyperparameters are in Table 3.\n\nTable 3: Training Values for Hyperparameters\n\n| Hyperparameter | Value |\n|----------------|-------|\n| Time Resolution Factor | 9 |\n| Hidden State Size | 30 |\n| Number of LSTM Layers | 2 |\n| Learning Rate | 0.01 |', 'sub_heading': '2.1 Long Short-Term Memory', 'collection_name': 'pdf3', 'similarity': 0.8147710561752319}], 'cnn2': [{'text': 'Convolutional Neural Networks (CNNs), introduced by Le Cun et al. [6] are a class of biologically inspired neural networks which solve equation (1) by passing X through a series of convolutional filters and simple non-linearities. They have shown remarkable results in a wide variety of machine learning problems [8]. Figure 1 shows a typical CNN architecture.\n\nA convolutional neural network has a hierarchical architecture. Starting from the input signal x, each subsequent layer xj is computed as\n\n$$x_j = \\rho W_j x_{j-1} \\tag{5}$$\n\nHere Wj is a linear operator and œÅ is a non-linearity. Typically, in a CNN, Wj is a convolution, and œÅ is a rectifier max(x, 0) or sigmoid 1/1+exp(‚àíx). It is easier to think of the operator Wj as a stack of convolutional filters. So the layers are filter maps and each layer can be written as a sum of convolutions of the previous layer.\n\n$$x_j(u, k_j) = \\rho \\left( \\sum_k (x_{j-1}(., k) * W_{j,k_j}(., k))(u) \\right) \\tag{6}$$\n\nHere * is the discrete convolution operator:\n\n$$(f * g)(x) = \\sum_{u=-\\infty}^{\\infty} f(u)g(x - u) \\tag{7}$$\n\nThe optimization problem defined by a convolutional neural network is highly non-convex. So typically, the weights Wj are learned by stochastic gradient descent, using the backpropagation algorithm to compute gradients.\n\nFigure 1: Architecture of a Convolutional Neural Network (from LeCun et al. [7])\n\n| Layer | Description | Size/Maps |\n|-------|-------------|-----------|\n| INPUT | Input layer | 32x32 |\n| C1 | Feature maps | 6@28x28 |\n| S2 | Subsampling | 6@14x14 |\n| C3 | Feature maps | 16@10x10 |\n| S4 | Subsampling | 16@5x5 |\n| C5 | Fully connected layer | 120 |\n| F6 | Fully connected layer | 84 |\n| OUTPUT | Output layer | 10 |\n\nConvolutions -> Subsampling -> Convolutions -> Subsampling -> Full connection -> Gaussian connections', 'sub_heading': '1.5 Convolutional Neural Networks', 'collection_name': 'cnn2', 'similarity': 0.8557035326957703}, {'text': 'Mallat [10] introduced a mathematical framework for analyzing the properties of convolutional networks. The theory is based on extensive prior work on wavelet scattering (see for example [2, 1]) and illustrates that to compute invariants, we must separate variations of X at different scales with a wavelet transform. The theory is a first step towards understanding general classes of CNNs, and this paper presents its key concepts.', 'sub_heading': '1.6 A mathematical framework for CNNs', 'collection_name': 'cnn2', 'similarity': 0.8287503719329834}, {'text': 'The scattering transform described in the previous section provides a simple view of a general convolutional neural netowrk. While it provides intuition behind the working of CNNs, the transformation suffers from high variance and loss of information because we only consider single channel convolutions. To analyze the properties of general CNN architectures, we must allow for channel combinations. Mallat [10] extends previously introduced tools to develop a mathematical framework for this analysis. The theory is, however, out of the scope of this paper. At a high level, the extension is achieved by replacing the requirement of contractions and invariants to translations by contractions along adaptive groups of local symmetries. Further, the wavelets are replaced by adapted filter weights similar to deep learning models.', 'sub_heading': '5 General Convolutional Neural Network Architectures', 'collection_name': 'cnn2', 'similarity': 0.8038275241851807}, {'text': 'To avoid the loss of information that comes from integrating over all time, we might use a weight function that localizes f in time. Without going into specifics, let us consider some function g supported on [‚àíT, 0] and define the windowed Fourier transform (WFT) as\n\n$$\\tilde{f}(\\omega, t) \\equiv \\int_{-\\infty}^{\\infty} f(u)g(u - t)e^{-2\\pi i\\omega u} du$$\n\nIt should be intuitively clear that the WFT can capture local variations in a time window of width T. Further, it can be shown that the WFT also provides accurate information about f in a frequency band\n\n3\n\nof some width Œ©. So does the WFT solve our problem? Unfortunately not; and this is a consequence of Theorem 1 which is stated very informally next.', 'sub_heading': '2 The need for wavelets', 'collection_name': 'cnn2', 'similarity': 0.803309440612793}, {'text': 'The Fourier transform of f is defined as\n\n$$\\hat{f}(\\omega) \\equiv \\int_{-\\infty}^{\\infty} f(t)e^{-2\\pi i\\omega t} dt$$\n\nThe Fourier transform is a powerful tool which decomposes f into the frequencies that make it up. However, it should be quite clear from equation (8) that it is useless for the task we are interested in. Since the integral is from ‚àí‚àû to ‚àû, $\\hat{f}$ is an average over all time and does not have any local information.', 'sub_heading': '2 The need for wavelets', 'collection_name': 'cnn2', 'similarity': 0.803309440612793}], 'cnn4': [{'text': 'machine learning, self expanding neural networks, computational efficiency, convolutional neural networks.', 'sub_heading': 'Keywords', 'collection_name': 'cnn4', 'similarity': 0.8004220724105835}], 'cnn5': [{'text': '1. Cheng, Qisen and Qu, Shuhui and Lee, Janghwan. "72-3: Deep Learning Based Visual Defect Detection in Noisy and Imbalanced Data." SID Symposium Digest of Technical Papers, vol. 53, no. 1, pp. 971-974, 2022.\n\n2. Cheng, Qisen and Zhang, Chang and Shen, Xiang. "Estimation of Energy and Time Usage in 3D Printing With Multimodal Neural Network." 2022 4th International Conference on Frontiers Technology of Information and Computer (ICFTIC), pp. 900-903, 2022.\n\n3. Cifar10 Dataset. [online]. Avaiable:https://www.cs.toronto.edu/ kriz/cifar.html.\n\n4. Xing, Jinming. "Enhancing Link Prediction with Fuzzy Graph Attention Networks and Dynamic Negative Sampling." arXiv preprint arXiv:2411.07482 (2024).\n\n5. Veliƒçkoviƒá, Petar, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. "Graph attention networks." arXiv preprint arXiv:1710.10903 (2017).\n\n6. Hamilton, Will, Zhitao Ying, and Jure Leskovec. "Inductive representation learning on large graphs." Advances in neural information processing systems 30 (2017).\n\n7. Xing, Jinming, Can Gao, and Jie Zhou. "Weighted fuzzy rough sets-based tri-training and its application to medical diagnosis." Applied Soft Computing 124 (2022): 109025.\n\n8. Gao, Can, Jie Zhou, Jinming Xing, and Xiaodong Yue. "Parameterized maximum-entropy-based three-way approximate attribute reduction." International Journal of Approximate Reasoning 151 (2022): 85-100.\n\n9. Xing, Jinming, Ruilin Xing, and Yan Sun. "FGATT: A Robust Framework for Wireless Data Imputation Using Fuzzy Graph Attention Networks and Transformer Encoders." arXiv preprint arXiv:2412.01979 (2024).\n\n10. S. R. Livingstone and F. A. Russo, "The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)," PloS one, vol. 13, no. 5, p. e0196391, 2018. Available: https://zenodo.org/record/1188976\n\n11. Xing, Jinming, Dongwen Luo, Qisen Cheng, Chang Xue, and Ruilin Xing. "Multi-view Fuzzy Graph Attention Networks for Enhanced Graph Learning." arXiv preprint arXiv:2412.17271 (2024).\n\n12. G. Heigold, I. L. Moreno, S. Bengio, and N. Shazeer, "End-to-End Text-Dependent Speaker Verification," in Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2016, pp. 5115‚Äì5119.\n\n13. S. Hochreiter and J. Schmidhuber, "Long Short-Term Memory," Neural Computation, vol. 9, no. 8, pp. 1735‚Äì1780, 1997.\n\n14. F. A. Gers, J. Schmidhuber, and F. Cummins, "Learning to Forget: Continual Prediction with LSTM," Neural Computation, vol. 12, no. 10, pp. 2451‚Äì2471, 2000.\n\n15. Xing, Jinming, Ruilin Xing, and Yan Sun. "Comparative Analysis of Pooling Mechanisms in LLMs: A Sentiment Analysis Perspective." arXiv preprint arXiv:2411.14654 (2024).', 'sub_heading': 'REFERENCES', 'collection_name': 'cnn5', 'similarity': 0.8010231256484985}], 'pdf2': [{'text': 'Abulwerdi, F. A., Xu, W., Ageeli, A. A., Yonkunas, M. J., Arun, G., Nam, H., Schneekloth Jr, J. S., Dayie, T. K., Spector, D., Baird, N., et al. Selective small-molecule targeting of a triple helix encoded by the long noncoding rna, malat1. ACS chemical biology, 14(2):223‚Äì235, 2019.\n\nAdamczyk, B., Antczak, M., and Szachniuk, M. Rnasolo: a repository of cleaned pdb-derived rna 3d structures. Bioinformatics, 38(14):3668‚Äì3670, 2022.\n\nAlam, T., Uludag, M., Essack, M., Salhi, A., Ashoor, H., Hanks, J. B., Kapfer, C., Mineta, K., Gojobori, T., and Bajic, V. B. Farna: knowledgebase of inferred functions of non-coding rna transcripts. Nucleic acids research, 45 (5):2838‚Äì2848, 2017.\n\nAnand, R., Joshi, C. K., Morehead, A., Jamasb, A. R., Harris, C., Mathis, S. V., Didi, K., Hooi, B., and Lio, P. Rnaframeflow: Flow matching for de novo 3d rna backbone design. arXiv preprint arXiv:2406.13839, 2024.\n\nAshburner, M., Ball, C. A., Blake, J. A., Botstein, D., Butler, H., Cherry, J. M., Davis, A. P., Dolinski, K., Dwight, S. S., Eppig, J. T., et al. Gene ontology: tool for the unification of biology. Nature genetics, 25(1):25‚Äì29, 2000.\n\nBecquey, L., Angel, E., and Tahi, F. Rnanet: an automatically built dual-source dataset integrating homologous sequences and rna structures. Bioinformatics, 37(9):1218‚Äì1224, 2021.\n\nBoccaletto, P., Stefaniak, F., Ray, A., Cappannini, A., Mukherjee, S., Purta, E., Kurkowska, M., Shirvanizadeh, N., Destefanis, E., Groza, P., et al. Modomics: a database of rna modification pathways. 2021 update. Nucleic acids research, 50(D1):D231‚ÄìD235, 2022.\n\nButtenschoen, M., Morris, G. M., and Deane, C. M. Posebusters: Ai-based docking methods fail to generate physically valid poses or generalise to novel sequences. Chemical Science, 15(9):3130‚Äì3139, 2024.\n\nCarvajal-Patino, J. G., Mallet, V., Becerra, D., Ni√±o Vasquez, L. F., Oliver, C., and Waldisp√ºhl, J. Rnamigos2: accelerated structure-based rna virtual screening with deep graph learning. Nature Communications, 16(1):1‚Äì12, 2025.\n\nCech, T. R. and Steitz, J. A. The noncoding rna revolution‚Äîtrashing old rules to forge new ones. Cell, 157(1): 77‚Äì94, 2014.\n\nCorso, G., St√§rk, H., Jing, B., Barzilay, R., and Jaakkola, T. Diffdock: Diffusion steps, twists, and turns for molecular docking. arXiv preprint arXiv:2210.01776, 2022.\n\nDauparas, J., Anishchenko, I., Bennett, N., Bai, H., Ragotte, R. J., Milles, L. F., Wicky, B. I., Courbet, A., de Haas, R. J., Bethel, N., et al. Robust deep learning‚Äìbased protein sequence design using proteinmpnn. Science, 378 (6615):49‚Äì56, 2022.\n\nDisney, M. D. Targeting rna with small molecules to capture opportunities at the intersection of chemistry, biology, and medicine. Journal of the American Chemical Society, 141 (17):6776‚Äì6790, 2019.\n\nDurairaj, J., Adeshina, Y., Cao, Z., Zhang, X., Oleinikovas, V., Duignan, T., McClure, Z., Robin, X., Kovtun, D., Rossi, E., et al. Plinder: The protein-ligand interactions dataset and evaluation resource. bioRxiv, pp. 2024‚Äì07, 2024.\n\nFalese, J. P., Donlic, A., and Hargrove, A. E. Targeting rna with small molecules: from fundamental principles towards the clinic. Chemical Society Reviews, 50(4): 2224‚Äì2243, 2021.\n\nFu, L., Niu, B., Zhu, Z., Wu, S., and Li, W. Cd-hit: accelerated for clustering the next-generation sequencing data. Bioinformatics, 28(23):3150‚Äì3152, 2012.\n\nGainza, P., Sverrisson, F., Monti, F., Rodol√†, E., Boscaini, D., Bronstein, M., and Correia, B. Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning. Nature Methods, 17(2):184‚Äì192, 2020.\n\nGligorijevic, V., Renfrew, P. D., Kosciolek, T., Leman, J. K., Berenberg, D., Vatanen, T., Chandler, C., Taylor, B. C., Fisk, I. M., Vlamakis, H., et al. Structure-based protein function prediction using graph convolutional networks. Nature communications, 12(1):3168, 2021.\n\nGlisovic, T., Bachorik, J. L., Yong, J., and Dreyfuss, G. Rna-binding proteins and post-transcriptional gene regulation. FEBS letters, 582(14):1977‚Äì1986, 2008.\n\nGriffiths-Jones, S., Bateman, A., Marshall, M., Khanna, A., and Eddy, S. R. Rfam: an rna family database. Nucleic acids research, 31(1):439‚Äì441, 2003.\n\nHaga, C. L. and Phinney, D. G. Strategies for targeting rna with small molecule drugs. Expert Opinion on Drug Discovery, 18(2):135‚Äì147, 2023.\n\nHou, J., Adhikari, B., and Cheng, J. Deepsf: deep convolutional neural network for mapping protein sequences to folds. Bioinformatics, 34(8):1295‚Äì1303, 2018.\n\nBenchmark for RNA 3D Structure Modeling\n\nHuang, H., Lin, Z., He, D., Hong, L., and Li, Y. Ribodiffusion: tertiary structure-based rna inverse folding with generative diffusion models. Bioinformatics, 40 (Supplement 1):i347‚Äìi356, 2024.\n\nJamasb, A. R., Morehead, A., Joshi, C. K., Zhang, Z., Didi, K., Mathis, S., Harris, C., Tang, J., Cheng, J., Lio, P., et al. Evaluating representation learning on the protein structure universe. ArXiv, pp. arXiv‚Äì2406, 2024.\n\nJing, B., Eismann, S., Suriana, P., Townshend, R. J., and Dror, R. Learning from protein structure with geometric vector perceptrons. arXiv preprint arXiv:2009.01411, 2020.\n\nJing, B., Eismann, S., Soni, P. N., and Dror, R. O. Equivariant graph neural networks for 3d macromolecular structure, 2021. URL https://arxiv.org/abs/2106.03843.\n\nJoshi, C. K., Jamasb, A. R., Vi√±as, R., Harris, C., Mathis, S. V., Morehead, A., and Lio, P. grnade: Geometric deep learning for 3d rna inverse design. bioRxiv, pp. 2024‚Äì03, 2024.\n\nJumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., Tunyasuvunakool, K., Bates, R., ≈Ω√≠dek, A., Potapenko, A., et al. Highly accurate protein structure prediction with alphafold. Nature, 596(7873):583‚Äì589, 2021.\n\nKouranov, A., Xie, L., de la Cruz, J., Chen, L., Westbrook, J., Bourne, P. E., and Berman, H. M. The rcsb pdb information portal for structural genomics. Nucleic acids research, 34(suppl 1):D302‚ÄìD305, 2006.\n\nKovtun, D., Akdel, M., Goncearenco, A., Zhou, G., Holt, G., Baugher, D., Lin, D., Adeshina, Y., Castiglione, T., Wang, X., et al. Pinder: The protein interaction dataset and evaluation resource. bioRxiv, pp. 2024‚Äì07, 2024.\n\nKucera, T., Oliver, C., Chen, D., and Borgwardt, K. Proteinshake: Building datasets and benchmarks for deep learning on protein structures. In Advances in Neural Information Processing Systems, volume 36, pp. 58277‚Äì58289, 2023.\n\nLeman, J. K., Weitzner, B. D., Lewis, S. M., Adolf-Bryfogle, J., Alam, N., Alford, R. F., Aprahamian, M., Baker, D., Barlow, K. A., Barth, P., et al. Macromolecular modeling and design in rosetta: recent methods and frameworks. Nature methods, 17(7):665‚Äì680, 2020a.\n\nLeman, J. K., Weitzner, B. D., Lewis, S. M., Adolf-Bryfogle, J., Alam, N., Alford, R. F., Aprahamian, M., Baker, D., Barlow, K. A., Barth, P., et al. Macromolecular modeling and design in rosetta: recent methods and frameworks. Nature methods, 17(7):665‚Äì680, 2020b.\n\nLeontis, N. B. and Zirbel, C. L. Nonredundant 3d structure datasets for rna knowledge extraction and benchmarking. RNA 3D structure analysis and prediction, pp. 281‚Äì298, 2012.\n\nLorenz, R., Bernhart, S. H., H√∂ner zu Siederdissen, C., Tafer, H., Flamm, C., Stadler, P. F., and Hofacker, I. L. Viennarna package 2.0. Algorithms for molecular biology, 6:1‚Äì14, 2011.\n\nMitchell, S., OSullivan, M., and Dunning, I. Pulp: a linear programming toolkit for python. The University of Auckland, Auckland, New Zealand, 65:25, 2011.\n\nNori, D. and Jin, W. Rnaflow: Rna structure and sequence design via inverse folding-based flow matching, 2024. URL https://arxiv.org/abs/2405.18768.\n\nNotin, P., Kollasch, A., Ritter, D., van Niekerk, L., Paul, S., Spinner, H., Rollins, N., Shaw, A., Orenbuch, R., Weitzman, R., Frazer, J., Dias, M., Franceschi, D., Gal, Y., and Marks, D. Proteingym: Large-scale benchmarks for protein fitness prediction and design. In Advances in Neural Information Processing Systems, volume 36, pp. 64331‚Äì64379, 2023.\n\nOliver, C., Mallet, V., Gendron, R. S., Reinharz, V., Hamilton, W. L., Moitessier, N., and Waldisp√ºhl, J. Augmented base pairing networks encode rna-small molecule binding preferences. Nucleic acids research, 48(14):7690‚Äì7699, 2020.\n\nOntiveros-Palacios, N., Cooke, E., Nawrocki, E. P., Triebel, S., Marz, M., Rivas, E., Griffiths-Jones, S., Petrov, A. I., Bateman, A., and Sweeney, B. Rfam 15: Rna families database in 2025. Nucleic Acids Research, 53(D1):D258‚ÄìD267, 2025.\n\nPanei, F. P., Torchet, R., Menager, H., Gkeka, P., and Bonomi, M. Hariboss: a curated database of rna-small molecules structures to aid rational drug design. Bioinformatics, 38(17):4185‚Äì4193, 2022.\n\nRen, Y., Chen, Z., Qiao, L., Jing, H., Cai, Y., Xu, S., Ye, P., Ma, X., Sun, S., Yan, H., et al. Beacon: Benchmark for comprehensive rna tasks and language models. Advances in Neural Information Processing Systems, 37:92891‚Äì92921, 2024.\n\nRoundtree, I. A., Evans, M. E., Pan, T., and He, C. Dynamic rna modifications in gene expression regulation. Cell, 169(7):1187‚Äì1200, 2017.\n\nRuiz-Carmona, S., Alvarez-Garcia, D., Foloppe, N., Garmendia-Doval, A. B., Juhos, S., Schmidtke, P., Barril, X., Hubbard, R. E., and Morley, S. D. rdock: A\n\nBenchmark for RNA 3D Structure Modeling\n\nfast, versatile and open source program for docking ligands to proteins and nucleic acids. PLoS Computational Biology, 10:1‚Äì8, 2014. ISSN 15537358. doi: 10.1371/journal.pcbi.1003571.\n\nSchneuing, A., Harris, C., Du, Y., Didi, K., Jamasb, A., Igashov, I., Du, W., Gomes, C., Blundell, T. L., Lio, P., et al. Structure-based drug design with equivariant diffusion models. Nature Computational Science, 4(12): 899‚Äì909, 2024.\n\nStatello, L., Guo, C.-J., Chen, L.-L., and Huarte, M. Gene regulation by long non-coding rnas and its biological functions. Nature reviews Molecular cell biology, 22(2): 96‚Äì118, 2021.\n\nSu, H., Peng, Z., and Yang, J. Recognition of small molecule‚Äìrna binding sites using rna sequence and structure. Bioinformatics, 37(1):36‚Äì42, 2021.\n\nSzikszai, M., Magnus, M., Sanghi, S., Kadyan, S., Bouatta, N., and Rivas, E. Rna3db: A structurally-dissimilar dataset split for training and benchmarking deep learning models for rna structure prediction. Journal of Molecular Biology, pp. 168552, 2024. ISSN 0022-2836. doi: https://doi.org/10.1016/j.jmb.2024.168552.\n\nTan, C., Zhang, Y., Gao, Z., Hu, B., Li, S., Liu, Z., and Li, S. Z. Rdesign: hierarchical data-efficient representation learning for tertiary structure-based rna design. arXiv preprint arXiv:2301.10774, 2023.\n\nTan, C., Zhang, Y., Gao, Z., Cao, H., Li, S., Ma, S., Blanchette, M., and Li, S. Z. R3design: deep tertiary structure-based rna sequence design and beyond. Briefings in Bioinformatics, 26(1):bbae682, 2025.\n\nTownshend, R., V√∂gele, M., Suriana, P., Derry, A., Powers, A., Laloudakis, Y., Balachandar, S., Jing, B., Anderson, B., Eismann, S., Kondor, R., Altman, R., and Dror, R. Atom3d: Tasks on molecules in three dimensions. In Advances in Neural Information Processing Systems, Datasets and Benchmarks, volume 1, 2021a.\n\nTownshend, R. J., Eismann, S., Watkins, A. M., Rangan, R., Karelina, M., Das, R., and Dror, R. O. Geometric deep learning of rna structure. Science, 373(6558):1047‚Äì1051, 2021b.\n\nvan Kempen, M., Kim, S. S., Tumescheit, C., Mirdita, M., Gilchrist, C. L., S√∂ding, J., and Steinegger, M. Foldseek: fast and accurate protein structure search. Biorxiv, pp. 2022‚Äì02, 2022.\n\nVolkov, M., Turk, J.-A., Drizard, N., Martin, N., Hoffmann, B., Gaston-Math√©, Y., and Rognan, D. On the frustration to predict binding affinities from protein‚Äìligand structures with deep neural networks. Journal of medicinal chemistry, 65(11):7946‚Äì7958, 2022.\n\nWang, J., Quan, L., Jin, Z., Wu, H., Ma, X., Wang, X., Xie, J., Pan, D., Chen, T., Wu, T., et al. Multimodrlbp: A deep learning approach for multi-modal rna-small molecule ligand binding sites prediction. IEEE Journal of Biomedical and Health Informatics, 2024.\n\nWang, K., Jian, Y., Wang, H., Zeng, C., and Zhao, Y. Rbind: computational network method to predict rna binding sites. Bioinformatics, 34(18):3131‚Äì3136, 2018.\n\nWang, K., Zhou, R., Wu, Y., and Li, M. Rlbind: a deep learning method to predict rna‚Äìligand binding sites. Briefings in Bioinformatics, 24(1):bbac486, 2023.\n\nWang, L., Liu, H., Liu, Y., Kurtin, J., and Ji, S. Learning hierarchical protein representations via complete 3d graph networks, 2022. URL https://arxiv.org/abs/2207.12600.\n\nWang, R., Fang, X., Lu, Y., Yang, C.-Y., and Wang, S. The pdbbind database: methodologies and updates. Journal of medicinal chemistry, 48(12):4111‚Äì4119, 2005a.\n\nWang, R., ueliang Fang, Lu, Y., Yang, C.-Y., and Wang, S. The pdbbind database: Methodologies and updates. Journal of Medicinal Chemistry, 22, 11 2005b. ISSN 4111‚Äì4119. doi: 10.1021/jm048957q.\n\nWatson, J. L., Juergens, D., Bennett, N. R., Trippe, B. L., Yim, J., Eisenach, H. E., Ahern, W., Borst, A. J., Ragotte, R. J., Milles, L. F., et al. De novo design of protein structure and function with rfdiffusion. Nature, 620(7976): 1089‚Äì1100, 2023.\n\nWong, F., He, D., Krishnan, A., Hong, L., Wang, A. Z., Wang, J., Hu, Z., Omori, S., Li, A., Rao, J., et al. Deep generative design of rna aptamers using structural predictions. Nature Computational Science, pp. 1‚Äì11, 2024.\n\nXu, J., Wu, K.-j., Jia, Q.-j., and Ding, X.-f. Roles of mirna and lncrna in triple-negative breast cancer. Journal of Zhejiang University-science b, 21(9):673‚Äì689, 2020.\n\nZeng, P. and Cui, Q. Rsite2: an efficient computational method to predict the functional sites of noncoding rnas. Scientific Reports, 6(1):19016, 2016.\n\nZeng, P., Li, J., Ma, W., and Cui, Q. Rsite: a computational method to identify the functional sites of noncoding rnas. Scientific Reports, 5(1):9179, 2015.\n\nZhang, C., Shine, M., Pyle, A. M., and Zhang, Y. Us-align: universal structure alignments of proteins, nucleic acids, and macromolecular complexes. Nature methods, 19(9): 1109‚Äì1115, 2022a.\n\nZhang, Z., Xu, M., Jamasb, A., Chenthamarakshan, V., Lozano, A., Das, P., and Tang, J. Protein representation learning by geometric structure pretraining. arXiv preprint arXiv:2203.06125, 2022b.\n\n\nZheng, J., Xie, J., Hong, X., and Liu, S. Rmalign: an\nrna structural alignment tool based on a novel scoring\nfunction rmscore. BMC genomics, 20:1‚Äì10, 2019.\n\nZhu, Z., Shi, C., Zhang, Z., Liu, S., Xu, M., Yuan, X.,\nZhang, Y., Chen, J., Cai, H., Lu, J., et al. Torchdrug: A\npowerful and flexible machine learning platform for drug\ndiscovery. arXiv preprint arXiv:2202.08320, 2022.', 'sub_heading': 'References', 'collection_name': 'pdf2', 'similarity': 0.8010231256484985}], 'pdf4': [{'text': 'For the neural network, we let $F_\\theta(\\cdot) = O^\\top\\phi\\{A^\\top\\phi(\\cdot)\\}$, where $A \\in \\mathbb{R}^{r\\times h}$, $O \\in \\mathbb{R}^{h\\times q}$, $\\phi(\\cdot)$ is the point-wise ReLU function and we let $h = 32$. We implement neural networks in Pytorch. For neural network estimator of B discussed in Section I.4, we minimize the loss function\n\n$$\\ell(\\theta, B) = \\frac{1}{n} \\sum_{i=1}^n \\|y_i - F_\\theta(B^\\top x_i)\\|_2^2,$$\n\nWe use the batch-training strategy to train the neural networks. We use Adam optimizer with Pytorch default parameters. We choose the batch size to be 0.5% of the sample size and train the neural networks for 200 epochs.', 'sub_heading': 'II.3 Structures and Training Details of Neural Networks', 'collection_name': 'pdf4', 'similarity': 0.8409820199012756}, {'text': "The reduced rank regression addresses the following multiple-response linear regression model:\n\n$$y = C^‚ä§x + Œµ,$$ (S5)\n\nwhere $C \\in \\mathbb{R}^{p\\times q}$ and $\\text{rank}(C) \\leq r$ for some $r \\leq \\min(p,q)$. Let $X$ denote the data matrix $(x_1,\\ldots,x_n)^‚ä§$ and $Y$ denote the response matrix $(y_1,\\ldots,y_n)^‚ä§$, reduced rank regression estimates the coefficient matrix $C$ by solving the constrained optimization problem: $\\hat{C} = \\text{argmin}_{\\text{rank}(C)\\leq r}\\|Y - XC\\|^2_F$.\n\nUnder low-dimensional setting, i.e., rank($C$) is fixed, it is well known that if $r$ is given, $\\hat{C}$ has the closed form (Mukherjee and Zhu, 2011): $\\hat{C} = \\hat{C}_{\\text{ols}}V_rV_r^‚ä§$. $\\hat{C}_{\\text{ols}}$ is the ordinary least squares estimator, i.e., $\\hat{C}_{\\text{ols}} = \\text{argmin}\\|Y = XC\\|^2_F$. $V_r = \\text{SVD}_{l,r}\\{(X\\hat{C}_{\\text{ols}})^‚ä§\\}$, i.e., the matrix consisting of the first $r$ leading right singular vectors of $X\\hat{C}_{\\text{ols}}$.\n\nNotably, in our model (2.2), if we additionally require that $r < q$, and $f_j(v) = a_j^‚ä§v$ for certain $a_j \\in \\mathbb{R}^r, j \\in [q]$, it reduces to model (S5) with $C = BA$, where $A = (a_1,\\ldots,a_q)$. Therefore, model (S5) is a special case of our model (2.2), and $\\hat{C}$ can be used for estimating $B$. The reduced rank regression estimator of $B$ is defined as $\\hat{B}_R = \\text{SVD}_{l,r}(\\hat{C})$.\n\n**Remark I.1.** Under the assumption that $x \\sim N(0,\\Sigma_N)$, and $\\Sigma_N$ is non-degenerate, by Lemma IV.1, $s(x) = \\Sigma_N^{-1}x$, if we let $\\hat{s}(x) = (1/n)(X^‚ä§X)^{-1}x$, then $\\hat{B} = \\text{SVD}_{l,r}(\\hat{C}_{\\text{ols}})$. The difference between $\\hat{B}_R$ and $\\hat{B}$ lies in the projection matrix $V_rV_r^‚ä§$, which can be seen as the benefit of $\\hat{B}_R$ taking advantage of the extra linear information of link functions in model (S5). Results of simulations in Section 4 demonstrate that performances of $\\hat{B}$ and $\\hat{B}_R$ are almost the same when $x \\sim N(0,\\Sigma_N)$, the difference above is almost negligible.\n\nThe multi-index model has a close relationship with NNs, and many works try to show that NNs can be used to estimate MIM and construct the representation space in the low-dimensional setting (Bauer and Kohler, 2019; Damian et al., 2022; Mousavi-Hosseini et al., 2022). Similarly, for our multi-response extension, the matrix $B$ can also be estimated by NNs. Let $F_Œ∏(\\cdot): \\mathbb{R}^r \\to \\mathbb{R}^q$ be a neural network parametrized by $Œ∏$, the neural network estimator $\\hat{B}_N$ can be obtained by\n\n$$(\\hat{Œ∏}_N, \\hat{B}_N) = \\text{argmin}_{(Œ∏,B)} \\frac{1}{n} \\sum_{i=1}^n \\|y_i - F_Œ∏(B^‚ä§x_i)\\|_2^2.$$ (S6)\n\nWe solve the optimization problem by mini-batch gradient descent. For details of the neural network structure and training procedures, please see Section II.3 of the Supplement.\n\nTo apply our method, by densities of $x$, first-order and second-order score functions can be derived in closed forms. Please refer to Section II.4 of Supplement for details. Then, for $x \\sim N(0,\\Sigma_N)$, parameters are estimated by maximum likelihood estimation. For $x \\sim t_ŒΩ(0,\\Sigma_t)$ and $x \\sim H_{\\chi,\\psi}(0,\\Sigma_H)$, parameters are estimated by a multi-cycle, expectation, conditional estimation algorithm (Breymann and L√ºthi, 2013). Then we use the plug-in estimators $\\hat{s}(\\cdot)$ and $\\hat{T}(\\cdot)$ to calculate $\\hat{B}$ and $\\tilde{B}$ defined by equation (2.8) and equation (2.11), respectively.\n\nI.5 Extended Experiments and Further Discussion\n\nIn this subsection, we provide results of experiments on additional choices of p in {50, 80, 100}, and p = 30 in the main paper, which are depicted in Figures S1 to S4. Except results similar to those discussed in Section 4.2, comparing Figures S1 to S4, we see that, while the second-order method tend to overwhelm other methods as the sample size increases, the minimum sample size that it needs to overtake others increases as p increases, which coincides with our analysis of the higher order dependency of its convergence rate on p in Section 3.2.\n\nI.6 Measures of Qualities of Estimates of Latent Spaces in Section 5\n\nSuppose image data X ‚àà ‚Ñù·∂úÀ£·∂ú ‚àº P(X), we have an encoder E(Z) : ‚Ñù·∂úÀ£·∂ú ‚Üí ‚Ñù ∞, and a decoder D(z) : ‚Ñù ∞ ‚Üí ‚Ñù·∂úÀ£·∂ú, where h denotes the embedding dimension. We first consider two metrics measuring (dis-)similarities between the original image X and the recovered image XÃÉ = D ‚àò E(X).\n\n1. We consider the normalized root squared error (NRSE), i.e., E_X(‚à•XÃÉ - X‚à•_F / ‚à•X‚à•_F)\n\n2. We also consider the structural similarity index measure (SSIM) between XÃÉ and X, i.e., E_X{SSIM(XÃÉ, X)}. SSIM calculates the similarity score between two images by comparing their luminance, contrast, and structure; it ranges from -1 to 1 and the larger the SSIM is, the more similar the images are. For the definition of SSIM, please refer to Section III.1.1 of the Supplement for details.\n\n3. Specifically, we consider the classification accuracy defined by:\n\nE[I{argmax ‚àò C_E ‚àò E(X) = y}],\n\nwhere I(¬∑) is the indicator function and C_E(¬∑) : ‚Ñù ∞ ‚Üí ‚Ñù¬π‚Å∞ is a multinomial logistic regression model trained on the set [{E(X_i), y_i}]‚Åø·µ¢‚Çå‚ÇÅ. For details of the model C_E(¬∑), please refer to Section III.1.2 of the Supplement.\n\nI.7 Application Details of Competing Methods in Section 5\n\nLet BÃÇ_PCA = Eigen_h[var{vec(X)}]. For PCA method, we let the encoder to be E_PCA(X) = BÃÇ·µÄ_PCA vec(X) and the decoder to be D_PCA(x) = vec‚Åª¬π{BÃÇ_PCA x}.¬≥ We employ fully connected neural networks for AE, encoder E_AE,Œ∏‚Çë(X) and decoder D_AE,Œ∏d(x), are parametrized by Œ∏_e and Œ∏_d respectively, which can be estimated by minimizing the reconstruction squared error loss. Empirically, (Œ∏ÃÇ_e, Œ∏ÃÇ_d) is the minimizer of the following loss function:\n\n$$‚Ñì(Œ∏_e, Œ∏_d) = \\frac{1}{n} \\sum_{i=1}^n ‚à•D_{AE,Œ∏_d} ‚àò E_{AE,Œ∏_e}(X_i) - X_i‚à•¬≤_F.$$\n\nWe also use batch-training methods to solve the optimization problem. For details of the structure of the AE and training procedures, please refer to Section III.1.3 of the Supplement.\n\n¬≥Since pixel values of original images are in [0,1], we use the clip function clip(x, Œ±, Œ≤) = min{max(x, Œ±), Œ≤} to scale the output of the decoder. For fair comparison, we handle the range problem in the same way for all methods, instead of constraining the range of output in the structure of the decoder.\n\nFor our first-order estimator, we use the pre-trained score model for MNIST from Song and Ermon (2019) as our first-order score estimator denoted as $\\hat{s}(¬∑)^4$. Then the plug-in estimator $\\hat{B}$ equals $\\text{SVD}_{l,h}[(1/n)\\sum_{i=1}^n \\text{vec}\\{\\hat{s}(X_i)\\}\\{\\text{vec}(X_i)\\}^\\top]$, and our first-order encoder is defined as $\\mathcal{E}_{S_f}(X) = \\hat{B}^\\top \\text{vec}(X)$. Our first-order decoder has the same structure as that of the AE, parametrized by $\\theta_{S_f}$ and denoted as $D_{S_f,\\theta_{S_f}}(\\cdot)$; $\\theta_{S_f}$ can also be estimated by minimizing the following empirical mean reconstruction squared error losses on the training set:\n\n$$\\ell(\\theta_{S_f}) = \\frac{1}{n}\\sum_{i=1}^n \\{||D_{S_f,\\theta_{S_f}} \\circ \\mathcal{E}_{S_f}(X_i) - X_i||_F^2\\} \\qquad (S8)$$\n\nThe decoder is trained in the way similar to that of the AE, please see Section III.1.3 of the Supplement for details.\n\nFor our second-order estimator, since there is a lack of trustworthy second-order score models as discussed in Section I.3, we assume pixel values in an vectorized image data follow a multivariate normal distribution and use the estimator of second-order stein's score of multivariate normal distribution introduced in Section II.4 as the second-order score estimator $\\hat{T}(\\cdot)$. We still use $\\tilde{B}$ to denote the second-order plug-in estimator, which equals $\\text{SVD}_{l,h}[(1/n/c^2\\sum_{i=1}^n \\sum_{j=1}^{c^2} \\text{vec}(X_i)_j\\hat{T}\\{\\text{vec}(X_i)\\}]$, and the second-order encoder is defined as $\\mathcal{E}_{S_s}(X) = \\tilde{B}^\\top \\text{vec}(X)$. The second order decoder $D_{S_s,\\theta_{S_s}}(X)$ has the same structure as the first-order decoder and is trained in the same way.", 'sub_heading': 'I.4 Reduced Rank Estimator, Neural Network Estimator and Ours', 'collection_name': 'pdf4', 'similarity': 0.8028448820114136}, {'text': 'Balasubramanian, K., Fan, J. and Yang, Z. (2018). Tensor methods for additive index models under discordance and heterogeneity. arXiv preprint arXiv:1807.06693 .\n\nBauer, B. and Kohler, M. (2019). On deep learning as a remedy for the curse of dimensionality in nonparametric regression. The Annals of Statistics 47 2261‚Äì2285.\n\nBauer, F., Pereverzev, S. and Rosasco, L. (2007). On regularization algorithms in learning theory. Journal of complexity 23 52‚Äì72.\n\nBreymann, W. and L√ºthi, D. (2013). ghyp: A package on generalized hyperbolic distributions. Manual for R Package ghyp .\n\nCandes, E. J., Li, X., Ma, Y. and Wright, J. (2009). Robust principal component analysis? arXiv preprint arXiv: 0912.3599 .\n\nChangliang Zou, Y. K. and Zhang, W. (2022). Estimation of low rank high-dimensional multivariate linear models for multi-response data. Journal of the American Statistical Association 117 693‚Äì703.\n\nChen, K., Dong, H. and Chan, K.-S. (2012). Reduced rank regression via adaptive nuclear norm penalization. arXiv preprint arXiv:1201.0381 .\n\nChen, X., Zou, C. and Cook, R. D. (2010). Coordinate-independent sparse sufficient dimension reduction and variable selection. The Annals of Statistics 38 3696 ‚Äì 3723.\n\nDamian, A., Lee, J. and Soltanolkotabi, M. (2022). Neural networks can learn representations with gradient descent. In Conference on Learning Theory.\n\nFriedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American Statistical Association 76 817‚Äì823.\n\nHui Zou, T. H. and Tibshirani, R. (2006). Sparse principal component analysis. Journal of Computational and Graphical Statistics 15 265‚Äì286.\n\nHyv√§rinen, A. and Dayan, P. (2005). Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research 6 695‚Äì709.\n\nJanzamin, M., Sedghi, H. and Anandkumar, A. (2014). Score function features for discriminative learning: Matrix and tensor framework. arXiv preprint arXiv:1412.2863 .\n\nKobak, D., Bernaerts, Y., Weis, M. A., Scala, F., Tolias, A. S. and Berens, P. (2021). Sparse reduced-rank regression for exploratory visualisation of paired multivariate data. Journal of the Royal Statistical Society Series C: Applied Statistics 70 980‚Äì1000.\n\nLee, W. and Liu, Y. (2012). Simultaneous multiple response regression and inverse covariance matrix estimation via penalized gaussian maximum likelihood. Journal of Multivariate Analysis 111 241‚Äì255.\n\nLi, K.-C. (1991). Sliced inverse regression for dimension reduction. Journal of the American Statistical Association 86 316‚Äì327.\n\nLi, K.-C. (1992). On principal hessian directions for data visualization and dimension reduction: Another application of stein\'s lemma. Journal of the American Statistical Association 87 1025‚Äì1039.\n\nLi, K.-C. and Duan, N. (1989). Regression analysis under link violation. The Annals of Statistics 1009‚Äì1052.\n\nLi, Y. and Turner, R. E. (2017). Gradient estimators for implicit models. arXiv preprint arXiv:1705.07107 .\n\nLu, Z., Monteiro, R. D. and Yuan, M. (2012). Convex optimization methods for dimension reduction and coefficient estimation in multivariate linear regression. Mathematical Programming 131 163‚Äì194.\n\nMakhzani, A. and Frey, B. (2013). K-sparse autoencoders. arXiv preprint arXiv:1312.5663 .\n\nMeng, C., Song, Y., Li, W. and Ermon, S. (2021). Estimating high order gradients of the data distribution by denoising. Advances in Neural Information Processing Systems 34 25359‚Äì25369.\n\nMousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. and Erdogdu, M. A. (2022).\nNeural networks efficiently learn low-dimensional representations with sgd. arXiv preprint\narXiv:2209.14863 .\n\nMukherjee, A. and Zhu, J. (2011). Reduced rank ridge regression and its kernel extensions.\nStatistical analysis and data mining: the ASA data science journal 4 612‚Äì622.\n\nO\'Rourke, S., Vu, V. and Wang, K. (2018). Random perturbation of low rank matrices:\nImproving classical bounds. Linear Algebra and its Applications 540 26‚Äì59.\n\nPearson, K. (1901). Liii. on lines and planes of closest fit to systems of points in space. The\nLondon, Edinburgh, and Dublin philosophical magazine and journal of science 2 559‚Äì572.\n\nRifai, S., Vincent, P., Muller, X., Glorot, X. and Bengio, Y. (2011). Contractive auto-\nencoders: Explicit invariance during feature extraction. In Proceedings of the 28th international\nconference on international conference on machine learning.\n\nScala, F., Kobak, D., Bernabucci, M., Bernaerts, Y., Cadwell, C. R., Castro, J. R.,\nHartmanis, L., Jiang, X., Laturnus, S., Miranda, E. et al. (2021). Phenotypic variation\nof transcriptomic cell types in mouse motor cortex. Nature 598 144‚Äì150.\n\nShi, J., Sun, S. and Zhu, J. (2018). A spectral approach to gradient estimation for implicit\ndistributions. In International Conference on Machine Learning.\n\nSimon, N., Friedman, J. and Hastie, T. (2013). A blockwise descent algorithm for group-\npenalized multiresponse and multinomial regression. arXiv preprint arXiv:1311.6529 .\n\nSong, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data\ndistribution. Advances in neural information processing systems 32.\n\nSong, Y., Garg, S., Shi, J. and Ermon, S. (2020). Sliced score matching: A scalable approach\nto density and score estimation. In Uncertainty in Artificial Intelligence.\n\nStrathmann, H., Sejdinovic, D., Livingstone, S., Szabo, Z. and Gretton, A. (2015).\nGradient-free hamiltonian monte carlo with efficient kernel exponential families. Advances in\nNeural Information Processing Systems 28 955‚Äì963.\n\nTan, K. M., Wang, Z., Zhang, T., Liu, H. and Cook, R. D. (2018). A convex formulation for\nhigh-dimensional sparse sliced inverse regression. Biometrika 105 769‚Äì782.\n\nVershynin, R. (2018a). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVershynin, R. (2018b). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVincent, P. (2011). A connection between score matching and denoising autoencoders. Neural\ncomputation 23 1661‚Äì1674.\n\nVincent, P., Larochelle, H., Bengio, Y. and Manzagol, P.-A. (2008). Extracting and\ncomposing robust features with denoising autoencoders. In Proceedings of the 25th international\nconference on Machine learning.\n\nWANG, W., LIANG, Y. and XING, E. (2013). Block regularized lasso for multivariate multi-response linear regression. In Artificial intelligence and statistics.\n\nXU, X. (2020). On the perturbation of the moore‚Äìpenrose inverse of a matrix. Applied Mathematics and Computation 374 124920.\n\nYANG, Z., BALASUBRAMANIAN, K. and LIU, H. (2017a). High-dimensional non-Gaussian single index models via thresholded score function estimation. In Proceedings of the 34th International Conference on Machine Learning, vol. 70.\n\nYANG, Z., BALASUBRAMANIAN, K., WANG, Z. and LIU, H. (2017b). Learning non-gaussian multi-index model via second-order stein\'s method. Advances in Neural Information Processing Systems 30 6097‚Äì6106.\n\nYU, Y., WANG, T. and SAMWORTH, R. J. (2015). A useful variant of the davis‚Äìkahan theorem for statisticians. Biometrika 102 315‚Äì323.\n\nYUAN, M., EKICI, A., LU, Z. and MONTEIRO, R. (2007). Dimension reduction and coefficient estimation in multivariate linear regression. Journal of the Royal Statistical Society Series B: Statistical Methodology 69 329‚Äì346.\n\nZHOU, Y., SHI, J. and ZHU, J. (2020). Nonparametric score estimators. In International Conference on Machine Learning.\n\n17\n\nSupplementary Material for\n"Nonlinear Multiple Response Regression and Learning of Latent Spaces"\n\nYe Tian, Sanyou Wu and Long Feng', 'sub_heading': 'References', 'collection_name': 'pdf4', 'similarity': 0.8010231256484985}, {'text': 'Table S1 demonstrates the structure of the AE we use. The same decoder structure is also used for our method. To estimate the parameters of AE (Œ∏_e, Œ∏_d), we minimize the loss function (S7); and to estimate the parameters of decoders of our methods, we minimize the loss functions (S8). For both AE and our methods, we use the batch-training strategy to train the neural network. We use Adam optimizer with Pytorch default parameters. We choose the batch size to be 128 and we train the neural network for 50 epochs.\n\nTable S1: Structure of the Autoencoder\n\n| Layer | Type | Encoder | Decoder |\n|-------|------|---------|---------|\n| 1 | fully connected layer (in dims = 784, out dims = 4h) | ‚úì | ‚úì |\n| 2 | ReLU | ‚úì | ‚úì |\n| 3 | fully connected layer (in dims = 4h, out dims = 2h) | ‚úì | fully connected layer (in dims = 2h, out dims = 4h) |\n| 4 | ReLU | ‚úì | ‚úì |\n| 5 | fully connected layer (in dims = 2h, out dims = h) | ‚úì | fully connected layer (in dims = 4h, out dims = 784) |', 'sub_heading': 'III.1.3 Structure and Training Details of Autoencoder', 'collection_name': 'pdf4', 'similarity': 0.8005106449127197}], 'cnn1': [{'text': "As noted earlier, CNNs primarily focus on the basis that the input will be comprised of images. This focuses the architecture to be set up in way to best suit the need for dealing with the specific type of data.\n\n4      Keiron O‚ÄôShea et al.\n\nOne of the key differences is that the neurons that the layers within the CNN\nare comprised of neurons organised into three dimensions, the spatial dimen-\nsionality of the input (height and the width) and the depth. The depth does not\nrefer to the total number of layers within the ANN, but the third dimension of a\nactivation volume. Unlike standard ANNS, the neurons within any given layer\nwill only connect to a small region of the layer preceding it.\nIn practice this would mean that for the example given earlier, the input ‚Äôvol-\nume‚Äô will have a dimensionality of 64 √ó 64 √ó3 (height, width and depth), lead-\ning to a final output layer comprised of a dimensionality of 1 √ó 1 √ó n (where\nn represents the possible number of classes) as we would have condensed the\nfull input dimensionality into a smaller volume of class scores filed across the\ndepth dimension.\n\n2.1  Overall architecture\n\nCNNs are comprised of three types of layers. These are convolutional layers,\npooling layers and fully-connected layers. When these layers are stacked, a\nCNN architecture has been formed. A simplified CNN architecture for MNIST\nclassification is illustrated in Figure 2.\n\nconvolution\nw/ReLu pooling     fully‚Äëconnected\n\n0\n...\n9\ninput                                    output\n\nfully‚Äëconnected\nw/ ReLu\n\nFig. 2: An simple CNN architecture, comprised of just five layers\n\nThe basic functionality of the example CNN above can be broken down into\nfour key areas.\n1. As found in other forms of ANN, the input layer will hold the pixel values\nof the image.\n2. The convolutional layer will determine the output of neurons of which are\nconnected to local regions of the input through the calculation of the scalar\nproduct between their weights and the region connected to the input vol-\nume. The rectified linear unit (commonly shortened to ReLu) aims to apply\n\nIntroduction to Convolutional Neural Networks    5\n\nan 'elementwise' activation function such as sigmoid to the output of the activation produced by the previous layer.\n\n3. The pooling layer will then simply perform downsampling along the spatial dimensionality of the given input, further reducing the number of parameters within that activation.\n\n4. The fully-connected layers will then perform the same duties found in standard ANNs and attempt to produce class scores from the activations, to be used for classification. It is also suggested that ReLu may be used between these layers, as to improve performance.\n\nThrough this simple method of transformation, CNNs are able to transform the original input layer by layer using convolutional and downsampling techniques to produce class scores for classification and regression purposes.\n\n| | | | | | | | | | | | | | |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| / | L | ‚Ä¢ | - | - | ) | / | - | - | ) | 6 | - | / | \\ |\n| 7 | | < | - | \\ | ) | ( | ‚Ä¢ | | - | ) | < | ) | ‚Ä¢ |\n| < | / | \\ | \\ | / | - | / | ( | ( | / | - | \\ | - | / |\n| \\ | ) | ( | - | < | ( | ) | - | / | \\ | ( | - | ( | ) |\n| - | | ) | ) | \\ | - | ) | - | | - | ( | | | |\n| / | 5 | - | ( | ( | - | ) | - | ( | / | ) | ) | - |\n\nFig. 3: Activations taken from the first convolutional layer of a simplistic deep CNN, after training on the MNIST database of handwritten digits. If you look carefully, you can see that the network has successfully picked up on characteristics unique to specific numeric digits.\n\nHowever, it is important to note that simply understanding the overall architecture of a CNN architecture will not suffice. The creation and optimisation of these models can take quite some time, and can be quite confusing. We will now explore in detail the individual layers, detailing their hyperparameters and connectivities.", 'sub_heading': '2 CNN architecture', 'collection_name': 'cnn1', 'similarity': 0.8361161947250366}, {'text': "As the name implies, the convolutional layer plays a vital role in how CNNs operate. The layers parameters focus around the use of learnable kernels.\n\n6       Keiron O'Shea et al.\n\nThese kernels are usually small in spatial dimensionality, but spreads along the entirety of the depth of the input. When the data hits a convolutional layer, the layer convolves each filter across the spatial dimensionality of the input to produce a 2D activation map. These activation maps can be visualised, as seen in Figure 3.\n\nAs we glide through the input, the scalar product is calculated for each value in that kernel. (Figure 4) From this the network will learn kernels that 'fire' when they see a specific feature at a given spatial position of the input. These are commonly known as activations.\n\n| Input Vector |  |  |  |  |  | Pooled Vector |  |  | Kernel |  |  | Destination Pixel |\n|--------------|--|--|--|--|--|---------------|--|--|--------|--|--|-------------------|\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 4 | 0 | 0 |  |\n| 0 | 1 | 2 | 1 | 1 | 2 | 0 | 1 | 2 | 0 | 0 | 0 | -8 |\n| 0 | 1 | 1 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 0 | -4 |  |\n| 1 | 0 | 0 | 0 | 0 | 0 |  |  |  |  |  |  |  |\n| 0 | 0 | 1 | 1 | 1 | 0 |  |  |  |  |  |  |  |\n| 0 | 1 | 1 | 1 | 1 | 1 |  |  |  |  |  |  |  |\n\nFig. 4: A visual representation of a convolutional layer. The centre element of the kernel is placed over the input vector, of which is then calculated and replaced with a weighted sum of itself and any nearby pixels.\n\nEvery kernel will have a corresponding activation map, of which will be stacked along the depth dimension to form the full output volume from the convolutional layer.\n\nAs we alluded to earlier, training ANNs on inputs such as images results in models of which are too big to train effectively. This comes down to the fully-connected manner of standard ANN neurons, so to mitigate against this every neuron in a convolutional layer is only connected to small region of the input volume. The dimensionality of this region is commonly referred to as the receptive field size of the neuron. The magnitude of the connectivity through the depth is nearly always equal to the depth of the input.\n\nFor example, if the input to the network is an image of size 64 √ó 64 √ó 3 (a RGB-coloured image with a dimensionality of 64 √ó 64) and we set the receptive field size as 6 √ó 6, we would have a total of 108 weights on each neuron within the convolutional layer. (6 √ó 6 √ó 3 where 3 is the magnitude of connectivity across the depth of the volume) To put this into perspective, a standard neuron seen in other forms of ANN would contain 12,288 weights each.\n\nConvolutional layers are also able to significantly reduce the complexity of the model through the optimisation of its output. These are optimised through three hyperparameters, the depth, the stride and setting zero-padding.\n\nIntroduction to Convolutional Neural Networks    7\n\nThe depth of the output volume produced by the convolutional layers can be manually set through the number of neurons within the layer to a the same region of the input. This can be seen with other forms of ANNs, where the all of the neurons in the hidden layer are directly connected to every single neuron beforehand. Reducing this hyperparameter can significantly minimise the total number of neurons of the network, but it can also significantly reduce the pattern recognition capabilities of the model.\n\nWe are also able to define the stride in which we set the depth around the spatial dimensionality of the input in order to place the receptive field. For example if we were to set a stride as 1, then we would have a heavily overlapped receptive field producing extremely large activations. Alternatively, setting the stride to a greater number will reduce the amount of overlapping and produce an output of lower spatial dimensions.\n\nZero-padding is the simple process of padding the border of the input, and is an effective method to give further control as to the dimensionality of the output volumes.\n\nIt is important to understand that through using these techniques, we will alter the spatial dimensionality of the convolutional layers output. To calculate this, you can make use of the following formula:\n\n$$(V - R) + 2Z \\over S + 1$$\n\nWhere V represents the input volume size (height√ówidth√ódepth), R represents the receptive field size, Z is the amount of zero padding set and S referring to the stride. If the calculated result from this equation is not equal to a whole integer then the stride has been incorrectly set, as the neurons will be unable to fit neatly across the given input.\n\nDespite our best efforts so far we will still find that our models are still enormous if we use an image input of any real dimensionality. However, methods have been developed as to greatly curtail the overall number of parameters within the convolutional layer.\n\nParameter sharing works on the assumption that if one region feature is useful to compute at a set spatial region, then it is likely to be useful in another region. If we constrain each individual activation map within the output volume to the same weights and bias, then we will see a massive reduction in the number of parameters being produced by the convolutional layer.\n\nAs a result of this as the backpropagation stage occurs, each neuron in the output will represent the overall gradient of which can be totalled across the depth - thus only updating a single set of weights, as opposed to every single one.\n\n8      Keiron O'Shea et al.", 'sub_heading': '2.2 Convolutional layer', 'collection_name': 'cnn1', 'similarity': 0.826104998588562}, {'text': '1. Ciresan, D., Meier, U., Schmidhuber, J.: Multi-column deep neural networks for image classification. In: Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. pp. 3642‚Äì3649. IEEE (2012)\n\n2. Cire≈üan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J.: Mitosis detection in breast cancer histology images with deep neural networks. In: Medical Image Computing and Computer-Assisted Intervention‚ÄìMICCAI 2013, pp. 411‚Äì418. Springer (2013)\n\n3. Ciresan, D.C., Meier, U., Masci, J., Maria Gambardella, L., Schmidhuber, J.: Flexible, high performance convolutional neural networks for image classification. In: IJCAI Proceedings-International Joint Conference on Artificial Intelligence. vol. 22, p. 1237 (2011)\n\nIntroduction to Convolutional Neural Networks         11\n\n4. Cire≈üan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J.: Convolutional neural network committees for handwritten character classification. In: Document Analysis and Recognition (ICDAR), 2011 International Conference on. pp. 1135‚Äì1139. IEEE (2011)\n\n5. Egmont-Petersen, M., de Ridder, D., Handels, H.: Image processing with neural networks a review. Pattern recognition 35(10), 2279‚Äì2301 (2002)\n\n6. Farabet, C., Martini, B., Akselrod, P., Talay, S., LeCun, Y., Culurciello, E.: Hardware accelerated convolutional neural networks for synthetic vision systems. In: Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on. pp. 257‚Äì260. IEEE (2010)\n\n7. Hinton, G.: A practical guide to training restricted boltzmann machines. Momentum 9(1), 926 (2010)\n\n8. Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R.: Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580 (2012)\n\n9. Ji, S., Xu, W., Yang, M., Yu, K.: 3d convolutional neural networks for human action recognition. Pattern Analysis and Machine Intelligence, IEEE Transactions on 35(1), 221‚Äì231 (2013)\n\n10. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L.: Large-scale video classification with convolutional neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. pp. 1725‚Äì1732. IEEE (2014)\n\n11. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Advances in neural information processing systems. pp. 1097‚Äì1105 (2012)\n\n12. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural computation 1(4), 541‚Äì551 (1989)\n\n13. LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11), 2278‚Äì2324 (1998)\n\n14. Nebauer, C.: Evaluation of convolutional neural networks for visual recognition. Neural Networks, IEEE Transactions on 9(4), 685‚Äì696 (1998)\n\n15. Simard, P.Y., Steinkraus, D., Platt, J.C.: Best practices for convolutional neural networks applied to visual document analysis. In: null. p. 958. IEEE (2003)\n\n16. Srivastava, N.: Improving neural networks with dropout. Ph.D. thesis, University of Toronto (2013)\n\n17. Szarvas, M., Yoshizawa, A., Yamamoto, M., Ogata, J.: Pedestrian detection with convolutional neural networks. In: Intelligent Vehicles Symposium, 2005. Proceedings. IEEE. pp. 224‚Äì229. IEEE (2005)\n\n18. Szegedy, C., Toshev, A., Erhan, D.: Deep neural networks for object detection. In: Advances in Neural Information Processing Systems. pp. 2553‚Äì2561 (2013)\n\n19. Tivive, F.H.C., Bouzerdoum, A.: A new class of convolutional neural networks (siconnets) and their application of face detection. In: Neural Networks, 2003. Proceedings of the International Joint Conference on. vol. 3, pp. 2157‚Äì2162. IEEE (2003)\n\n20. Zeiler, M.D., Fergus, R.: Stochastic pooling for regularization of deep convolutional neural networks. arXiv preprint arXiv:1301.3557 (2013)\n\n21. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks. In: Computer Vision‚ÄìECCV 2014, pp. 818‚Äì833. Springer (2014)', 'sub_heading': 'References', 'collection_name': 'cnn1', 'similarity': 0.8010231256484985}], 'cnn3': []}, 'default_results': {'Introduction': {'cnn1': [{'text': 'Artificial Neural Networks (ANNs) are computational processing systems of which are heavily inspired by way biological nervous systems (such as the human brain) operate. ANNs are mainly comprised of a high number of interconnected computational nodes (referred to as neurons), of which work entwine in a distributed fashion to collectively learn from the input in order to optimise its final output.\n\nThe basic structure of a ANN can be modelled as shown in Figure 1. We would load the input, usually in the form of a multidimensional vector to the input layer of which will distribute it to the hidden layers. The hidden layers will then make decisions from the previous layer and weigh up how a stochastic change within itself detriments or improves the final output, and this is referred to as the process of learning. Having multiple hidden layers stacked upon each-other is commonly called deep learning.\n\n2      Keiron O‚ÄôShea et al.\n\nInput Layer    Hidden Layer   Output Layer\n\nInput 1\n\nInput 2\nOutput\n\nInput 3\n\nInput 4\n\nFig. 1: A simple three layered feedforward neural network (FNN), comprised\nof a input layer, a hidden layer and an output layer. This structure is the basis\nof a number of common ANN architectures, included but not limited to Feed-\nforward Neural Networks (FNN), Restricted Boltzmann Machines (RBMs) and\nRecurrent Neural Networks (RNNs).\n\nThe two key learning paradigms in image processing tasks are supervised and\nunsupervised learning. Supervised learning is learning through pre-labelled\ninputs, which act as targets. For each training example there will be a set of\ninput values (vectors) and one or more associated designated output values.\nThe goal of this form of training is to reduce the models overall classification\nerror, through correct calculation of the output value of training example by\ntraining.\n\nUnsupervised learning differs in that the training set does not include any la-\nbels. Success is usually determined by whether the network is able to reduce or\nincrease an associated cost function. However, it is important to note that most\nimage-focused pattern-recognition tasks usually depend on classification using\nsupervised learning.\n\nConvolutional Neural Networks (CNNs) are analogous to traditional ANNs\nin that they are comprised of neurons that self-optimise through learning. Each\nneuron will still receive an input and perform a operation (such as a scalar\nproduct followed by a non-linear function) - the basis of countless ANNs. From\nthe input raw image vectors to the final output of the class score, the entire of\nthe network will still express a single perceptive score function (the weight).\nThe last layer will contain loss functions associated with the classes, and all of\nthe regular tips and tricks developed for traditional ANNs still apply.\n\nThe only notable difference between CNNs and traditional ANNs is that CNNs\nare primarily used in the field of pattern recognition within images. This allows\nus to encode image-specific features into the architecture, making the network\n\nIntroduction to Convolutional Neural Networks    3\n\nmore suited for image-focused tasks - whilst further reducing the parameters required to set up the model.\n\nOne of the largest limitations of traditional forms of ANN is that they tend to struggle with the computational complexity required to compute image data. Common machine learning benchmarking datasets such as the MNIST database of handwritten digits are suitable for most forms of ANN, due to its relatively small image dimensionality of just 28 √ó 28. With this dataset a single neuron in the first hidden layer will contain 784 weights (28 √ó 28 √ó 1 where 1 bare in mind that MNIST is normalised to just black and white values), which is manageable for most forms of ANN.\n\nIf you consider a more substantial coloured image input of 64 √ó 64, the number of weights on just a single neuron of the first layer increases substantially to 12,288. Also take into account that to deal with this scale of input, the network will also need to be a lot larger than one used to classify colour-normalised MNIST digits, then you will understand the drawbacks of using such models.', 'similarity': 0.9304435849189758}], 'cnn3': [{'text': 'In order to investigate the effect of the goodness of the first convolutional layer, we train the CNN configurations reported in Section 3.1 again, but this time including the first layer in the goodness computation. Figure 9, reports the results, highlighting that the training of the first layer affects the speed of convergence of the next layers. Adding the first layer also reduces the overall accuracy of the network by approximately 2%.\n\nSCODELLARO, KULKARNI, ALVES AND SCHR√ñTER\n\nGraph showing accuracy over epochs for different layers and training conditions\n\nFigure 9: Our implementation of FF trained CNNs does not require the inclusion of the goodness of the first layer during training. Continuous lines represent evolution of the discrimination accuracy during the training phase, when the first layer is not included. Dashed lines represent the discrimination accuracy evolution if its goodness is included.', 'similarity': 0.8171168565750122}], 'cnn5': [{'text': "Image classification is a core task in computer vision and machine learning, where the goal is to assign one or more labels to an image based on its content. It serves as the foundation for numerous real-world applications, such as facial recognition, autonomous driving, medical diagnosis, and smart manufacturing [1], [2]. The CIFAR-10 dataset [3], introduced by Krizhevsky and Hinton [3], has become a standard benchmark in this field. It consists of 60,000 color images divided into 10 distinct classes, each representing a unique object category, such as airplanes, automobiles, birds, and cats. The dataset is balanced, with an equal number of samples for each class, making it an ideal testbed for evaluating classification algorithms. The relatively small size of the dataset allows for efficient experimentation while retaining sufficient complexity to challenge advanced models.\n\nConvolutional Neural Networks (CNNs) have been the backbone of most state-of-the-art models in image classification. CNNs excel in extracting hierarchical spatial features from images, enabling them to capture low-level edges and textures in earlier layers and high-level semantic features in deeper layers. This hierarchical feature extraction capability, combined with their translational invariance, makes CNNs particularly well-suited for visual tasks. However, achieving high accuracy on the CIFAR-10 dataset presents several challenges. First, the dataset's small image resolution of 32x32x3 limits the amount of information and detail that can be extracted, thereby constraining the model's capacity to distinguish between similar classes. Second, the limited size of the dataset increases the risk of overfitting, especially for deeper networks with a large number of parameters. This necessitates the use of effective regularization techniques and data augmentation strategies. Finally, there is a need for a robust network design that strikes a balance between depth, parameter efficiency, and regularization to achieve both high accuracy and generalization.\n\nThis paper aims to address these challenges by proposing an enhanced CNN architecture specifically designed for CIFAR-10 image classification. As suggested in [4], by integrating deeper convolutional blocks, batch normalization to stabilize training, and dropout to mitigate overfitting, the proposed model effectively extracts rich hierarchical features while maintaining robustness. Experimental results demonstrate that this architecture achieves superior performance, highlighting its potential for tackling small-scale yet complex image classification tasks.\n\nIn this paper, we address these challenges by proposing an enhanced CNN architecture with deeper convolutional layers, batch normalization for stable training, and dropout regularization to mitigate overfitting. Our model surpasses standard CNN baselines in accuracy, highlighting the importance of architectural refinement in deep learning applications.", 'similarity': 0.9230858087539673}], 'pdf2': [{'text': 'Recent years have witnessed the advent of deep learning methods for structural biology culminating in the award of the Nobel Prize in Chemistry. AlphaFold (Jumper et al., 2021) revolutionized protein structure prediction, equipping the field with millions of new structures. Breakthroughs go beyond structure prediction, notably in protein design (Watson et al., 2023; Dauparas et al., 2022), drug discovery (Schneuing et al., 2024; Corso et al., 2022) or fundamental biology (van Kempen et al., 2022). While it is tempting to attribute the success of these methods to the increase in available structural data caused by AlphaFold, most of the methods are actually not reliant on them. Instead, it seems that these breakthroughs result from progress in training neural encoders that directly model protein structures (Jing et al., 2020; Zhang et al., 2022b; Gainza et al., 2020; Wang et al., 2022). This progress is in turn rooted in solid competitions (CASP, CAPRI), and benchmarks (Townshend et al., 2021a; Kucera et al., 2023; Zhu et al., 2022; Jamasb et al., 2024; Notin et al., 2023). By setting clear goals, such benchmarks are the foundation for the development of structure encoders. Yet to date, structure-function benchmarks have focused on proteins.\n\nRibonucleic acids (RNAs) are a large family of molecules which support biological functions along every branch of the tree of life. Besides messenger RNAs, non-coding RNAs carry out biological functions by adopting complex 3D folds (Cech & Steitz, 2014) like proteins do and take up diverse roles in cellular functions, including gene regulation, RNA processing, and protein synthesis (Statello et al., 2021). However, our understanding of non-coding RNAs and their functions remains limited. This can be largely attributed to the negatively charged nature of RNA backbones, which makes it flexible and limits the availability of high-resolution RNA structures, and imposes significant modeling challenges. Another predominant challenge to a functional understanding of RNA 3D structure lies in the lack of infrastructure for the development and evaluation of function prediction models. In this work, we propose a benchmarking suite to act as this facilitating framework.\n\nOur key contributions include:\n\n- Seven tasks related to RNA 3D structure that represent various biological challenges. Each task consists of a dataset, a splitting strategy, and an evaluation method, laying the ground for comparable, reproducible model development.\n\n- End-to-end reproducible and modular access to task data. Modular annotators, filters and splitting strategies, both novel and from existing literature, facilitate the addition of new tasks by other researchers across fields.\n\n*Equal contribution ‚Ä†Equal supervision 1Max Planck Institute of Biochemistry, Munich, Germany 2Mines Paris, PSL Research University, CBIO, Paris, France 3Vanderbilt University, Nashville, Tennessee, USA. Correspondence to: Luis Wyss <wyss@biochem.mpg.de>.\n\nA preprint.\n\nBenchmark for RNA 3D Structure Modeling', 'similarity': 0.9308565855026245}], 'pdf4': [{'text': 'Balasubramanian, K., Fan, J. and Yang, Z. (2018). Tensor methods for additive index models under discordance and heterogeneity. arXiv preprint arXiv:1807.06693 .\n\nBauer, B. and Kohler, M. (2019). On deep learning as a remedy for the curse of dimensionality in nonparametric regression. The Annals of Statistics 47 2261‚Äì2285.\n\nBauer, F., Pereverzev, S. and Rosasco, L. (2007). On regularization algorithms in learning theory. Journal of complexity 23 52‚Äì72.\n\nBreymann, W. and L√ºthi, D. (2013). ghyp: A package on generalized hyperbolic distributions. Manual for R Package ghyp .\n\nCandes, E. J., Li, X., Ma, Y. and Wright, J. (2009). Robust principal component analysis? arXiv preprint arXiv: 0912.3599 .\n\nChangliang Zou, Y. K. and Zhang, W. (2022). Estimation of low rank high-dimensional multivariate linear models for multi-response data. Journal of the American Statistical Association 117 693‚Äì703.\n\nChen, K., Dong, H. and Chan, K.-S. (2012). Reduced rank regression via adaptive nuclear norm penalization. arXiv preprint arXiv:1201.0381 .\n\nChen, X., Zou, C. and Cook, R. D. (2010). Coordinate-independent sparse sufficient dimension reduction and variable selection. The Annals of Statistics 38 3696 ‚Äì 3723.\n\nDamian, A., Lee, J. and Soltanolkotabi, M. (2022). Neural networks can learn representations with gradient descent. In Conference on Learning Theory.\n\nFriedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American Statistical Association 76 817‚Äì823.\n\nHui Zou, T. H. and Tibshirani, R. (2006). Sparse principal component analysis. Journal of Computational and Graphical Statistics 15 265‚Äì286.\n\nHyv√§rinen, A. and Dayan, P. (2005). Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research 6 695‚Äì709.\n\nJanzamin, M., Sedghi, H. and Anandkumar, A. (2014). Score function features for discriminative learning: Matrix and tensor framework. arXiv preprint arXiv:1412.2863 .\n\nKobak, D., Bernaerts, Y., Weis, M. A., Scala, F., Tolias, A. S. and Berens, P. (2021). Sparse reduced-rank regression for exploratory visualisation of paired multivariate data. Journal of the Royal Statistical Society Series C: Applied Statistics 70 980‚Äì1000.\n\nLee, W. and Liu, Y. (2012). Simultaneous multiple response regression and inverse covariance matrix estimation via penalized gaussian maximum likelihood. Journal of Multivariate Analysis 111 241‚Äì255.\n\nLi, K.-C. (1991). Sliced inverse regression for dimension reduction. Journal of the American Statistical Association 86 316‚Äì327.\n\nLi, K.-C. (1992). On principal hessian directions for data visualization and dimension reduction: Another application of stein\'s lemma. Journal of the American Statistical Association 87 1025‚Äì1039.\n\nLi, K.-C. and Duan, N. (1989). Regression analysis under link violation. The Annals of Statistics 1009‚Äì1052.\n\nLi, Y. and Turner, R. E. (2017). Gradient estimators for implicit models. arXiv preprint arXiv:1705.07107 .\n\nLu, Z., Monteiro, R. D. and Yuan, M. (2012). Convex optimization methods for dimension reduction and coefficient estimation in multivariate linear regression. Mathematical Programming 131 163‚Äì194.\n\nMakhzani, A. and Frey, B. (2013). K-sparse autoencoders. arXiv preprint arXiv:1312.5663 .\n\nMeng, C., Song, Y., Li, W. and Ermon, S. (2021). Estimating high order gradients of the data distribution by denoising. Advances in Neural Information Processing Systems 34 25359‚Äì25369.\n\nMousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. and Erdogdu, M. A. (2022).\nNeural networks efficiently learn low-dimensional representations with sgd. arXiv preprint\narXiv:2209.14863 .\n\nMukherjee, A. and Zhu, J. (2011). Reduced rank ridge regression and its kernel extensions.\nStatistical analysis and data mining: the ASA data science journal 4 612‚Äì622.\n\nO\'Rourke, S., Vu, V. and Wang, K. (2018). Random perturbation of low rank matrices:\nImproving classical bounds. Linear Algebra and its Applications 540 26‚Äì59.\n\nPearson, K. (1901). Liii. on lines and planes of closest fit to systems of points in space. The\nLondon, Edinburgh, and Dublin philosophical magazine and journal of science 2 559‚Äì572.\n\nRifai, S., Vincent, P., Muller, X., Glorot, X. and Bengio, Y. (2011). Contractive auto-\nencoders: Explicit invariance during feature extraction. In Proceedings of the 28th international\nconference on international conference on machine learning.\n\nScala, F., Kobak, D., Bernabucci, M., Bernaerts, Y., Cadwell, C. R., Castro, J. R.,\nHartmanis, L., Jiang, X., Laturnus, S., Miranda, E. et al. (2021). Phenotypic variation\nof transcriptomic cell types in mouse motor cortex. Nature 598 144‚Äì150.\n\nShi, J., Sun, S. and Zhu, J. (2018). A spectral approach to gradient estimation for implicit\ndistributions. In International Conference on Machine Learning.\n\nSimon, N., Friedman, J. and Hastie, T. (2013). A blockwise descent algorithm for group-\npenalized multiresponse and multinomial regression. arXiv preprint arXiv:1311.6529 .\n\nSong, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data\ndistribution. Advances in neural information processing systems 32.\n\nSong, Y., Garg, S., Shi, J. and Ermon, S. (2020). Sliced score matching: A scalable approach\nto density and score estimation. In Uncertainty in Artificial Intelligence.\n\nStrathmann, H., Sejdinovic, D., Livingstone, S., Szabo, Z. and Gretton, A. (2015).\nGradient-free hamiltonian monte carlo with efficient kernel exponential families. Advances in\nNeural Information Processing Systems 28 955‚Äì963.\n\nTan, K. M., Wang, Z., Zhang, T., Liu, H. and Cook, R. D. (2018). A convex formulation for\nhigh-dimensional sparse sliced inverse regression. Biometrika 105 769‚Äì782.\n\nVershynin, R. (2018a). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVershynin, R. (2018b). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVincent, P. (2011). A connection between score matching and denoising autoencoders. Neural\ncomputation 23 1661‚Äì1674.\n\nVincent, P., Larochelle, H., Bengio, Y. and Manzagol, P.-A. (2008). Extracting and\ncomposing robust features with denoising autoencoders. In Proceedings of the 25th international\nconference on Machine learning.\n\nWANG, W., LIANG, Y. and XING, E. (2013). Block regularized lasso for multivariate multi-response linear regression. In Artificial intelligence and statistics.\n\nXU, X. (2020). On the perturbation of the moore‚Äìpenrose inverse of a matrix. Applied Mathematics and Computation 374 124920.\n\nYANG, Z., BALASUBRAMANIAN, K. and LIU, H. (2017a). High-dimensional non-Gaussian single index models via thresholded score function estimation. In Proceedings of the 34th International Conference on Machine Learning, vol. 70.\n\nYANG, Z., BALASUBRAMANIAN, K., WANG, Z. and LIU, H. (2017b). Learning non-gaussian multi-index model via second-order stein\'s method. Advances in Neural Information Processing Systems 30 6097‚Äì6106.\n\nYU, Y., WANG, T. and SAMWORTH, R. J. (2015). A useful variant of the davis‚Äìkahan theorem for statisticians. Biometrika 102 315‚Äì323.\n\nYUAN, M., EKICI, A., LU, Z. and MONTEIRO, R. (2007). Dimension reduction and coefficient estimation in multivariate linear regression. Journal of the Royal Statistical Society Series B: Statistical Methodology 69 329‚Äì346.\n\nZHOU, Y., SHI, J. and ZHU, J. (2020). Nonparametric score estimators. In International Conference on Machine Learning.\n\n17\n\nSupplementary Material for\n"Nonlinear Multiple Response Regression and Learning of Latent Spaces"\n\nYe Tian, Sanyou Wu and Long Feng', 'similarity': 0.856539249420166}], 'cnn2': [{'text': '', 'similarity': 0.9304435849189758}], 'cnn4': [{'text': 'Convolutional Neural Networks (CNNs) have revolutionized the field of deep learning, especially in processing grid-like data structures such as images [1]. Their effectiveness in tasks like image classification [2, 3], object detection [4, 5], semantic segmentation [6, 7] and image generation [8] stem from their ability to effectively learn spatial features. Convolutional layers, using filters or kernels, capture local patterns and extract features from input images. One important feature of convolutional layers is the shared weights implemented by kernels. This allows for efficient deep learning on images, as using only fully connected layers for such tasks would result in unfathomable numbers of parameters. Pooling layers, like max pooling and average pooling, reduce the spatial dimensions of these features, helping the network to focus on the most significant aspects.\n\nDespite their popularity, CNNs face challenges in computational efficiency and adaptability. There have been several convolutional neural network architectures that have been proposed that are aimed at efficiency. Some of such architectures include MobileNet [12] and EfficientNet [13]. However, such traditional CNNs, with fixed architectures and number of parameters, may not perform uniformly across different types of input data with varying levels of complexity.\n\nNeural Architecture Search (NAS), a method for selecting optimal neural network architectures, has been a response to this challenge. NAS aims to obtain the best model for a specific task under certain constraints [14]. However, NAS is often resource-intensive due to the need to train multiple candidate models. in order to determine the optimal architecture. It is estimated that the carbon emission produced when using NAS to train a transformer model can amount to five times the lifetime carbon emissions of an average car [15]. This highlights the importance of finding suitable\n\narchitectures for neural networks, yet also points to the limitations of current approaches in terms of static structure and proneness to over-parameterization.\n\nSelf Expanding Neural Networks (SENN), introduced in [9], offer a promising direction. Inspired by neurogenesis, SENN dynamically adds neurons and fully connected layers to the architecture during training using a natural expansion score (defined in section 2.1) as a criteria to guide this process. This helps overcome the problem of over-parametrization. However, its application has been limited to multilayer perceptrons, with extensions to more practical architectures like CNNs identified as a future research prospect.\n\nOur study aims to develop a Self Expanding Convolutional Neural Network (SECNN), building on the concept of SENN and applying it to modern vision tasks. To the best of our knowledge, there has been no research on Self Expanding CNNs, despite the potential they hold for addressing model efficiency and adaptability in vision tasks. Unlike existing approaches that often require restarting training after modifications or rely on preset mechanisms for expansion, our approach utilizes the natural expansion score for dynamic and optimal model expansion. This research represents a significant step in developing adaptable, efficient CNN models for a variety of vision-related tasks.\n\nThe contributions of this research are as follows:\n\n- Developing a Self Expanding CNN that dynamically determines the optimal model size based on the task, thereby enhancing efficiency.\n- Eliminating the need to train multiple CNN models of varying sizes by allowing for the extraction of checkpoints at diverse complexity levels.\n- Eliminating the need to restart the training process after expanding the CNN model.', 'similarity': 0.9304435849189758}], 'pdf1': [{'text': "Autonomous underwater vehicles (AUVs) are valuable tools for exploring and operating underwater. They are used in a wide range of applications, including seafloor mapping, underwater construction and inspection, environmental monitoring, and studying marine life [1], [2]. To accomplish their task accurately and robustly, precise navigation is required. Commonly, this is achieved by fusing inertial sensors with a Doppler velocity log (DVL) [3]. The DVL is an acoustic sensor that utilizes the Doppler effect. This device transmits four acoustic beams to the seafloor, which are then reflected back. Based on the frequency shift, the DVL calculates the velocity of each beam and then estimates the velocity vector of the AUV [4].\n\nData-driven methods have been employed in AUV-related tasks with promising outcomes [5]‚Äì[9]. DCNet, a data-driven framework that utilizes a two-dimensional convolution kernel in an innovative way, demonstrated its ability to improve the process of DVL calibration [10]. Deep-learning frameworks have been used to estimate real-world scenarios of missing DVL beams in partial and complete outage scenarios [11], [12]. Additionally, when all beams are available, the BeamsNet approach [13] offers a more accurate and robust velocity solution using a dedicated deep-learning framework. Deep learning methods were suggested for the fusion process to adaptively estimate the process noise covariance in the inertial DVL fusion process [14], [15]. Recently, an end-to-end deep learning approach was suggested to estimate the AUV acceleration vector, which is introduced to the navigation filter as an additional measurement [16]. In normal operating conditions of the DVL, the BeamsNet approach outperforms model-based approaches. This method employs both inertial measurements and past DVL measurements to estimate the current velocity vector. When updating the navigation filter with this measurement, a cross-correlation arises between the BeamsNet velocity vector measurement and the inertial-based process noise. This process-measurement cross-correlation matrix should be taken into account in the navigation filter to obtain a desired matched filter [17].\n\nIn this paper, we employ the inertial/DVL navigation filter based on the extended Kalman filter (EKF), taking into account the process-measurement cross-correlation matrix. The latter is calculated using the inertial and BeamsNet error sources. Using two real-world underwater AUV datasets, we show the necessity of the cross-correlation matrix to allow filter consistency and robustness.\n\nThe rest of the paper is organized as follows: Section II formulates the problem and presents the theoretical foundation for incorporating cross-correlations within the extended Kalman filter. Section III introduces the proposed cross-correlation-aware deep INS/DVL fusion framework, detailing the integration of BeamsNet with a modified filter formulation. Section IV presents the experimental results and performance analysis based on real-world AUV trajectories. Finally, Section V concludes the findings in the paper.\n\n*Corresponding author: N. Cohen (email: ncohe140@campus.haifa.ac.il).\n\nII. PROBLEM FORMULATION\n\nA. EKF with Correlated Noise\n\nIn the classical derivation of the error-state EKF, it is typically assumed that the process noise and measurement noise are uncorrelated. This is due to the fact that the different sensors provide the information for the process and update. However, in some cases, like the one we introduce in this paper, non-negligible cross-correlations may exist between the process and measurement noise terms. In this section, we present an error-state EKF framework that accounts for such correlation, following the modified Kalman filter equations that explicitly incorporate this dependency.\n\nLet the system dynamics and measurement model be described by the discrete-time equations [18], [19]:\n\n$$x_k = F_{k-1}x_{k-1} + G_{k-1}w_{k-1},$$\n\nwhere $x_k$ denotes the system state vector at time step $k$, $F_{k-1}$ is the state transition matrix that propagates the state from time $k - 1$ to $k$, and $G_{k-1}$ is the process noise input matrix.\n\nThe measurement model is:\n\n$$y_k = H_kx_k + v_k,$$\n\nwhere, $y_k$ is the measurement vector at time step $k$ and $H_k$ is the observation matrix that maps the state vector to the measurement space. Additionally, $w_k \\sim N(0, Q_k)$ denotes the process noise with associated process noise covariance $Q_k$, and $v_k \\sim N(0, R_k)$ denotes the measurement noise with associated measurement noise covariance $R_k$.\n\nThe cross-correlation matrix between the process and measurement noise covariances is defined as [17]:\n\n$$E[w_kv_j^T] = M_k\\delta_{k-j+1},$$\n\nindicating that the process noise at time $k$ is correlated with the measurement noise at time $k+1$. This structure arises naturally in systems where the same external disturbance influences both the system dynamics and the measurement process, albeit with a one-step time lag.\n\nTo incorporate this cross-correlation into the Kalman gain computation, the innovation covariance must be adjusted such that the Kalman gain becomes:\n\n$$K_k = (P_k^-H_k^T + M_k) \\cdot (H_kP_k^-H_k^T + H_kM_k + M_k^TH_k^T + R_k)^{-1},$$\n\nwhere $P_k^-$ is the prior error covariance matrix.\n\nConsequently, the posterior error covariance is updated according to:\n\n$$P_k = P_k^- - K_k(H_kP_k^- + M_k^T).$$\n\nThese modified expressions account for the non-zero cross-correlation between process and measurement noise, improving filter consistency in scenarios where this assumption is violated. The rest of the error state EKF equations and process remain the same with the exception of the Kalman gain (4) and can be seen in [20], for example.\n\nB. Cross-Correlation within INS/DVL Fusion\n\nRecent advances in deep learning have demonstrated significant potential in time series estimation and sensor fusion, especially in navigation systems where standard model-based filters often struggle with drift, nonlinearity, or degraded measurement conditions. By leveraging the expressive power of deep neural networks (DNNs), it is possible to model complex dependencies between sensor modalities and capture higher-order temporal patterns in the data. In particular, DNN-based approaches that jointly process inertial and acoustic measurements can yield more accurate velocity estimates than classical extended Kalman filtering alone.\n\nConsider a system where the goal is to estimate the vehicle's velocity using both the inertial sensors, which include accelerometers that provide the specific force vector $f_k \\in \\mathbb{R}^3$ and gyroscopes that measure the angular velocity vector $\\omega_k \\in \\mathbb{R}^3$, and a DVL, which provides beam velocity measurements $z_k^{DVL} \\in \\mathbb{R}^4$. A deep neural network can be trained to produce a fused velocity estimate via a nonlinear function:\n\n$$\\hat{v}_k = \\mathcal{F}_\\theta(f_{k-T:k}, \\omega_{k-T:k}, z_{k-T:k}^{DVL}),$$\n\nwhere $\\mathcal{F}_\\theta(\\cdot)$ denotes the DNN with parameters $\\theta$ and the inputs consist of a temporal window of size $T$. The output $\\hat{v}_k$ is the estimated velocity vector at time $k$, typically expressed in the body frame.\n\nThe challenge arises from the stochastic properties of the inputs. The IMU measurements $f_k$ and $\\omega_k$ are driven by process noise $w_k$, while the DVL beams $z_k^{DVL}$ are corrupted by measurement noise $v_k$. Let us denote:\n\n$$f_k = f_k^{true} + w_k^f$$\n$$\\omega_k = \\omega_k^{true} + w_k^\\omega$$\n$$z_k^{DVL} = z_k^{true} + v_k$$\n\nwhere $w_k^f$ and $w_k^\\omega$ represent the accelerometer and gyroscopes process noise, respectively, and $v_k$ denotes the DVL measurement noise. Due to the nonlinear mapping, $\\mathcal{F}_\\theta(\\cdot)$, the output velocity estimate becomes a complex function of all the noise sources:\n\n$$\\hat{v}_k = \\mathcal{F}_\\theta(f_k^{true} + w_k^f, \\omega_k^{true} + w_k^\\omega, z_k^{true} + v_k).$$\n\nUnlike linear estimators, where uncorrelated inputs lead to uncorrelated outputs, the nonlinear dependency structure in $\\mathcal{F}_\\theta$ causes interactions between $w_k$ and $v_k$. As a result, the effective measurement used for state correction, the output of the DNN, embeds cross-correlations between the process and measurement noise. That is,\n\n$$E[w_kv_k^T] \\neq 0,$$\n\nand the distribution of the estimation error becomes analytically intractable due to the black-box nature of the network. Therefore, when such a fused estimate is used as an update measurement in an error-state EKF, the assumption of noise independence no longer holds. This violates the foundational\n\n\n```mermaid\ngraph LR\nDVL[DVL] --> BeamsNet\nInertial[Inertial Sensors] --> BeamsNet\nBeamsNet --> CrossCorrelation[Cross-Correlation]\nDVL --> EKF\nInertial --> EKF\nCrossCorrelation --> EKF\nEKF --> Position\nEKF --> Velocity\nEKF --> Orientation\n```\n\nFig. 1: Our proposed approach block diagram illustrates how inertial and DVL measurements are utilized as inputs to the BeamsNet framework. This model generates an enhanced velocity vector measurement update, which is then passed, together with the inertial uncertainty, to the cross-correlation block. This block computes the cross-correlation matrix, which is subsequently integrated into the EKF to derive the navigation solution.\n\nassumptions of standard Kalman filtering theory and necessitates either reformulation of the filter to incorporate the cross-covariance or empirical techniques to mitigate its effect.", 'similarity': 0.9230858087539673}], 'pdf3': [{'text': 'The ship design process involves many challenges but one of the most important is the consideration of extreme events. Knowledge of ocean wave conditions that may cause extreme responses is imperative for safe operation of a ship though the impact on day-to-day routine operations in calm seas is small. Obtaining this knowledge involves understanding the stochastic nature of the seaway conditions, non-linear hydrodynamics in waves, and the corresponding non-linear vessel dynamics. Consequently, extreme responses and conditions are difficult to predict due to the stochastic nature and nonlinearity of the events.\n\nThe most straightforward approach to estimating extremes of stochastic non-linear systems is through Monte Carlo simulations. However, for most tools of reasonable fidelity, the computational cost is far too expensive when considering potential extreme events for longer return periods and simulation run times on the order of real time. Extrapolation methods, generally based on Weibull distributions, can be explored with a limited dataset. However, this approach requires prior knowledge of the response distribution with particular focus on the tail of the distribution.\n\nOther methods to identify extreme behavior efficiently without overextending assumptions have been developed. One such method is the Design Loads Generator (DLG) (Alford 2008, Kim 2012). DLG was initially developed for linear systems with stochastic Gaussian input, and drew from modified phase distributions based on Extreme Value Theory to generate ensembles of extreme realizations for a given return period.\n\nAnother method that has been explored is a lower-fidelity simulation tool that retains major nonlinearities to identify extreme conditions, and then running the identified conditions with a higher-fidelity simulation tool (Reed 2021). In this framework, a surrogate model does not need to be identified but requires a high level of correlation at the peaks between the two simulation tools employed.\n\nExtreme event prediction in the ocean space has also been attempted with machine learning methods. In Guth (2023), extreme statistics of the vertical bending moment were estimated with a wave-episode approach. These wave episodes were generated with the Karhunen-Loeve Theorem and then the responses were estimated by reduced-order models created through Gaussian Process Regression.\n\nWan et al. (2018) introduced an LSTM-based method to predict extreme events in complex dynamical systems. The methodology details an LSTM architecture that provides a reduced-order model to estimate the non-Galerkin contributions to state dynamics of the model of interest.\n\nIn this study, a multi-fidelity approach with neural network correction is investigated. A neural network will be trained to correct extreme low-fidelity\n\nhydrodynamic simulation results. The goal is to train the network with more limited data while still retaining the ability to correct the lower-fidelity results to produce quantitatively accurate higher-fidelity response in the most extreme cases. The intent is to recover the extreme statistics and information about the specific wave groups that lead to the extreme event.\n\nThis study will specifically focus on the pitch response of the Office of Naval Research Tumblehome (ONRT) flared variant hull form in head seas for Sea State 5 (significant wave height of 4.0 meters and modal period of 15.0 seconds,) and Sea State 6 (significant wave height of 6.0 meters and modal period of 12.0 seconds,) and compare the results of the trained neural network with the higher-fidelity simulation tool.\n\nFigure 1: Sample sectional volume calculation for the ONR Topsides Series Tumblehome hull.\n\nThe complete instantaneous submerged volume and its center is computed by integration of sectional values over the hull shown in Figure 2.', 'similarity': 0.9068964719772339}]}, 'Abstract': {'cnn1': [{'text': 'Artificial Neural Networks (ANNs) are computational processing systems of which are heavily inspired by way biological nervous systems (such as the human brain) operate. ANNs are mainly comprised of a high number of interconnected computational nodes (referred to as neurons), of which work entwine in a distributed fashion to collectively learn from the input in order to optimise its final output.\n\nThe basic structure of a ANN can be modelled as shown in Figure 1. We would load the input, usually in the form of a multidimensional vector to the input layer of which will distribute it to the hidden layers. The hidden layers will then make decisions from the previous layer and weigh up how a stochastic change within itself detriments or improves the final output, and this is referred to as the process of learning. Having multiple hidden layers stacked upon each-other is commonly called deep learning.\n\n2      Keiron O‚ÄôShea et al.\n\nInput Layer    Hidden Layer   Output Layer\n\nInput 1\n\nInput 2\nOutput\n\nInput 3\n\nInput 4\n\nFig. 1: A simple three layered feedforward neural network (FNN), comprised\nof a input layer, a hidden layer and an output layer. This structure is the basis\nof a number of common ANN architectures, included but not limited to Feed-\nforward Neural Networks (FNN), Restricted Boltzmann Machines (RBMs) and\nRecurrent Neural Networks (RNNs).\n\nThe two key learning paradigms in image processing tasks are supervised and\nunsupervised learning. Supervised learning is learning through pre-labelled\ninputs, which act as targets. For each training example there will be a set of\ninput values (vectors) and one or more associated designated output values.\nThe goal of this form of training is to reduce the models overall classification\nerror, through correct calculation of the output value of training example by\ntraining.\n\nUnsupervised learning differs in that the training set does not include any la-\nbels. Success is usually determined by whether the network is able to reduce or\nincrease an associated cost function. However, it is important to note that most\nimage-focused pattern-recognition tasks usually depend on classification using\nsupervised learning.\n\nConvolutional Neural Networks (CNNs) are analogous to traditional ANNs\nin that they are comprised of neurons that self-optimise through learning. Each\nneuron will still receive an input and perform a operation (such as a scalar\nproduct followed by a non-linear function) - the basis of countless ANNs. From\nthe input raw image vectors to the final output of the class score, the entire of\nthe network will still express a single perceptive score function (the weight).\nThe last layer will contain loss functions associated with the classes, and all of\nthe regular tips and tricks developed for traditional ANNs still apply.\n\nThe only notable difference between CNNs and traditional ANNs is that CNNs\nare primarily used in the field of pattern recognition within images. This allows\nus to encode image-specific features into the architecture, making the network\n\nIntroduction to Convolutional Neural Networks    3\n\nmore suited for image-focused tasks - whilst further reducing the parameters required to set up the model.\n\nOne of the largest limitations of traditional forms of ANN is that they tend to struggle with the computational complexity required to compute image data. Common machine learning benchmarking datasets such as the MNIST database of handwritten digits are suitable for most forms of ANN, due to its relatively small image dimensionality of just 28 √ó 28. With this dataset a single neuron in the first hidden layer will contain 784 weights (28 √ó 28 √ó 1 where 1 bare in mind that MNIST is normalised to just black and white values), which is manageable for most forms of ANN.\n\nIf you consider a more substantial coloured image input of 64 √ó 64, the number of weights on just a single neuron of the first layer increases substantially to 12,288. Also take into account that to deal with this scale of input, the network will also need to be a lot larger than one used to classify colour-normalised MNIST digits, then you will understand the drawbacks of using such models.', 'similarity': 0.8390400409698486}], 'cnn3': [{'text': 'CNNs are considered the gold standard in deep learning-based image analysis. For instance, in biomedical imaging, they overcome the drawbacks of subjective analysis in the semi-quantitative visual inspection of samples (Gurcan et al., 2009), and they support experts\n\n\nFigure 6: Class activation maps (CAMs) of a FF trained CNN show which image regions are considered beneficial (yellow) or deleterious (pink) by the network for making its prediction. (A), (C), (E), and (G) display four input images. (B), (D), (F), and (H) are their corresponding CAMs. All examples are from a network with 16 convolutional neurons per layer, filter size 5x5, and trained with a batch size of 50.\n\n| A | B | C | D |\n|---|---|---|---|\n| 1 | Heatmap | 2 | Heatmap |\n| E | F | G | H |\n| 7 | Heatmap | 9 | Heatmap |\n\nColor scale: -0.04 (purple) to 0.04 (yellow)\n\nFigure 7: Class activation maps show that the different layers of the FF-trained CNN provide similar, but yet distinguishable information. (A) shows the CAM obtained from considering both layer 2 and layer 3 together. (B) and (C) show the CAMs obtained respectively only from layer 2 and layer 3.\n\n| A | B | C |\n|---|---|---|\n| Heatmap | Heatmap | Heatmap |\n\nColor scale: -0.04 (purple) to 0.04 (yellow)\n\nduring their daily clinical routine by reducing their workload (Shmatko et al., 2022). Furthermore, their exploitation of the spatial information within images makes them suitable for the deployment of explainable AI tools (such as class activation maps), which highlight the image regions contributing most significantly to the classification outcome. Our implementation of FF trained CNN shows that with the right choice of hyperparameters, this technique is competitive with backpropagation. These results were obtained without implementing all the possible and suggested optimizations such as enforcing symmetry of the loss function (Lee and Song, 2023) or choosing hard, i.e. easily confused, labels for the negative data set, as suggested by Hinton (2022). We propose that our work shows the\n\nSCODELLARO, KULKARNI, ALVES AND SCHR√ñTER\n\npotential of FF trained CNNs to address real world computer vision problems. An open question remains if this technique will supersede BP in specific applications. We believe that this potential exists, especially in the cases of neuromorphic hardware and unsupervised learning.\n\nA better understanding of the FF training will however also expand our understanding of the generic concept of neuronal information processing in all its breadth from biological systems to reservoir computing. The demonstrated capability to implement class activation maps offers an initial insight into these research topics. Achieving deeper insights will also mean to understand how the two innovations of FF, providing positive and negative labels and computing a locally defined goodness parameter, contribute to its success individually and synergetically (Tosato et al., 2023). Moreover, a better understanding why it is beneficial to exclude the first layer during the goodness computation (c.f. Appendix B) would be desirable. Subsequent work on FF training should also address its ability to train deeper networks, most likely expanding on the work of Lorberbom et al. (2023). Also the ability of FF training to work with larger and more complex data sets needs to be explored. Finally, its connection to biological neuronal systems (Ororbia and Mali, 2023; Ororbia, 2023) seems a promising research direction.', 'similarity': 0.807677686214447}], 'cnn5': [{'text': "Image classification is a core task in computer vision and machine learning, where the goal is to assign one or more labels to an image based on its content. It serves as the foundation for numerous real-world applications, such as facial recognition, autonomous driving, medical diagnosis, and smart manufacturing [1], [2]. The CIFAR-10 dataset [3], introduced by Krizhevsky and Hinton [3], has become a standard benchmark in this field. It consists of 60,000 color images divided into 10 distinct classes, each representing a unique object category, such as airplanes, automobiles, birds, and cats. The dataset is balanced, with an equal number of samples for each class, making it an ideal testbed for evaluating classification algorithms. The relatively small size of the dataset allows for efficient experimentation while retaining sufficient complexity to challenge advanced models.\n\nConvolutional Neural Networks (CNNs) have been the backbone of most state-of-the-art models in image classification. CNNs excel in extracting hierarchical spatial features from images, enabling them to capture low-level edges and textures in earlier layers and high-level semantic features in deeper layers. This hierarchical feature extraction capability, combined with their translational invariance, makes CNNs particularly well-suited for visual tasks. However, achieving high accuracy on the CIFAR-10 dataset presents several challenges. First, the dataset's small image resolution of 32x32x3 limits the amount of information and detail that can be extracted, thereby constraining the model's capacity to distinguish between similar classes. Second, the limited size of the dataset increases the risk of overfitting, especially for deeper networks with a large number of parameters. This necessitates the use of effective regularization techniques and data augmentation strategies. Finally, there is a need for a robust network design that strikes a balance between depth, parameter efficiency, and regularization to achieve both high accuracy and generalization.\n\nThis paper aims to address these challenges by proposing an enhanced CNN architecture specifically designed for CIFAR-10 image classification. As suggested in [4], by integrating deeper convolutional blocks, batch normalization to stabilize training, and dropout to mitigate overfitting, the proposed model effectively extracts rich hierarchical features while maintaining robustness. Experimental results demonstrate that this architecture achieves superior performance, highlighting its potential for tackling small-scale yet complex image classification tasks.\n\nIn this paper, we address these challenges by proposing an enhanced CNN architecture with deeper convolutional layers, batch normalization for stable training, and dropout regularization to mitigate overfitting. Our model surpasses standard CNN baselines in accuracy, highlighting the importance of architectural refinement in deep learning applications.", 'similarity': 0.8322737812995911}], 'pdf2': [{'text': 'Recent years have witnessed the advent of deep learning methods for structural biology culminating in the award of the Nobel Prize in Chemistry. AlphaFold (Jumper et al., 2021) revolutionized protein structure prediction, equipping the field with millions of new structures. Breakthroughs go beyond structure prediction, notably in protein design (Watson et al., 2023; Dauparas et al., 2022), drug discovery (Schneuing et al., 2024; Corso et al., 2022) or fundamental biology (van Kempen et al., 2022). While it is tempting to attribute the success of these methods to the increase in available structural data caused by AlphaFold, most of the methods are actually not reliant on them. Instead, it seems that these breakthroughs result from progress in training neural encoders that directly model protein structures (Jing et al., 2020; Zhang et al., 2022b; Gainza et al., 2020; Wang et al., 2022). This progress is in turn rooted in solid competitions (CASP, CAPRI), and benchmarks (Townshend et al., 2021a; Kucera et al., 2023; Zhu et al., 2022; Jamasb et al., 2024; Notin et al., 2023). By setting clear goals, such benchmarks are the foundation for the development of structure encoders. Yet to date, structure-function benchmarks have focused on proteins.\n\nRibonucleic acids (RNAs) are a large family of molecules which support biological functions along every branch of the tree of life. Besides messenger RNAs, non-coding RNAs carry out biological functions by adopting complex 3D folds (Cech & Steitz, 2014) like proteins do and take up diverse roles in cellular functions, including gene regulation, RNA processing, and protein synthesis (Statello et al., 2021). However, our understanding of non-coding RNAs and their functions remains limited. This can be largely attributed to the negatively charged nature of RNA backbones, which makes it flexible and limits the availability of high-resolution RNA structures, and imposes significant modeling challenges. Another predominant challenge to a functional understanding of RNA 3D structure lies in the lack of infrastructure for the development and evaluation of function prediction models. In this work, we propose a benchmarking suite to act as this facilitating framework.\n\nOur key contributions include:\n\n- Seven tasks related to RNA 3D structure that represent various biological challenges. Each task consists of a dataset, a splitting strategy, and an evaluation method, laying the ground for comparable, reproducible model development.\n\n- End-to-end reproducible and modular access to task data. Modular annotators, filters and splitting strategies, both novel and from existing literature, facilitate the addition of new tasks by other researchers across fields.\n\n*Equal contribution ‚Ä†Equal supervision 1Max Planck Institute of Biochemistry, Munich, Germany 2Mines Paris, PSL Research University, CBIO, Paris, France 3Vanderbilt University, Nashville, Tennessee, USA. Correspondence to: Luis Wyss <wyss@biochem.mpg.de>.\n\nA preprint.\n\nBenchmark for RNA 3D Structure Modeling', 'similarity': 0.8272076845169067}], 'pdf4': [{'text': 'Balasubramanian, K., Fan, J. and Yang, Z. (2018). Tensor methods for additive index models under discordance and heterogeneity. arXiv preprint arXiv:1807.06693 .\n\nBauer, B. and Kohler, M. (2019). On deep learning as a remedy for the curse of dimensionality in nonparametric regression. The Annals of Statistics 47 2261‚Äì2285.\n\nBauer, F., Pereverzev, S. and Rosasco, L. (2007). On regularization algorithms in learning theory. Journal of complexity 23 52‚Äì72.\n\nBreymann, W. and L√ºthi, D. (2013). ghyp: A package on generalized hyperbolic distributions. Manual for R Package ghyp .\n\nCandes, E. J., Li, X., Ma, Y. and Wright, J. (2009). Robust principal component analysis? arXiv preprint arXiv: 0912.3599 .\n\nChangliang Zou, Y. K. and Zhang, W. (2022). Estimation of low rank high-dimensional multivariate linear models for multi-response data. Journal of the American Statistical Association 117 693‚Äì703.\n\nChen, K., Dong, H. and Chan, K.-S. (2012). Reduced rank regression via adaptive nuclear norm penalization. arXiv preprint arXiv:1201.0381 .\n\nChen, X., Zou, C. and Cook, R. D. (2010). Coordinate-independent sparse sufficient dimension reduction and variable selection. The Annals of Statistics 38 3696 ‚Äì 3723.\n\nDamian, A., Lee, J. and Soltanolkotabi, M. (2022). Neural networks can learn representations with gradient descent. In Conference on Learning Theory.\n\nFriedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American Statistical Association 76 817‚Äì823.\n\nHui Zou, T. H. and Tibshirani, R. (2006). Sparse principal component analysis. Journal of Computational and Graphical Statistics 15 265‚Äì286.\n\nHyv√§rinen, A. and Dayan, P. (2005). Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research 6 695‚Äì709.\n\nJanzamin, M., Sedghi, H. and Anandkumar, A. (2014). Score function features for discriminative learning: Matrix and tensor framework. arXiv preprint arXiv:1412.2863 .\n\nKobak, D., Bernaerts, Y., Weis, M. A., Scala, F., Tolias, A. S. and Berens, P. (2021). Sparse reduced-rank regression for exploratory visualisation of paired multivariate data. Journal of the Royal Statistical Society Series C: Applied Statistics 70 980‚Äì1000.\n\nLee, W. and Liu, Y. (2012). Simultaneous multiple response regression and inverse covariance matrix estimation via penalized gaussian maximum likelihood. Journal of Multivariate Analysis 111 241‚Äì255.\n\nLi, K.-C. (1991). Sliced inverse regression for dimension reduction. Journal of the American Statistical Association 86 316‚Äì327.\n\nLi, K.-C. (1992). On principal hessian directions for data visualization and dimension reduction: Another application of stein\'s lemma. Journal of the American Statistical Association 87 1025‚Äì1039.\n\nLi, K.-C. and Duan, N. (1989). Regression analysis under link violation. The Annals of Statistics 1009‚Äì1052.\n\nLi, Y. and Turner, R. E. (2017). Gradient estimators for implicit models. arXiv preprint arXiv:1705.07107 .\n\nLu, Z., Monteiro, R. D. and Yuan, M. (2012). Convex optimization methods for dimension reduction and coefficient estimation in multivariate linear regression. Mathematical Programming 131 163‚Äì194.\n\nMakhzani, A. and Frey, B. (2013). K-sparse autoencoders. arXiv preprint arXiv:1312.5663 .\n\nMeng, C., Song, Y., Li, W. and Ermon, S. (2021). Estimating high order gradients of the data distribution by denoising. Advances in Neural Information Processing Systems 34 25359‚Äì25369.\n\nMousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. and Erdogdu, M. A. (2022).\nNeural networks efficiently learn low-dimensional representations with sgd. arXiv preprint\narXiv:2209.14863 .\n\nMukherjee, A. and Zhu, J. (2011). Reduced rank ridge regression and its kernel extensions.\nStatistical analysis and data mining: the ASA data science journal 4 612‚Äì622.\n\nO\'Rourke, S., Vu, V. and Wang, K. (2018). Random perturbation of low rank matrices:\nImproving classical bounds. Linear Algebra and its Applications 540 26‚Äì59.\n\nPearson, K. (1901). Liii. on lines and planes of closest fit to systems of points in space. The\nLondon, Edinburgh, and Dublin philosophical magazine and journal of science 2 559‚Äì572.\n\nRifai, S., Vincent, P., Muller, X., Glorot, X. and Bengio, Y. (2011). Contractive auto-\nencoders: Explicit invariance during feature extraction. In Proceedings of the 28th international\nconference on international conference on machine learning.\n\nScala, F., Kobak, D., Bernabucci, M., Bernaerts, Y., Cadwell, C. R., Castro, J. R.,\nHartmanis, L., Jiang, X., Laturnus, S., Miranda, E. et al. (2021). Phenotypic variation\nof transcriptomic cell types in mouse motor cortex. Nature 598 144‚Äì150.\n\nShi, J., Sun, S. and Zhu, J. (2018). A spectral approach to gradient estimation for implicit\ndistributions. In International Conference on Machine Learning.\n\nSimon, N., Friedman, J. and Hastie, T. (2013). A blockwise descent algorithm for group-\npenalized multiresponse and multinomial regression. arXiv preprint arXiv:1311.6529 .\n\nSong, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data\ndistribution. Advances in neural information processing systems 32.\n\nSong, Y., Garg, S., Shi, J. and Ermon, S. (2020). Sliced score matching: A scalable approach\nto density and score estimation. In Uncertainty in Artificial Intelligence.\n\nStrathmann, H., Sejdinovic, D., Livingstone, S., Szabo, Z. and Gretton, A. (2015).\nGradient-free hamiltonian monte carlo with efficient kernel exponential families. Advances in\nNeural Information Processing Systems 28 955‚Äì963.\n\nTan, K. M., Wang, Z., Zhang, T., Liu, H. and Cook, R. D. (2018). A convex formulation for\nhigh-dimensional sparse sliced inverse regression. Biometrika 105 769‚Äì782.\n\nVershynin, R. (2018a). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVershynin, R. (2018b). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVincent, P. (2011). A connection between score matching and denoising autoencoders. Neural\ncomputation 23 1661‚Äì1674.\n\nVincent, P., Larochelle, H., Bengio, Y. and Manzagol, P.-A. (2008). Extracting and\ncomposing robust features with denoising autoencoders. In Proceedings of the 25th international\nconference on Machine learning.\n\nWANG, W., LIANG, Y. and XING, E. (2013). Block regularized lasso for multivariate multi-response linear regression. In Artificial intelligence and statistics.\n\nXU, X. (2020). On the perturbation of the moore‚Äìpenrose inverse of a matrix. Applied Mathematics and Computation 374 124920.\n\nYANG, Z., BALASUBRAMANIAN, K. and LIU, H. (2017a). High-dimensional non-Gaussian single index models via thresholded score function estimation. In Proceedings of the 34th International Conference on Machine Learning, vol. 70.\n\nYANG, Z., BALASUBRAMANIAN, K., WANG, Z. and LIU, H. (2017b). Learning non-gaussian multi-index model via second-order stein\'s method. Advances in Neural Information Processing Systems 30 6097‚Äì6106.\n\nYU, Y., WANG, T. and SAMWORTH, R. J. (2015). A useful variant of the davis‚Äìkahan theorem for statisticians. Biometrika 102 315‚Äì323.\n\nYUAN, M., EKICI, A., LU, Z. and MONTEIRO, R. (2007). Dimension reduction and coefficient estimation in multivariate linear regression. Journal of the Royal Statistical Society Series B: Statistical Methodology 69 329‚Äì346.\n\nZHOU, Y., SHI, J. and ZHU, J. (2020). Nonparametric score estimators. In International Conference on Machine Learning.\n\n17\n\nSupplementary Material for\n"Nonlinear Multiple Response Regression and Learning of Latent Spaces"\n\nYe Tian, Sanyou Wu and Long Feng', 'similarity': 0.8253905773162842}], 'cnn2': [{'text': '', 'similarity': 0.8390400409698486}], 'cnn4': [{'text': 'Convolutional Neural Networks (CNNs) have revolutionized the field of deep learning, especially in processing grid-like data structures such as images [1]. Their effectiveness in tasks like image classification [2, 3], object detection [4, 5], semantic segmentation [6, 7] and image generation [8] stem from their ability to effectively learn spatial features. Convolutional layers, using filters or kernels, capture local patterns and extract features from input images. One important feature of convolutional layers is the shared weights implemented by kernels. This allows for efficient deep learning on images, as using only fully connected layers for such tasks would result in unfathomable numbers of parameters. Pooling layers, like max pooling and average pooling, reduce the spatial dimensions of these features, helping the network to focus on the most significant aspects.\n\nDespite their popularity, CNNs face challenges in computational efficiency and adaptability. There have been several convolutional neural network architectures that have been proposed that are aimed at efficiency. Some of such architectures include MobileNet [12] and EfficientNet [13]. However, such traditional CNNs, with fixed architectures and number of parameters, may not perform uniformly across different types of input data with varying levels of complexity.\n\nNeural Architecture Search (NAS), a method for selecting optimal neural network architectures, has been a response to this challenge. NAS aims to obtain the best model for a specific task under certain constraints [14]. However, NAS is often resource-intensive due to the need to train multiple candidate models. in order to determine the optimal architecture. It is estimated that the carbon emission produced when using NAS to train a transformer model can amount to five times the lifetime carbon emissions of an average car [15]. This highlights the importance of finding suitable\n\narchitectures for neural networks, yet also points to the limitations of current approaches in terms of static structure and proneness to over-parameterization.\n\nSelf Expanding Neural Networks (SENN), introduced in [9], offer a promising direction. Inspired by neurogenesis, SENN dynamically adds neurons and fully connected layers to the architecture during training using a natural expansion score (defined in section 2.1) as a criteria to guide this process. This helps overcome the problem of over-parametrization. However, its application has been limited to multilayer perceptrons, with extensions to more practical architectures like CNNs identified as a future research prospect.\n\nOur study aims to develop a Self Expanding Convolutional Neural Network (SECNN), building on the concept of SENN and applying it to modern vision tasks. To the best of our knowledge, there has been no research on Self Expanding CNNs, despite the potential they hold for addressing model efficiency and adaptability in vision tasks. Unlike existing approaches that often require restarting training after modifications or rely on preset mechanisms for expansion, our approach utilizes the natural expansion score for dynamic and optimal model expansion. This research represents a significant step in developing adaptable, efficient CNN models for a variety of vision-related tasks.\n\nThe contributions of this research are as follows:\n\n- Developing a Self Expanding CNN that dynamically determines the optimal model size based on the task, thereby enhancing efficiency.\n- Eliminating the need to train multiple CNN models of varying sizes by allowing for the extraction of checkpoints at diverse complexity levels.\n- Eliminating the need to restart the training process after expanding the CNN model.', 'similarity': 0.8390400409698486}], 'pdf1': [{'text': "Autonomous underwater vehicles (AUVs) are valuable tools for exploring and operating underwater. They are used in a wide range of applications, including seafloor mapping, underwater construction and inspection, environmental monitoring, and studying marine life [1], [2]. To accomplish their task accurately and robustly, precise navigation is required. Commonly, this is achieved by fusing inertial sensors with a Doppler velocity log (DVL) [3]. The DVL is an acoustic sensor that utilizes the Doppler effect. This device transmits four acoustic beams to the seafloor, which are then reflected back. Based on the frequency shift, the DVL calculates the velocity of each beam and then estimates the velocity vector of the AUV [4].\n\nData-driven methods have been employed in AUV-related tasks with promising outcomes [5]‚Äì[9]. DCNet, a data-driven framework that utilizes a two-dimensional convolution kernel in an innovative way, demonstrated its ability to improve the process of DVL calibration [10]. Deep-learning frameworks have been used to estimate real-world scenarios of missing DVL beams in partial and complete outage scenarios [11], [12]. Additionally, when all beams are available, the BeamsNet approach [13] offers a more accurate and robust velocity solution using a dedicated deep-learning framework. Deep learning methods were suggested for the fusion process to adaptively estimate the process noise covariance in the inertial DVL fusion process [14], [15]. Recently, an end-to-end deep learning approach was suggested to estimate the AUV acceleration vector, which is introduced to the navigation filter as an additional measurement [16]. In normal operating conditions of the DVL, the BeamsNet approach outperforms model-based approaches. This method employs both inertial measurements and past DVL measurements to estimate the current velocity vector. When updating the navigation filter with this measurement, a cross-correlation arises between the BeamsNet velocity vector measurement and the inertial-based process noise. This process-measurement cross-correlation matrix should be taken into account in the navigation filter to obtain a desired matched filter [17].\n\nIn this paper, we employ the inertial/DVL navigation filter based on the extended Kalman filter (EKF), taking into account the process-measurement cross-correlation matrix. The latter is calculated using the inertial and BeamsNet error sources. Using two real-world underwater AUV datasets, we show the necessity of the cross-correlation matrix to allow filter consistency and robustness.\n\nThe rest of the paper is organized as follows: Section II formulates the problem and presents the theoretical foundation for incorporating cross-correlations within the extended Kalman filter. Section III introduces the proposed cross-correlation-aware deep INS/DVL fusion framework, detailing the integration of BeamsNet with a modified filter formulation. Section IV presents the experimental results and performance analysis based on real-world AUV trajectories. Finally, Section V concludes the findings in the paper.\n\n*Corresponding author: N. Cohen (email: ncohe140@campus.haifa.ac.il).\n\nII. PROBLEM FORMULATION\n\nA. EKF with Correlated Noise\n\nIn the classical derivation of the error-state EKF, it is typically assumed that the process noise and measurement noise are uncorrelated. This is due to the fact that the different sensors provide the information for the process and update. However, in some cases, like the one we introduce in this paper, non-negligible cross-correlations may exist between the process and measurement noise terms. In this section, we present an error-state EKF framework that accounts for such correlation, following the modified Kalman filter equations that explicitly incorporate this dependency.\n\nLet the system dynamics and measurement model be described by the discrete-time equations [18], [19]:\n\n$$x_k = F_{k-1}x_{k-1} + G_{k-1}w_{k-1},$$\n\nwhere $x_k$ denotes the system state vector at time step $k$, $F_{k-1}$ is the state transition matrix that propagates the state from time $k - 1$ to $k$, and $G_{k-1}$ is the process noise input matrix.\n\nThe measurement model is:\n\n$$y_k = H_kx_k + v_k,$$\n\nwhere, $y_k$ is the measurement vector at time step $k$ and $H_k$ is the observation matrix that maps the state vector to the measurement space. Additionally, $w_k \\sim N(0, Q_k)$ denotes the process noise with associated process noise covariance $Q_k$, and $v_k \\sim N(0, R_k)$ denotes the measurement noise with associated measurement noise covariance $R_k$.\n\nThe cross-correlation matrix between the process and measurement noise covariances is defined as [17]:\n\n$$E[w_kv_j^T] = M_k\\delta_{k-j+1},$$\n\nindicating that the process noise at time $k$ is correlated with the measurement noise at time $k+1$. This structure arises naturally in systems where the same external disturbance influences both the system dynamics and the measurement process, albeit with a one-step time lag.\n\nTo incorporate this cross-correlation into the Kalman gain computation, the innovation covariance must be adjusted such that the Kalman gain becomes:\n\n$$K_k = (P_k^-H_k^T + M_k) \\cdot (H_kP_k^-H_k^T + H_kM_k + M_k^TH_k^T + R_k)^{-1},$$\n\nwhere $P_k^-$ is the prior error covariance matrix.\n\nConsequently, the posterior error covariance is updated according to:\n\n$$P_k = P_k^- - K_k(H_kP_k^- + M_k^T).$$\n\nThese modified expressions account for the non-zero cross-correlation between process and measurement noise, improving filter consistency in scenarios where this assumption is violated. The rest of the error state EKF equations and process remain the same with the exception of the Kalman gain (4) and can be seen in [20], for example.\n\nB. Cross-Correlation within INS/DVL Fusion\n\nRecent advances in deep learning have demonstrated significant potential in time series estimation and sensor fusion, especially in navigation systems where standard model-based filters often struggle with drift, nonlinearity, or degraded measurement conditions. By leveraging the expressive power of deep neural networks (DNNs), it is possible to model complex dependencies between sensor modalities and capture higher-order temporal patterns in the data. In particular, DNN-based approaches that jointly process inertial and acoustic measurements can yield more accurate velocity estimates than classical extended Kalman filtering alone.\n\nConsider a system where the goal is to estimate the vehicle's velocity using both the inertial sensors, which include accelerometers that provide the specific force vector $f_k \\in \\mathbb{R}^3$ and gyroscopes that measure the angular velocity vector $\\omega_k \\in \\mathbb{R}^3$, and a DVL, which provides beam velocity measurements $z_k^{DVL} \\in \\mathbb{R}^4$. A deep neural network can be trained to produce a fused velocity estimate via a nonlinear function:\n\n$$\\hat{v}_k = \\mathcal{F}_\\theta(f_{k-T:k}, \\omega_{k-T:k}, z_{k-T:k}^{DVL}),$$\n\nwhere $\\mathcal{F}_\\theta(\\cdot)$ denotes the DNN with parameters $\\theta$ and the inputs consist of a temporal window of size $T$. The output $\\hat{v}_k$ is the estimated velocity vector at time $k$, typically expressed in the body frame.\n\nThe challenge arises from the stochastic properties of the inputs. The IMU measurements $f_k$ and $\\omega_k$ are driven by process noise $w_k$, while the DVL beams $z_k^{DVL}$ are corrupted by measurement noise $v_k$. Let us denote:\n\n$$f_k = f_k^{true} + w_k^f$$\n$$\\omega_k = \\omega_k^{true} + w_k^\\omega$$\n$$z_k^{DVL} = z_k^{true} + v_k$$\n\nwhere $w_k^f$ and $w_k^\\omega$ represent the accelerometer and gyroscopes process noise, respectively, and $v_k$ denotes the DVL measurement noise. Due to the nonlinear mapping, $\\mathcal{F}_\\theta(\\cdot)$, the output velocity estimate becomes a complex function of all the noise sources:\n\n$$\\hat{v}_k = \\mathcal{F}_\\theta(f_k^{true} + w_k^f, \\omega_k^{true} + w_k^\\omega, z_k^{true} + v_k).$$\n\nUnlike linear estimators, where uncorrelated inputs lead to uncorrelated outputs, the nonlinear dependency structure in $\\mathcal{F}_\\theta$ causes interactions between $w_k$ and $v_k$. As a result, the effective measurement used for state correction, the output of the DNN, embeds cross-correlations between the process and measurement noise. That is,\n\n$$E[w_kv_k^T] \\neq 0,$$\n\nand the distribution of the estimation error becomes analytically intractable due to the black-box nature of the network. Therefore, when such a fused estimate is used as an update measurement in an error-state EKF, the assumption of noise independence no longer holds. This violates the foundational\n\n\n```mermaid\ngraph LR\nDVL[DVL] --> BeamsNet\nInertial[Inertial Sensors] --> BeamsNet\nBeamsNet --> CrossCorrelation[Cross-Correlation]\nDVL --> EKF\nInertial --> EKF\nCrossCorrelation --> EKF\nEKF --> Position\nEKF --> Velocity\nEKF --> Orientation\n```\n\nFig. 1: Our proposed approach block diagram illustrates how inertial and DVL measurements are utilized as inputs to the BeamsNet framework. This model generates an enhanced velocity vector measurement update, which is then passed, together with the inertial uncertainty, to the cross-correlation block. This block computes the cross-correlation matrix, which is subsequently integrated into the EKF to derive the navigation solution.\n\nassumptions of standard Kalman filtering theory and necessitates either reformulation of the filter to incorporate the cross-covariance or empirical techniques to mitigate its effect.", 'similarity': 0.8322737812995911}], 'pdf3': [{'text': '', 'similarity': 0.8111008405685425}]}, 'Conclusion': {'cnn1': [{'text': 'Convolutional Neural Networks differ to other forms of Artifical Neural Network in that instead of focusing on the entirety of the problem domain, knowledge about the specific type of input is exploited. This in turn allows for a much simpler network architecture to be set up.\n\nThis paper has outlined the basic concepts of Convolutional Neural Networks, explaining the layers required to build one and detailing how best to structure the network in most image analysis tasks.\n\nResearch in the field of image analysis using neural networks has somewhat slowed in recent times. This is partly due to the incorrect belief surrounding the level of complexity and knowledge required to begin modelling these superbly powerful machine learning algorithms. The authors hope that this paper has in some way reduced this confusion, and made the field more accessible to beginners.', 'similarity': 0.9333658218383789}], 'cnn3': [{'text': 'CNNs are considered the gold standard in deep learning-based image analysis. For instance, in biomedical imaging, they overcome the drawbacks of subjective analysis in the semi-quantitative visual inspection of samples (Gurcan et al., 2009), and they support experts\n\n\nFigure 6: Class activation maps (CAMs) of a FF trained CNN show which image regions are considered beneficial (yellow) or deleterious (pink) by the network for making its prediction. (A), (C), (E), and (G) display four input images. (B), (D), (F), and (H) are their corresponding CAMs. All examples are from a network with 16 convolutional neurons per layer, filter size 5x5, and trained with a batch size of 50.\n\n| A | B | C | D |\n|---|---|---|---|\n| 1 | Heatmap | 2 | Heatmap |\n| E | F | G | H |\n| 7 | Heatmap | 9 | Heatmap |\n\nColor scale: -0.04 (purple) to 0.04 (yellow)\n\nFigure 7: Class activation maps show that the different layers of the FF-trained CNN provide similar, but yet distinguishable information. (A) shows the CAM obtained from considering both layer 2 and layer 3 together. (B) and (C) show the CAMs obtained respectively only from layer 2 and layer 3.\n\n| A | B | C |\n|---|---|---|\n| Heatmap | Heatmap | Heatmap |\n\nColor scale: -0.04 (purple) to 0.04 (yellow)\n\nduring their daily clinical routine by reducing their workload (Shmatko et al., 2022). Furthermore, their exploitation of the spatial information within images makes them suitable for the deployment of explainable AI tools (such as class activation maps), which highlight the image regions contributing most significantly to the classification outcome. Our implementation of FF trained CNN shows that with the right choice of hyperparameters, this technique is competitive with backpropagation. These results were obtained without implementing all the possible and suggested optimizations such as enforcing symmetry of the loss function (Lee and Song, 2023) or choosing hard, i.e. easily confused, labels for the negative data set, as suggested by Hinton (2022). We propose that our work shows the\n\nSCODELLARO, KULKARNI, ALVES AND SCHR√ñTER\n\npotential of FF trained CNNs to address real world computer vision problems. An open question remains if this technique will supersede BP in specific applications. We believe that this potential exists, especially in the cases of neuromorphic hardware and unsupervised learning.\n\nA better understanding of the FF training will however also expand our understanding of the generic concept of neuronal information processing in all its breadth from biological systems to reservoir computing. The demonstrated capability to implement class activation maps offers an initial insight into these research topics. Achieving deeper insights will also mean to understand how the two innovations of FF, providing positive and negative labels and computing a locally defined goodness parameter, contribute to its success individually and synergetically (Tosato et al., 2023). Moreover, a better understanding why it is beneficial to exclude the first layer during the goodness computation (c.f. Appendix B) would be desirable. Subsequent work on FF training should also address its ability to train deeper networks, most likely expanding on the work of Lorberbom et al. (2023). Also the ability of FF training to work with larger and more complex data sets needs to be explored. Finally, its connection to biological neuronal systems (Ororbia and Mali, 2023; Ororbia, 2023) seems a promising research direction.', 'similarity': 0.8813095092773438}], 'cnn5': [{'text': "We propose an enhanced CNN architecture tailored specifically for image classification tasks on the CIFAR-10 dataset. This architecture leverages deeper convolutional layers, which enable the model to learn more complex and hierarchical features from the input images. The inclusion of batch normalization plays a critical role in stabilizing the training process by normalizing intermediate feature distributions, thereby mitigating the issue of vanishing or exploding gradients. Dropout layers are strategically integrated into the architecture to address overfitting, ensuring that the model generalizes well to unseen data. These combined enhancements contribute to the model achieving a test accuracy of 84.95%, which represents a significant improvement over standard baseline CNN models.\n\nThe improvements observed with the proposed architecture underscore the importance of refining network design to balance depth, feature extraction capabilities, and regularization techniques. By carefully combining these elements, the model not only improves classification accuracy but also exhibits better robustness and generalization across the diverse image categories within CIFAR-10. These results highlight the potential of enhanced CNNs for tackling image classification tasks that require extracting fine-grained visual features while maintaining computational efficiency.\n\nFuture work will focus on extending this enhanced architecture to more complex datasets such as CIFAR-100, which consists of 100 classes and provides a more challenging testbed for multi-class classification models. Additionally, transfer learning techniques will be explored to adapt the proposed architecture to larger datasets with higher-resolution images, such as ImageNet, or domain-specific datasets, where pre-trained models can be fine-tuned for specialized tasks. These extensions will allow for further evaluation of the architecture's scalability and applicability across a broader range of computer vision problems, paving the way for its integration into practical applications.", 'similarity': 0.9361571669578552}], 'pdf2': [{'text': 'Recent years have witnessed the advent of deep learning methods for structural biology culminating in the award of the Nobel Prize in Chemistry. AlphaFold (Jumper et al., 2021) revolutionized protein structure prediction, equipping the field with millions of new structures. Breakthroughs go beyond structure prediction, notably in protein design (Watson et al., 2023; Dauparas et al., 2022), drug discovery (Schneuing et al., 2024; Corso et al., 2022) or fundamental biology (van Kempen et al., 2022). While it is tempting to attribute the success of these methods to the increase in available structural data caused by AlphaFold, most of the methods are actually not reliant on them. Instead, it seems that these breakthroughs result from progress in training neural encoders that directly model protein structures (Jing et al., 2020; Zhang et al., 2022b; Gainza et al., 2020; Wang et al., 2022). This progress is in turn rooted in solid competitions (CASP, CAPRI), and benchmarks (Townshend et al., 2021a; Kucera et al., 2023; Zhu et al., 2022; Jamasb et al., 2024; Notin et al., 2023). By setting clear goals, such benchmarks are the foundation for the development of structure encoders. Yet to date, structure-function benchmarks have focused on proteins.\n\nRibonucleic acids (RNAs) are a large family of molecules which support biological functions along every branch of the tree of life. Besides messenger RNAs, non-coding RNAs carry out biological functions by adopting complex 3D folds (Cech & Steitz, 2014) like proteins do and take up diverse roles in cellular functions, including gene regulation, RNA processing, and protein synthesis (Statello et al., 2021). However, our understanding of non-coding RNAs and their functions remains limited. This can be largely attributed to the negatively charged nature of RNA backbones, which makes it flexible and limits the availability of high-resolution RNA structures, and imposes significant modeling challenges. Another predominant challenge to a functional understanding of RNA 3D structure lies in the lack of infrastructure for the development and evaluation of function prediction models. In this work, we propose a benchmarking suite to act as this facilitating framework.\n\nOur key contributions include:\n\n- Seven tasks related to RNA 3D structure that represent various biological challenges. Each task consists of a dataset, a splitting strategy, and an evaluation method, laying the ground for comparable, reproducible model development.\n\n- End-to-end reproducible and modular access to task data. Modular annotators, filters and splitting strategies, both novel and from existing literature, facilitate the addition of new tasks by other researchers across fields.\n\n*Equal contribution ‚Ä†Equal supervision 1Max Planck Institute of Biochemistry, Munich, Germany 2Mines Paris, PSL Research University, CBIO, Paris, France 3Vanderbilt University, Nashville, Tennessee, USA. Correspondence to: Luis Wyss <wyss@biochem.mpg.de>.\n\nA preprint.\n\nBenchmark for RNA 3D Structure Modeling', 'similarity': 0.8349259495735168}], 'pdf4': [{'text': 'Balasubramanian, K., Fan, J. and Yang, Z. (2018). Tensor methods for additive index models under discordance and heterogeneity. arXiv preprint arXiv:1807.06693 .\n\nBauer, B. and Kohler, M. (2019). On deep learning as a remedy for the curse of dimensionality in nonparametric regression. The Annals of Statistics 47 2261‚Äì2285.\n\nBauer, F., Pereverzev, S. and Rosasco, L. (2007). On regularization algorithms in learning theory. Journal of complexity 23 52‚Äì72.\n\nBreymann, W. and L√ºthi, D. (2013). ghyp: A package on generalized hyperbolic distributions. Manual for R Package ghyp .\n\nCandes, E. J., Li, X., Ma, Y. and Wright, J. (2009). Robust principal component analysis? arXiv preprint arXiv: 0912.3599 .\n\nChangliang Zou, Y. K. and Zhang, W. (2022). Estimation of low rank high-dimensional multivariate linear models for multi-response data. Journal of the American Statistical Association 117 693‚Äì703.\n\nChen, K., Dong, H. and Chan, K.-S. (2012). Reduced rank regression via adaptive nuclear norm penalization. arXiv preprint arXiv:1201.0381 .\n\nChen, X., Zou, C. and Cook, R. D. (2010). Coordinate-independent sparse sufficient dimension reduction and variable selection. The Annals of Statistics 38 3696 ‚Äì 3723.\n\nDamian, A., Lee, J. and Soltanolkotabi, M. (2022). Neural networks can learn representations with gradient descent. In Conference on Learning Theory.\n\nFriedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American Statistical Association 76 817‚Äì823.\n\nHui Zou, T. H. and Tibshirani, R. (2006). Sparse principal component analysis. Journal of Computational and Graphical Statistics 15 265‚Äì286.\n\nHyv√§rinen, A. and Dayan, P. (2005). Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research 6 695‚Äì709.\n\nJanzamin, M., Sedghi, H. and Anandkumar, A. (2014). Score function features for discriminative learning: Matrix and tensor framework. arXiv preprint arXiv:1412.2863 .\n\nKobak, D., Bernaerts, Y., Weis, M. A., Scala, F., Tolias, A. S. and Berens, P. (2021). Sparse reduced-rank regression for exploratory visualisation of paired multivariate data. Journal of the Royal Statistical Society Series C: Applied Statistics 70 980‚Äì1000.\n\nLee, W. and Liu, Y. (2012). Simultaneous multiple response regression and inverse covariance matrix estimation via penalized gaussian maximum likelihood. Journal of Multivariate Analysis 111 241‚Äì255.\n\nLi, K.-C. (1991). Sliced inverse regression for dimension reduction. Journal of the American Statistical Association 86 316‚Äì327.\n\nLi, K.-C. (1992). On principal hessian directions for data visualization and dimension reduction: Another application of stein\'s lemma. Journal of the American Statistical Association 87 1025‚Äì1039.\n\nLi, K.-C. and Duan, N. (1989). Regression analysis under link violation. The Annals of Statistics 1009‚Äì1052.\n\nLi, Y. and Turner, R. E. (2017). Gradient estimators for implicit models. arXiv preprint arXiv:1705.07107 .\n\nLu, Z., Monteiro, R. D. and Yuan, M. (2012). Convex optimization methods for dimension reduction and coefficient estimation in multivariate linear regression. Mathematical Programming 131 163‚Äì194.\n\nMakhzani, A. and Frey, B. (2013). K-sparse autoencoders. arXiv preprint arXiv:1312.5663 .\n\nMeng, C., Song, Y., Li, W. and Ermon, S. (2021). Estimating high order gradients of the data distribution by denoising. Advances in Neural Information Processing Systems 34 25359‚Äì25369.\n\nMousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. and Erdogdu, M. A. (2022).\nNeural networks efficiently learn low-dimensional representations with sgd. arXiv preprint\narXiv:2209.14863 .\n\nMukherjee, A. and Zhu, J. (2011). Reduced rank ridge regression and its kernel extensions.\nStatistical analysis and data mining: the ASA data science journal 4 612‚Äì622.\n\nO\'Rourke, S., Vu, V. and Wang, K. (2018). Random perturbation of low rank matrices:\nImproving classical bounds. Linear Algebra and its Applications 540 26‚Äì59.\n\nPearson, K. (1901). Liii. on lines and planes of closest fit to systems of points in space. The\nLondon, Edinburgh, and Dublin philosophical magazine and journal of science 2 559‚Äì572.\n\nRifai, S., Vincent, P., Muller, X., Glorot, X. and Bengio, Y. (2011). Contractive auto-\nencoders: Explicit invariance during feature extraction. In Proceedings of the 28th international\nconference on international conference on machine learning.\n\nScala, F., Kobak, D., Bernabucci, M., Bernaerts, Y., Cadwell, C. R., Castro, J. R.,\nHartmanis, L., Jiang, X., Laturnus, S., Miranda, E. et al. (2021). Phenotypic variation\nof transcriptomic cell types in mouse motor cortex. Nature 598 144‚Äì150.\n\nShi, J., Sun, S. and Zhu, J. (2018). A spectral approach to gradient estimation for implicit\ndistributions. In International Conference on Machine Learning.\n\nSimon, N., Friedman, J. and Hastie, T. (2013). A blockwise descent algorithm for group-\npenalized multiresponse and multinomial regression. arXiv preprint arXiv:1311.6529 .\n\nSong, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data\ndistribution. Advances in neural information processing systems 32.\n\nSong, Y., Garg, S., Shi, J. and Ermon, S. (2020). Sliced score matching: A scalable approach\nto density and score estimation. In Uncertainty in Artificial Intelligence.\n\nStrathmann, H., Sejdinovic, D., Livingstone, S., Szabo, Z. and Gretton, A. (2015).\nGradient-free hamiltonian monte carlo with efficient kernel exponential families. Advances in\nNeural Information Processing Systems 28 955‚Äì963.\n\nTan, K. M., Wang, Z., Zhang, T., Liu, H. and Cook, R. D. (2018). A convex formulation for\nhigh-dimensional sparse sliced inverse regression. Biometrika 105 769‚Äì782.\n\nVershynin, R. (2018a). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVershynin, R. (2018b). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVincent, P. (2011). A connection between score matching and denoising autoencoders. Neural\ncomputation 23 1661‚Äì1674.\n\nVincent, P., Larochelle, H., Bengio, Y. and Manzagol, P.-A. (2008). Extracting and\ncomposing robust features with denoising autoencoders. In Proceedings of the 25th international\nconference on Machine learning.\n\nWANG, W., LIANG, Y. and XING, E. (2013). Block regularized lasso for multivariate multi-response linear regression. In Artificial intelligence and statistics.\n\nXU, X. (2020). On the perturbation of the moore‚Äìpenrose inverse of a matrix. Applied Mathematics and Computation 374 124920.\n\nYANG, Z., BALASUBRAMANIAN, K. and LIU, H. (2017a). High-dimensional non-Gaussian single index models via thresholded score function estimation. In Proceedings of the 34th International Conference on Machine Learning, vol. 70.\n\nYANG, Z., BALASUBRAMANIAN, K., WANG, Z. and LIU, H. (2017b). Learning non-gaussian multi-index model via second-order stein\'s method. Advances in Neural Information Processing Systems 30 6097‚Äì6106.\n\nYU, Y., WANG, T. and SAMWORTH, R. J. (2015). A useful variant of the davis‚Äìkahan theorem for statisticians. Biometrika 102 315‚Äì323.\n\nYUAN, M., EKICI, A., LU, Z. and MONTEIRO, R. (2007). Dimension reduction and coefficient estimation in multivariate linear regression. Journal of the Royal Statistical Society Series B: Statistical Methodology 69 329‚Äì346.\n\nZHOU, Y., SHI, J. and ZHU, J. (2020). Nonparametric score estimators. In International Conference on Machine Learning.\n\n17\n\nSupplementary Material for\n"Nonlinear Multiple Response Regression and Learning of Latent Spaces"\n\nYe Tian, Sanyou Wu and Long Feng', 'similarity': 0.8212827444076538}], 'cnn2': [{'text': 'In this paper, we tried to analyze the properties of convolutional neural networks. A simplified model, the scattering transform was introduced as a first step towards understanding CNN operations. We saw that the feature transformation is built on top of wavelet transforms which separate variations at different scales using a wavelet transform. The analysis of general CNN architectures was not considered in this paper, but even this analysis is only a first step towards a full mathematical understanding of convolutional neural networks.', 'similarity': 0.9318594932556152}], 'cnn4': [{'text': 'In this article, we introduced the Self Expanding Convolutional Neural Network, a dynamically expanding architecture that uses the natural expansion score to optimize model growth. The CIFAR-10 dataset was used to train an initial model consisting over 5 different trials, which resulted in a 84.1% mean validation accuracy. Our model demonstrates how a Self Expanding CNN offers a computationally efficient solution to dynamically determine an optimal architecture for vision tasks while eliminating the need to restart or train multiple models.', 'similarity': 0.9318594932556152}], 'pdf1': [{'text': 'This work introduced a cross-correlation-aware deep INS/DVL fusion framework that integrates the strengths of both data-driven and model-based approaches. First, we built upon a previous work called BeamsNet and showed its robustness to unseen data. Then, by incorporating deep learning-based velocity estimates into an error-state EKF with an explicit cross-covariance model, we achieved a solution that is not only superior in terms of accuracy when compared to the model-based least squares approach but also more consistent and theoretically grounded. The proposed method addresses a critical limitation of traditional EKF formulations, namely the assumption of uncorrelated process and measurement noise, a condition often violated when using data-driven measurements. Our results demonstrate that accounting for these correlations yields improved confidence in state estimates and reduced uncertainty over time.\n\nBeyond its empirical advantages, this approach offers a principled pathway for integrating modern deep learning techniques within the well-established Kalman filtering framework. This synergy is especially crucial in real-time underwater navigation applications, where reliability, robustness, and theoretical soundness are essential for operational success.', 'similarity': 0.9193439483642578}], 'pdf3': [{'text': '', 'similarity': 0.8355896472930908}]}, 'References': {'cnn1': [{'text': '1. Ciresan, D., Meier, U., Schmidhuber, J.: Multi-column deep neural networks for image classification. In: Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. pp. 3642‚Äì3649. IEEE (2012)\n\n2. Cire≈üan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J.: Mitosis detection in breast cancer histology images with deep neural networks. In: Medical Image Computing and Computer-Assisted Intervention‚ÄìMICCAI 2013, pp. 411‚Äì418. Springer (2013)\n\n3. Ciresan, D.C., Meier, U., Masci, J., Maria Gambardella, L., Schmidhuber, J.: Flexible, high performance convolutional neural networks for image classification. In: IJCAI Proceedings-International Joint Conference on Artificial Intelligence. vol. 22, p. 1237 (2011)\n\nIntroduction to Convolutional Neural Networks         11\n\n4. Cire≈üan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J.: Convolutional neural network committees for handwritten character classification. In: Document Analysis and Recognition (ICDAR), 2011 International Conference on. pp. 1135‚Äì1139. IEEE (2011)\n\n5. Egmont-Petersen, M., de Ridder, D., Handels, H.: Image processing with neural networks a review. Pattern recognition 35(10), 2279‚Äì2301 (2002)\n\n6. Farabet, C., Martini, B., Akselrod, P., Talay, S., LeCun, Y., Culurciello, E.: Hardware accelerated convolutional neural networks for synthetic vision systems. In: Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on. pp. 257‚Äì260. IEEE (2010)\n\n7. Hinton, G.: A practical guide to training restricted boltzmann machines. Momentum 9(1), 926 (2010)\n\n8. Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R.: Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580 (2012)\n\n9. Ji, S., Xu, W., Yang, M., Yu, K.: 3d convolutional neural networks for human action recognition. Pattern Analysis and Machine Intelligence, IEEE Transactions on 35(1), 221‚Äì231 (2013)\n\n10. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L.: Large-scale video classification with convolutional neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. pp. 1725‚Äì1732. IEEE (2014)\n\n11. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Advances in neural information processing systems. pp. 1097‚Äì1105 (2012)\n\n12. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural computation 1(4), 541‚Äì551 (1989)\n\n13. LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11), 2278‚Äì2324 (1998)\n\n14. Nebauer, C.: Evaluation of convolutional neural networks for visual recognition. Neural Networks, IEEE Transactions on 9(4), 685‚Äì696 (1998)\n\n15. Simard, P.Y., Steinkraus, D., Platt, J.C.: Best practices for convolutional neural networks applied to visual document analysis. In: null. p. 958. IEEE (2003)\n\n16. Srivastava, N.: Improving neural networks with dropout. Ph.D. thesis, University of Toronto (2013)\n\n17. Szarvas, M., Yoshizawa, A., Yamamoto, M., Ogata, J.: Pedestrian detection with convolutional neural networks. In: Intelligent Vehicles Symposium, 2005. Proceedings. IEEE. pp. 224‚Äì229. IEEE (2005)\n\n18. Szegedy, C., Toshev, A., Erhan, D.: Deep neural networks for object detection. In: Advances in Neural Information Processing Systems. pp. 2553‚Äì2561 (2013)\n\n19. Tivive, F.H.C., Bouzerdoum, A.: A new class of convolutional neural networks (siconnets) and their application of face detection. In: Neural Networks, 2003. Proceedings of the International Joint Conference on. vol. 3, pp. 2157‚Äì2162. IEEE (2003)\n\n20. Zeiler, M.D., Fergus, R.: Stochastic pooling for regularization of deep convolutional neural networks. arXiv preprint arXiv:1301.3557 (2013)\n\n21. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks. In: Computer Vision‚ÄìECCV 2014, pp. 818‚Äì833. Springer (2014)', 'similarity': 1.0000001192092896}], 'cnn3': [{'text': 'We first report the configuration which achieved the highest accuracy, followed by the search through the space of hyperparameters (using only our validation data set) leading to the optimal configuration. We close by demonstrating the ability of FF trained CNNs to implement Class Activation Maps, which is a method from the explainable AI toolbox.', 'similarity': 0.8359439373016357}], 'cnn5': [{'text': '1. Cheng, Qisen and Qu, Shuhui and Lee, Janghwan. "72-3: Deep Learning Based Visual Defect Detection in Noisy and Imbalanced Data." SID Symposium Digest of Technical Papers, vol. 53, no. 1, pp. 971-974, 2022.\n\n2. Cheng, Qisen and Zhang, Chang and Shen, Xiang. "Estimation of Energy and Time Usage in 3D Printing With Multimodal Neural Network." 2022 4th International Conference on Frontiers Technology of Information and Computer (ICFTIC), pp. 900-903, 2022.\n\n3. Cifar10 Dataset. [online]. Avaiable:https://www.cs.toronto.edu/ kriz/cifar.html.\n\n4. Xing, Jinming. "Enhancing Link Prediction with Fuzzy Graph Attention Networks and Dynamic Negative Sampling." arXiv preprint arXiv:2411.07482 (2024).\n\n5. Veliƒçkoviƒá, Petar, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. "Graph attention networks." arXiv preprint arXiv:1710.10903 (2017).\n\n6. Hamilton, Will, Zhitao Ying, and Jure Leskovec. "Inductive representation learning on large graphs." Advances in neural information processing systems 30 (2017).\n\n7. Xing, Jinming, Can Gao, and Jie Zhou. "Weighted fuzzy rough sets-based tri-training and its application to medical diagnosis." Applied Soft Computing 124 (2022): 109025.\n\n8. Gao, Can, Jie Zhou, Jinming Xing, and Xiaodong Yue. "Parameterized maximum-entropy-based three-way approximate attribute reduction." International Journal of Approximate Reasoning 151 (2022): 85-100.\n\n9. Xing, Jinming, Ruilin Xing, and Yan Sun. "FGATT: A Robust Framework for Wireless Data Imputation Using Fuzzy Graph Attention Networks and Transformer Encoders." arXiv preprint arXiv:2412.01979 (2024).\n\n10. S. R. Livingstone and F. A. Russo, "The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)," PloS one, vol. 13, no. 5, p. e0196391, 2018. Available: https://zenodo.org/record/1188976\n\n11. Xing, Jinming, Dongwen Luo, Qisen Cheng, Chang Xue, and Ruilin Xing. "Multi-view Fuzzy Graph Attention Networks for Enhanced Graph Learning." arXiv preprint arXiv:2412.17271 (2024).\n\n12. G. Heigold, I. L. Moreno, S. Bengio, and N. Shazeer, "End-to-End Text-Dependent Speaker Verification," in Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2016, pp. 5115‚Äì5119.\n\n13. S. Hochreiter and J. Schmidhuber, "Long Short-Term Memory," Neural Computation, vol. 9, no. 8, pp. 1735‚Äì1780, 1997.\n\n14. F. A. Gers, J. Schmidhuber, and F. Cummins, "Learning to Forget: Continual Prediction with LSTM," Neural Computation, vol. 12, no. 10, pp. 2451‚Äì2471, 2000.\n\n15. Xing, Jinming, Ruilin Xing, and Yan Sun. "Comparative Analysis of Pooling Mechanisms in LLMs: A Sentiment Analysis Perspective." arXiv preprint arXiv:2411.14654 (2024).', 'similarity': 1.0000001192092896}], 'pdf2': [{'text': 'Abulwerdi, F. A., Xu, W., Ageeli, A. A., Yonkunas, M. J., Arun, G., Nam, H., Schneekloth Jr, J. S., Dayie, T. K., Spector, D., Baird, N., et al. Selective small-molecule targeting of a triple helix encoded by the long noncoding rna, malat1. ACS chemical biology, 14(2):223‚Äì235, 2019.\n\nAdamczyk, B., Antczak, M., and Szachniuk, M. Rnasolo: a repository of cleaned pdb-derived rna 3d structures. Bioinformatics, 38(14):3668‚Äì3670, 2022.\n\nAlam, T., Uludag, M., Essack, M., Salhi, A., Ashoor, H., Hanks, J. B., Kapfer, C., Mineta, K., Gojobori, T., and Bajic, V. B. Farna: knowledgebase of inferred functions of non-coding rna transcripts. Nucleic acids research, 45 (5):2838‚Äì2848, 2017.\n\nAnand, R., Joshi, C. K., Morehead, A., Jamasb, A. R., Harris, C., Mathis, S. V., Didi, K., Hooi, B., and Lio, P. Rnaframeflow: Flow matching for de novo 3d rna backbone design. arXiv preprint arXiv:2406.13839, 2024.\n\nAshburner, M., Ball, C. A., Blake, J. A., Botstein, D., Butler, H., Cherry, J. M., Davis, A. P., Dolinski, K., Dwight, S. S., Eppig, J. T., et al. Gene ontology: tool for the unification of biology. Nature genetics, 25(1):25‚Äì29, 2000.\n\nBecquey, L., Angel, E., and Tahi, F. Rnanet: an automatically built dual-source dataset integrating homologous sequences and rna structures. Bioinformatics, 37(9):1218‚Äì1224, 2021.\n\nBoccaletto, P., Stefaniak, F., Ray, A., Cappannini, A., Mukherjee, S., Purta, E., Kurkowska, M., Shirvanizadeh, N., Destefanis, E., Groza, P., et al. Modomics: a database of rna modification pathways. 2021 update. Nucleic acids research, 50(D1):D231‚ÄìD235, 2022.\n\nButtenschoen, M., Morris, G. M., and Deane, C. M. Posebusters: Ai-based docking methods fail to generate physically valid poses or generalise to novel sequences. Chemical Science, 15(9):3130‚Äì3139, 2024.\n\nCarvajal-Patino, J. G., Mallet, V., Becerra, D., Ni√±o Vasquez, L. F., Oliver, C., and Waldisp√ºhl, J. Rnamigos2: accelerated structure-based rna virtual screening with deep graph learning. Nature Communications, 16(1):1‚Äì12, 2025.\n\nCech, T. R. and Steitz, J. A. The noncoding rna revolution‚Äîtrashing old rules to forge new ones. Cell, 157(1): 77‚Äì94, 2014.\n\nCorso, G., St√§rk, H., Jing, B., Barzilay, R., and Jaakkola, T. Diffdock: Diffusion steps, twists, and turns for molecular docking. arXiv preprint arXiv:2210.01776, 2022.\n\nDauparas, J., Anishchenko, I., Bennett, N., Bai, H., Ragotte, R. J., Milles, L. F., Wicky, B. I., Courbet, A., de Haas, R. J., Bethel, N., et al. Robust deep learning‚Äìbased protein sequence design using proteinmpnn. Science, 378 (6615):49‚Äì56, 2022.\n\nDisney, M. D. Targeting rna with small molecules to capture opportunities at the intersection of chemistry, biology, and medicine. Journal of the American Chemical Society, 141 (17):6776‚Äì6790, 2019.\n\nDurairaj, J., Adeshina, Y., Cao, Z., Zhang, X., Oleinikovas, V., Duignan, T., McClure, Z., Robin, X., Kovtun, D., Rossi, E., et al. Plinder: The protein-ligand interactions dataset and evaluation resource. bioRxiv, pp. 2024‚Äì07, 2024.\n\nFalese, J. P., Donlic, A., and Hargrove, A. E. Targeting rna with small molecules: from fundamental principles towards the clinic. Chemical Society Reviews, 50(4): 2224‚Äì2243, 2021.\n\nFu, L., Niu, B., Zhu, Z., Wu, S., and Li, W. Cd-hit: accelerated for clustering the next-generation sequencing data. Bioinformatics, 28(23):3150‚Äì3152, 2012.\n\nGainza, P., Sverrisson, F., Monti, F., Rodol√†, E., Boscaini, D., Bronstein, M., and Correia, B. Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning. Nature Methods, 17(2):184‚Äì192, 2020.\n\nGligorijevic, V., Renfrew, P. D., Kosciolek, T., Leman, J. K., Berenberg, D., Vatanen, T., Chandler, C., Taylor, B. C., Fisk, I. M., Vlamakis, H., et al. Structure-based protein function prediction using graph convolutional networks. Nature communications, 12(1):3168, 2021.\n\nGlisovic, T., Bachorik, J. L., Yong, J., and Dreyfuss, G. Rna-binding proteins and post-transcriptional gene regulation. FEBS letters, 582(14):1977‚Äì1986, 2008.\n\nGriffiths-Jones, S., Bateman, A., Marshall, M., Khanna, A., and Eddy, S. R. Rfam: an rna family database. Nucleic acids research, 31(1):439‚Äì441, 2003.\n\nHaga, C. L. and Phinney, D. G. Strategies for targeting rna with small molecule drugs. Expert Opinion on Drug Discovery, 18(2):135‚Äì147, 2023.\n\nHou, J., Adhikari, B., and Cheng, J. Deepsf: deep convolutional neural network for mapping protein sequences to folds. Bioinformatics, 34(8):1295‚Äì1303, 2018.\n\nBenchmark for RNA 3D Structure Modeling\n\nHuang, H., Lin, Z., He, D., Hong, L., and Li, Y. Ribodiffusion: tertiary structure-based rna inverse folding with generative diffusion models. Bioinformatics, 40 (Supplement 1):i347‚Äìi356, 2024.\n\nJamasb, A. R., Morehead, A., Joshi, C. K., Zhang, Z., Didi, K., Mathis, S., Harris, C., Tang, J., Cheng, J., Lio, P., et al. Evaluating representation learning on the protein structure universe. ArXiv, pp. arXiv‚Äì2406, 2024.\n\nJing, B., Eismann, S., Suriana, P., Townshend, R. J., and Dror, R. Learning from protein structure with geometric vector perceptrons. arXiv preprint arXiv:2009.01411, 2020.\n\nJing, B., Eismann, S., Soni, P. N., and Dror, R. O. Equivariant graph neural networks for 3d macromolecular structure, 2021. URL https://arxiv.org/abs/2106.03843.\n\nJoshi, C. K., Jamasb, A. R., Vi√±as, R., Harris, C., Mathis, S. V., Morehead, A., and Lio, P. grnade: Geometric deep learning for 3d rna inverse design. bioRxiv, pp. 2024‚Äì03, 2024.\n\nJumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., Tunyasuvunakool, K., Bates, R., ≈Ω√≠dek, A., Potapenko, A., et al. Highly accurate protein structure prediction with alphafold. Nature, 596(7873):583‚Äì589, 2021.\n\nKouranov, A., Xie, L., de la Cruz, J., Chen, L., Westbrook, J., Bourne, P. E., and Berman, H. M. The rcsb pdb information portal for structural genomics. Nucleic acids research, 34(suppl 1):D302‚ÄìD305, 2006.\n\nKovtun, D., Akdel, M., Goncearenco, A., Zhou, G., Holt, G., Baugher, D., Lin, D., Adeshina, Y., Castiglione, T., Wang, X., et al. Pinder: The protein interaction dataset and evaluation resource. bioRxiv, pp. 2024‚Äì07, 2024.\n\nKucera, T., Oliver, C., Chen, D., and Borgwardt, K. Proteinshake: Building datasets and benchmarks for deep learning on protein structures. In Advances in Neural Information Processing Systems, volume 36, pp. 58277‚Äì58289, 2023.\n\nLeman, J. K., Weitzner, B. D., Lewis, S. M., Adolf-Bryfogle, J., Alam, N., Alford, R. F., Aprahamian, M., Baker, D., Barlow, K. A., Barth, P., et al. Macromolecular modeling and design in rosetta: recent methods and frameworks. Nature methods, 17(7):665‚Äì680, 2020a.\n\nLeman, J. K., Weitzner, B. D., Lewis, S. M., Adolf-Bryfogle, J., Alam, N., Alford, R. F., Aprahamian, M., Baker, D., Barlow, K. A., Barth, P., et al. Macromolecular modeling and design in rosetta: recent methods and frameworks. Nature methods, 17(7):665‚Äì680, 2020b.\n\nLeontis, N. B. and Zirbel, C. L. Nonredundant 3d structure datasets for rna knowledge extraction and benchmarking. RNA 3D structure analysis and prediction, pp. 281‚Äì298, 2012.\n\nLorenz, R., Bernhart, S. H., H√∂ner zu Siederdissen, C., Tafer, H., Flamm, C., Stadler, P. F., and Hofacker, I. L. Viennarna package 2.0. Algorithms for molecular biology, 6:1‚Äì14, 2011.\n\nMitchell, S., OSullivan, M., and Dunning, I. Pulp: a linear programming toolkit for python. The University of Auckland, Auckland, New Zealand, 65:25, 2011.\n\nNori, D. and Jin, W. Rnaflow: Rna structure and sequence design via inverse folding-based flow matching, 2024. URL https://arxiv.org/abs/2405.18768.\n\nNotin, P., Kollasch, A., Ritter, D., van Niekerk, L., Paul, S., Spinner, H., Rollins, N., Shaw, A., Orenbuch, R., Weitzman, R., Frazer, J., Dias, M., Franceschi, D., Gal, Y., and Marks, D. Proteingym: Large-scale benchmarks for protein fitness prediction and design. In Advances in Neural Information Processing Systems, volume 36, pp. 64331‚Äì64379, 2023.\n\nOliver, C., Mallet, V., Gendron, R. S., Reinharz, V., Hamilton, W. L., Moitessier, N., and Waldisp√ºhl, J. Augmented base pairing networks encode rna-small molecule binding preferences. Nucleic acids research, 48(14):7690‚Äì7699, 2020.\n\nOntiveros-Palacios, N., Cooke, E., Nawrocki, E. P., Triebel, S., Marz, M., Rivas, E., Griffiths-Jones, S., Petrov, A. I., Bateman, A., and Sweeney, B. Rfam 15: Rna families database in 2025. Nucleic Acids Research, 53(D1):D258‚ÄìD267, 2025.\n\nPanei, F. P., Torchet, R., Menager, H., Gkeka, P., and Bonomi, M. Hariboss: a curated database of rna-small molecules structures to aid rational drug design. Bioinformatics, 38(17):4185‚Äì4193, 2022.\n\nRen, Y., Chen, Z., Qiao, L., Jing, H., Cai, Y., Xu, S., Ye, P., Ma, X., Sun, S., Yan, H., et al. Beacon: Benchmark for comprehensive rna tasks and language models. Advances in Neural Information Processing Systems, 37:92891‚Äì92921, 2024.\n\nRoundtree, I. A., Evans, M. E., Pan, T., and He, C. Dynamic rna modifications in gene expression regulation. Cell, 169(7):1187‚Äì1200, 2017.\n\nRuiz-Carmona, S., Alvarez-Garcia, D., Foloppe, N., Garmendia-Doval, A. B., Juhos, S., Schmidtke, P., Barril, X., Hubbard, R. E., and Morley, S. D. rdock: A\n\nBenchmark for RNA 3D Structure Modeling\n\nfast, versatile and open source program for docking ligands to proteins and nucleic acids. PLoS Computational Biology, 10:1‚Äì8, 2014. ISSN 15537358. doi: 10.1371/journal.pcbi.1003571.\n\nSchneuing, A., Harris, C., Du, Y., Didi, K., Jamasb, A., Igashov, I., Du, W., Gomes, C., Blundell, T. L., Lio, P., et al. Structure-based drug design with equivariant diffusion models. Nature Computational Science, 4(12): 899‚Äì909, 2024.\n\nStatello, L., Guo, C.-J., Chen, L.-L., and Huarte, M. Gene regulation by long non-coding rnas and its biological functions. Nature reviews Molecular cell biology, 22(2): 96‚Äì118, 2021.\n\nSu, H., Peng, Z., and Yang, J. Recognition of small molecule‚Äìrna binding sites using rna sequence and structure. Bioinformatics, 37(1):36‚Äì42, 2021.\n\nSzikszai, M., Magnus, M., Sanghi, S., Kadyan, S., Bouatta, N., and Rivas, E. Rna3db: A structurally-dissimilar dataset split for training and benchmarking deep learning models for rna structure prediction. Journal of Molecular Biology, pp. 168552, 2024. ISSN 0022-2836. doi: https://doi.org/10.1016/j.jmb.2024.168552.\n\nTan, C., Zhang, Y., Gao, Z., Hu, B., Li, S., Liu, Z., and Li, S. Z. Rdesign: hierarchical data-efficient representation learning for tertiary structure-based rna design. arXiv preprint arXiv:2301.10774, 2023.\n\nTan, C., Zhang, Y., Gao, Z., Cao, H., Li, S., Ma, S., Blanchette, M., and Li, S. Z. R3design: deep tertiary structure-based rna sequence design and beyond. Briefings in Bioinformatics, 26(1):bbae682, 2025.\n\nTownshend, R., V√∂gele, M., Suriana, P., Derry, A., Powers, A., Laloudakis, Y., Balachandar, S., Jing, B., Anderson, B., Eismann, S., Kondor, R., Altman, R., and Dror, R. Atom3d: Tasks on molecules in three dimensions. In Advances in Neural Information Processing Systems, Datasets and Benchmarks, volume 1, 2021a.\n\nTownshend, R. J., Eismann, S., Watkins, A. M., Rangan, R., Karelina, M., Das, R., and Dror, R. O. Geometric deep learning of rna structure. Science, 373(6558):1047‚Äì1051, 2021b.\n\nvan Kempen, M., Kim, S. S., Tumescheit, C., Mirdita, M., Gilchrist, C. L., S√∂ding, J., and Steinegger, M. Foldseek: fast and accurate protein structure search. Biorxiv, pp. 2022‚Äì02, 2022.\n\nVolkov, M., Turk, J.-A., Drizard, N., Martin, N., Hoffmann, B., Gaston-Math√©, Y., and Rognan, D. On the frustration to predict binding affinities from protein‚Äìligand structures with deep neural networks. Journal of medicinal chemistry, 65(11):7946‚Äì7958, 2022.\n\nWang, J., Quan, L., Jin, Z., Wu, H., Ma, X., Wang, X., Xie, J., Pan, D., Chen, T., Wu, T., et al. Multimodrlbp: A deep learning approach for multi-modal rna-small molecule ligand binding sites prediction. IEEE Journal of Biomedical and Health Informatics, 2024.\n\nWang, K., Jian, Y., Wang, H., Zeng, C., and Zhao, Y. Rbind: computational network method to predict rna binding sites. Bioinformatics, 34(18):3131‚Äì3136, 2018.\n\nWang, K., Zhou, R., Wu, Y., and Li, M. Rlbind: a deep learning method to predict rna‚Äìligand binding sites. Briefings in Bioinformatics, 24(1):bbac486, 2023.\n\nWang, L., Liu, H., Liu, Y., Kurtin, J., and Ji, S. Learning hierarchical protein representations via complete 3d graph networks, 2022. URL https://arxiv.org/abs/2207.12600.\n\nWang, R., Fang, X., Lu, Y., Yang, C.-Y., and Wang, S. The pdbbind database: methodologies and updates. Journal of medicinal chemistry, 48(12):4111‚Äì4119, 2005a.\n\nWang, R., ueliang Fang, Lu, Y., Yang, C.-Y., and Wang, S. The pdbbind database: Methodologies and updates. Journal of Medicinal Chemistry, 22, 11 2005b. ISSN 4111‚Äì4119. doi: 10.1021/jm048957q.\n\nWatson, J. L., Juergens, D., Bennett, N. R., Trippe, B. L., Yim, J., Eisenach, H. E., Ahern, W., Borst, A. J., Ragotte, R. J., Milles, L. F., et al. De novo design of protein structure and function with rfdiffusion. Nature, 620(7976): 1089‚Äì1100, 2023.\n\nWong, F., He, D., Krishnan, A., Hong, L., Wang, A. Z., Wang, J., Hu, Z., Omori, S., Li, A., Rao, J., et al. Deep generative design of rna aptamers using structural predictions. Nature Computational Science, pp. 1‚Äì11, 2024.\n\nXu, J., Wu, K.-j., Jia, Q.-j., and Ding, X.-f. Roles of mirna and lncrna in triple-negative breast cancer. Journal of Zhejiang University-science b, 21(9):673‚Äì689, 2020.\n\nZeng, P. and Cui, Q. Rsite2: an efficient computational method to predict the functional sites of noncoding rnas. Scientific Reports, 6(1):19016, 2016.\n\nZeng, P., Li, J., Ma, W., and Cui, Q. Rsite: a computational method to identify the functional sites of noncoding rnas. Scientific Reports, 5(1):9179, 2015.\n\nZhang, C., Shine, M., Pyle, A. M., and Zhang, Y. Us-align: universal structure alignments of proteins, nucleic acids, and macromolecular complexes. Nature methods, 19(9): 1109‚Äì1115, 2022a.\n\nZhang, Z., Xu, M., Jamasb, A., Chenthamarakshan, V., Lozano, A., Das, P., and Tang, J. Protein representation learning by geometric structure pretraining. arXiv preprint arXiv:2203.06125, 2022b.\n\n\nZheng, J., Xie, J., Hong, X., and Liu, S. Rmalign: an\nrna structural alignment tool based on a novel scoring\nfunction rmscore. BMC genomics, 20:1‚Äì10, 2019.\n\nZhu, Z., Shi, C., Zhang, Z., Liu, S., Xu, M., Yuan, X.,\nZhang, Y., Chen, J., Cai, H., Lu, J., et al. Torchdrug: A\npowerful and flexible machine learning platform for drug\ndiscovery. arXiv preprint arXiv:2202.08320, 2022.', 'similarity': 1.0000001192092896}], 'pdf4': [{'text': 'Balasubramanian, K., Fan, J. and Yang, Z. (2018). Tensor methods for additive index models under discordance and heterogeneity. arXiv preprint arXiv:1807.06693 .\n\nBauer, B. and Kohler, M. (2019). On deep learning as a remedy for the curse of dimensionality in nonparametric regression. The Annals of Statistics 47 2261‚Äì2285.\n\nBauer, F., Pereverzev, S. and Rosasco, L. (2007). On regularization algorithms in learning theory. Journal of complexity 23 52‚Äì72.\n\nBreymann, W. and L√ºthi, D. (2013). ghyp: A package on generalized hyperbolic distributions. Manual for R Package ghyp .\n\nCandes, E. J., Li, X., Ma, Y. and Wright, J. (2009). Robust principal component analysis? arXiv preprint arXiv: 0912.3599 .\n\nChangliang Zou, Y. K. and Zhang, W. (2022). Estimation of low rank high-dimensional multivariate linear models for multi-response data. Journal of the American Statistical Association 117 693‚Äì703.\n\nChen, K., Dong, H. and Chan, K.-S. (2012). Reduced rank regression via adaptive nuclear norm penalization. arXiv preprint arXiv:1201.0381 .\n\nChen, X., Zou, C. and Cook, R. D. (2010). Coordinate-independent sparse sufficient dimension reduction and variable selection. The Annals of Statistics 38 3696 ‚Äì 3723.\n\nDamian, A., Lee, J. and Soltanolkotabi, M. (2022). Neural networks can learn representations with gradient descent. In Conference on Learning Theory.\n\nFriedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American Statistical Association 76 817‚Äì823.\n\nHui Zou, T. H. and Tibshirani, R. (2006). Sparse principal component analysis. Journal of Computational and Graphical Statistics 15 265‚Äì286.\n\nHyv√§rinen, A. and Dayan, P. (2005). Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research 6 695‚Äì709.\n\nJanzamin, M., Sedghi, H. and Anandkumar, A. (2014). Score function features for discriminative learning: Matrix and tensor framework. arXiv preprint arXiv:1412.2863 .\n\nKobak, D., Bernaerts, Y., Weis, M. A., Scala, F., Tolias, A. S. and Berens, P. (2021). Sparse reduced-rank regression for exploratory visualisation of paired multivariate data. Journal of the Royal Statistical Society Series C: Applied Statistics 70 980‚Äì1000.\n\nLee, W. and Liu, Y. (2012). Simultaneous multiple response regression and inverse covariance matrix estimation via penalized gaussian maximum likelihood. Journal of Multivariate Analysis 111 241‚Äì255.\n\nLi, K.-C. (1991). Sliced inverse regression for dimension reduction. Journal of the American Statistical Association 86 316‚Äì327.\n\nLi, K.-C. (1992). On principal hessian directions for data visualization and dimension reduction: Another application of stein\'s lemma. Journal of the American Statistical Association 87 1025‚Äì1039.\n\nLi, K.-C. and Duan, N. (1989). Regression analysis under link violation. The Annals of Statistics 1009‚Äì1052.\n\nLi, Y. and Turner, R. E. (2017). Gradient estimators for implicit models. arXiv preprint arXiv:1705.07107 .\n\nLu, Z., Monteiro, R. D. and Yuan, M. (2012). Convex optimization methods for dimension reduction and coefficient estimation in multivariate linear regression. Mathematical Programming 131 163‚Äì194.\n\nMakhzani, A. and Frey, B. (2013). K-sparse autoencoders. arXiv preprint arXiv:1312.5663 .\n\nMeng, C., Song, Y., Li, W. and Ermon, S. (2021). Estimating high order gradients of the data distribution by denoising. Advances in Neural Information Processing Systems 34 25359‚Äì25369.\n\nMousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. and Erdogdu, M. A. (2022).\nNeural networks efficiently learn low-dimensional representations with sgd. arXiv preprint\narXiv:2209.14863 .\n\nMukherjee, A. and Zhu, J. (2011). Reduced rank ridge regression and its kernel extensions.\nStatistical analysis and data mining: the ASA data science journal 4 612‚Äì622.\n\nO\'Rourke, S., Vu, V. and Wang, K. (2018). Random perturbation of low rank matrices:\nImproving classical bounds. Linear Algebra and its Applications 540 26‚Äì59.\n\nPearson, K. (1901). Liii. on lines and planes of closest fit to systems of points in space. The\nLondon, Edinburgh, and Dublin philosophical magazine and journal of science 2 559‚Äì572.\n\nRifai, S., Vincent, P., Muller, X., Glorot, X. and Bengio, Y. (2011). Contractive auto-\nencoders: Explicit invariance during feature extraction. In Proceedings of the 28th international\nconference on international conference on machine learning.\n\nScala, F., Kobak, D., Bernabucci, M., Bernaerts, Y., Cadwell, C. R., Castro, J. R.,\nHartmanis, L., Jiang, X., Laturnus, S., Miranda, E. et al. (2021). Phenotypic variation\nof transcriptomic cell types in mouse motor cortex. Nature 598 144‚Äì150.\n\nShi, J., Sun, S. and Zhu, J. (2018). A spectral approach to gradient estimation for implicit\ndistributions. In International Conference on Machine Learning.\n\nSimon, N., Friedman, J. and Hastie, T. (2013). A blockwise descent algorithm for group-\npenalized multiresponse and multinomial regression. arXiv preprint arXiv:1311.6529 .\n\nSong, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data\ndistribution. Advances in neural information processing systems 32.\n\nSong, Y., Garg, S., Shi, J. and Ermon, S. (2020). Sliced score matching: A scalable approach\nto density and score estimation. In Uncertainty in Artificial Intelligence.\n\nStrathmann, H., Sejdinovic, D., Livingstone, S., Szabo, Z. and Gretton, A. (2015).\nGradient-free hamiltonian monte carlo with efficient kernel exponential families. Advances in\nNeural Information Processing Systems 28 955‚Äì963.\n\nTan, K. M., Wang, Z., Zhang, T., Liu, H. and Cook, R. D. (2018). A convex formulation for\nhigh-dimensional sparse sliced inverse regression. Biometrika 105 769‚Äì782.\n\nVershynin, R. (2018a). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVershynin, R. (2018b). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVincent, P. (2011). A connection between score matching and denoising autoencoders. Neural\ncomputation 23 1661‚Äì1674.\n\nVincent, P., Larochelle, H., Bengio, Y. and Manzagol, P.-A. (2008). Extracting and\ncomposing robust features with denoising autoencoders. In Proceedings of the 25th international\nconference on Machine learning.\n\nWANG, W., LIANG, Y. and XING, E. (2013). Block regularized lasso for multivariate multi-response linear regression. In Artificial intelligence and statistics.\n\nXU, X. (2020). On the perturbation of the moore‚Äìpenrose inverse of a matrix. Applied Mathematics and Computation 374 124920.\n\nYANG, Z., BALASUBRAMANIAN, K. and LIU, H. (2017a). High-dimensional non-Gaussian single index models via thresholded score function estimation. In Proceedings of the 34th International Conference on Machine Learning, vol. 70.\n\nYANG, Z., BALASUBRAMANIAN, K., WANG, Z. and LIU, H. (2017b). Learning non-gaussian multi-index model via second-order stein\'s method. Advances in Neural Information Processing Systems 30 6097‚Äì6106.\n\nYU, Y., WANG, T. and SAMWORTH, R. J. (2015). A useful variant of the davis‚Äìkahan theorem for statisticians. Biometrika 102 315‚Äì323.\n\nYUAN, M., EKICI, A., LU, Z. and MONTEIRO, R. (2007). Dimension reduction and coefficient estimation in multivariate linear regression. Journal of the Royal Statistical Society Series B: Statistical Methodology 69 329‚Äì346.\n\nZHOU, Y., SHI, J. and ZHU, J. (2020). Nonparametric score estimators. In International Conference on Machine Learning.\n\n17\n\nSupplementary Material for\n"Nonlinear Multiple Response Regression and Learning of Latent Spaces"\n\nYe Tian, Sanyou Wu and Long Feng', 'similarity': 1.0000001192092896}], 'cnn2': [{'text': '[1] Joakim And√©n and St√©phane Mallat. Deep scattering spectrum. Signal Processing, IEEE Transactions on, 62(16):4114‚Äì4128, 2014.\n\n[2] Joan Bruna and St√©phane Mallat. Invariant scattering convolution networks. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 35(8):1872‚Äì1886, 2013.\n\n[3] Corinna Cortes and Vladimir Vapnik. Support-vector networks. Machine learning, 20(3): 273‚Äì297, 1995.\n\n[4] Joan Bruna Estrach. Scattering representations for recognition.\n\n[5] Kaiser Gerald. A friendly guide to wavelets, 1994.\n\n[6] B Boser Le Cun, John S Denker, D Henderson, Richard E Howard, W Hubbard, and Lawrence D Jackel. Handwritten digit recognition with a back-propagation network. In Advances in neural information processing systems. Citeseer, 1990.\n\n[7] Yann LeCun, L√©on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278‚Äì2324, 1998.\n\n[8] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436‚Äì444, 2015.\n\n[9] St√©phane Mallat. Group invariant scattering. Communications on Pure and Applied Mathematics, 65(10):1331‚Äì1398, 2012.\n\n[10] St√©phane Mallat. Understanding deep convolutional networks. arXiv preprint arXiv:1601.04920, 2016.', 'similarity': 1.0000001192092896}], 'cnn4': [{'text': 'Convolutional Neural Networks (CNNs) have revolutionized the field of deep learning, especially in processing grid-like data structures such as images [1]. Their effectiveness in tasks like image classification [2, 3], object detection [4, 5], semantic segmentation [6, 7] and image generation [8] stem from their ability to effectively learn spatial features. Convolutional layers, using filters or kernels, capture local patterns and extract features from input images. One important feature of convolutional layers is the shared weights implemented by kernels. This allows for efficient deep learning on images, as using only fully connected layers for such tasks would result in unfathomable numbers of parameters. Pooling layers, like max pooling and average pooling, reduce the spatial dimensions of these features, helping the network to focus on the most significant aspects.\n\nDespite their popularity, CNNs face challenges in computational efficiency and adaptability. There have been several convolutional neural network architectures that have been proposed that are aimed at efficiency. Some of such architectures include MobileNet [12] and EfficientNet [13]. However, such traditional CNNs, with fixed architectures and number of parameters, may not perform uniformly across different types of input data with varying levels of complexity.\n\nNeural Architecture Search (NAS), a method for selecting optimal neural network architectures, has been a response to this challenge. NAS aims to obtain the best model for a specific task under certain constraints [14]. However, NAS is often resource-intensive due to the need to train multiple candidate models. in order to determine the optimal architecture. It is estimated that the carbon emission produced when using NAS to train a transformer model can amount to five times the lifetime carbon emissions of an average car [15]. This highlights the importance of finding suitable\n\narchitectures for neural networks, yet also points to the limitations of current approaches in terms of static structure and proneness to over-parameterization.\n\nSelf Expanding Neural Networks (SENN), introduced in [9], offer a promising direction. Inspired by neurogenesis, SENN dynamically adds neurons and fully connected layers to the architecture during training using a natural expansion score (defined in section 2.1) as a criteria to guide this process. This helps overcome the problem of over-parametrization. However, its application has been limited to multilayer perceptrons, with extensions to more practical architectures like CNNs identified as a future research prospect.\n\nOur study aims to develop a Self Expanding Convolutional Neural Network (SECNN), building on the concept of SENN and applying it to modern vision tasks. To the best of our knowledge, there has been no research on Self Expanding CNNs, despite the potential they hold for addressing model efficiency and adaptability in vision tasks. Unlike existing approaches that often require restarting training after modifications or rely on preset mechanisms for expansion, our approach utilizes the natural expansion score for dynamic and optimal model expansion. This research represents a significant step in developing adaptable, efficient CNN models for a variety of vision-related tasks.\n\nThe contributions of this research are as follows:\n\n- Developing a Self Expanding CNN that dynamically determines the optimal model size based on the task, thereby enhancing efficiency.\n- Eliminating the need to train multiple CNN models of varying sizes by allowing for the extraction of checkpoints at diverse complexity levels.\n- Eliminating the need to restart the training process after expanding the CNN model.', 'similarity': 0.8484948873519897}], 'pdf1': [{'text': '[1] J. Nicholson and A. Healey, "The present state of autonomous underwater vehicle (AUV) applications and technologies," Marine Technology Society Journal, vol. 42, no. 1, pp. 44‚Äì51, 2008.\n\n[2] G. Griffiths, Technology and applications of autonomous underwater vehicles, vol. 2. CRC Press, 2002.\n\n[3] P. A. Miller, J. A. Farrell, Y. Zhao, and V. Djapic, "Autonomous underwater vehicle navigation," IEEE Journal of Oceanic Engineering, vol. 35, no. 3, pp. 663‚Äì678, 2010.\n\n[4] D. Rudolph and T. A. Wilson, "Doppler Velocity Log theory and preliminary considerations for design and construction," in 2012 Proceedings of IEEE Southeastcon, pp. 1‚Äì7, IEEE, 2012.\n\n[5] N. Cohen and I. Klein, "Inertial navigation meets deep learning: A survey of current trends and future directions," Results in Engineering, p. 103565, 2024.\n\n[6] F. Zhang, S. Zhao, L. Li, and C. Cao, "Underwater DVL Optimization Network (UDON): A Learning-Based DVL Velocity Optimizing Method for Underwater Navigation," Drones, vol. 9, no. 1, p. 56, 2025.\n\n[7] Liu, Peijia and Wang, Bo and Li, Guanghua and Hou, Dongdong and Zhu, Zhengyu and Wang, Zhongyong, "Sins/dvl integrated navigation method with current compensation using rbf neural network," IEEE Sensors Journal, vol. 22, no. 14, pp. 14366‚Äì14377, 2022.\n\n[8] E. Topini, F. Fanelli, A. Topini, M. Pebody, A. Ridolfi, A. B. Phillips, and B. Allotta, "An experimental comparison of Deep Learning strategies for AUV navigation in DVL-denied environments," Ocean Engineering, vol. 274, p. 114034, 2023.\n\n[9] R. Makam, M. Pramuk, S. Thomas, and S. Sundaram, "Spectrally Normalized Memory Neuron Network Based Navigation for Autonomous Underwater Vehicles in DVL-Denied Environment," in OCEANS 2024-Singapore, pp. 1‚Äì6, IEEE, 2024.\n\n[10] Z. Yampolsky and I. Klein, "DCNet: A data-driven framework for DVL calibration," Applied Ocean Research, vol. 158, p. 104525, 2025.\n\n[11] M. Yona and I. Klein, "MissBeamNet: Learning missing Doppler velocity log beam measurements," Neural Computing and Applications, vol. 36, no. 9, pp. 4947‚Äì4958, 2024.\n\n[12] N. Cohen, Z. Yampolsky, and I. Klein, "Set-transformer BeamsNet for AUV velocity forecasting in complete DVL outage scenarios," in 2023 IEEE Underwater Technology (UT), pp. 1‚Äì6, IEEE, 2023.\n\n[13] N. Cohen and I. Klein, "BeamsNet: A data-driven approach enhancing Doppler velocity log measurements for autonomous underwater vehicle navigation," Engineering Applications of Artificial Intelligence, vol. 114, p. 105216, 2022.\n\n[14] N. Cohen and I. Klein, "Adaptive Kalman-Informed Transformer," Engineering Applications of Artificial Intelligence, vol. 146, p. 110221, 2025.\n\n[15] A. Levy and I. Klein, "Adaptive Neural Unscented Kalman Filter," arXiv preprint arXiv:2503.05490, 2025.\n\n[16] Y. Stolero and I. Klein, "AUV Acceleration Prediction Using DVL and Deep Learning ," arXiv preprint arXiv: 2503.16573, 2025.\n\n[17] D. Simon, Optimal state estimation: Kalman, H infinity, and nonlinear approaches. John Wiley & Sons, 2006.\n\n[18] Y. Bar-Shalom, X. R. Li, and T. Kirubarajan, Estimation with applications to tracking and navigation: theory algorithms and software. John Wiley & Sons, 2004.\n\n[19] P. Groves, Principles of GNSS, Inertial, and Multisensor Integrated Navigation Systems, Second Edition. GNSS/GPS, Artech House, 2013.\n\n[20] J. Farrell, Aided navigation: GPS with high rate sensors. McGraw-Hill, Inc., 2008.', 'similarity': 1.0000001192092896}], 'pdf3': [{'text': 'Alford, L., "Estimating Extreme Responses Using a Non-Uniform Phase Distribution," University of Michigan, Ann Arbor, MI, USA 2008.\n\nBertram, V., Practical Ship Hydrodynamics, 2nd edition, Butterworth-Heinemann ISBN 978-0080971506, 2011.\n\nBishop, R. C., Belknap, W., Turner, C., Simon, B., and Kim, J. H., "Parametric Investigation on the Influence of GM, Roll Damping, and Above-Water Form on the\n\nRoll Response of Model 5613", Naval Surface Warfare Center Carderock Division, West Bethesda, MD, USA, Technical Report 50-TR-2005/027, 2005.\n\nGuth, S., and Sapsis. T., "Analytical and Computational Methods for Non-Gaussian Reliability Analysis of Nonlinear Systems Operating in Stochastic Environments," Massachusetts Institute of Technology, Cambridge, MA, USA 2023.\n\nHochreiter, S., and Schmidhuber, J., "Long Short-Term Memory," Neural Computation, Vol. 9, No. 11, pp 1735-1780, 1997.\n\nKim, D-H., "Design Loads Generator: Estimation of Extreme Environmental Loadings for Ship and Offshore Applications," University of Michigan, Ann Arbor, MI, USA 2012.\n\nLevine, M.D., Edwards, S.J., Howard, D., Weems, K., Sapsis, T., and Pipiras, V., "Multi-Fidelity Data-Adaptive Autonomous Seakeeping," Ocean Engineering, Volume 292, 2024.\n\nLevine, M. D., Belenky, V., and Weems, K. M., "Method for Automated Safe Seakeeping Guidance," Proceedings of the 1À¢·µó International Conference on the Stability and Safety of Ships and Ocean Vehicles, 2021, Glasgow, UK.\n\nLin, W., and Yue, D., "Numerical Solutions for Large Amplitude Ship Motions in the Time-Domain," Proceedings of the 18·µó ∞ Symposium on Naval Hydrodynamics, 1990, Ann Arbor, Michigan, USA.\n\nLonguet-Higgins, M. S., "Statistical Properties of Wave Groups in a Random Sea State," Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences, Vol. 312, No.1521, 1984, pp. 219-250.\n\nReed, A.M., "Predicting Extreme Loads and the Processes for Predicting Them Efficiently," Proceedings of the 1À¢·µó International Conference on the Stability and Safety of Ships and Ocean Vehicles, Glasgow, UK 2021.\n\nShin, Y.S., Belenky, V., Lin, W-M., and Weems, K.M., "Nonlinear Time Domain Simulation Technology for Seakeeping and Wave-Load Analysis for Modern Ship Design," SNAME Transactions, Vol. 111, pp. 557-589, 2003.\n\nWan, Z.Y., Vlachas, P., Koumoutsakos, P., Sapsis, T., "Data-assisted Reduced-Order Modeling of Extreme Events in Complex Dynamical Systems." PLOS ONE, Vol 13, Issue 5, 2018.\n\nWeems, K., and Wundrow, D., "Hybrid Models for the Fast Time-Domain Simulation of Stability Failures in Irregular Waves with Volume based Calculations for Froude-Krylov and Hydrostatic Forces," 13·µó ∞ International Ship Stability Workshop, Brest, France 2013.\n\n7. DISCUSSION\n\nArmin Troesch\nABS Professor Emeritus of Marine and Design\nPerformance\nDeparment of Naval Architecture\nUniversity of Michigan\n\nThe authors are to be congratulated on presenting a well-written paper investigating the application of a neural network method in the estimation of extreme ship responses. As discussed in the paper, extensive Monte Carlo simulations containing rare extreme events are generally not feasible for complex nonlinear systems. As a result, numerous strategies, such as the one described by the authors, have been proposed and developed where ensembles of short time series containing large responses are constructed.\n\nUsing pitch maxima of an ONRT flared hull variant as an example of the method, the authors showed impressive correlation between extreme value PDF\'s based on Snippet LSTM and LAMP simulations. However, pitch motion is characteristic of a "well behaved" nonlinear process in that pitch nonlinearities become apparent in a "regular" fashion with increasing excitation. This allowed the authors to successfully extend the Sea State 5 results to Sea State 6 without additional training.\n\n1. Would the authors please comment (speculate?) on how they expect the multi-fidelity approach with LSTM would work when applied to nonlinear systems that contain possible bifurcations, e.g. vessel capsize.\n\nThe authors also identified potential future applications of the LSTM method.\n\n2. Do they feel that the method is applicable when the nonlinear effect of interest has no SimpleCode equivalent? For example, sonar dome slamming pressures can be estimated using CFD or an impact model in LAMP. How would the authors propose to use the LSTM method on nonlinear processes such as extreme bottom slamming loads?\n\n8. AUTHOR\'S REPLY\n\nThe authors are grateful for Professor Troesch\'s insights and questions. The responses to the questions are below.\n\nQuestion 1: The application of neural networks to problems identifying extremes necessitates a special approach, as discussed in the paper. The basis of the solution was to make the rare events seem less rare by initially identifying candidates for large pitch events in SimpleCode and then only examining a small "snippet" of time around those candidate rare values. In investigating highly nonlinear systems that may contain bifurcations, the basis for the method would still have to apply. That is to say, there would need to be sufficient data including the different domains of attraction in the training set.\n\nA major crux of this application is whether or not the nonlinear dynamics of such an event would be captured in SimpleCode. SimpleCode does include the most important nonlinear effects in the body-nonlinear hydrostatic and Froude-Krylov forces. The training approach would be relatively straight-forward if SimpleCode was able to qualitatively model these excursions into different dynamical domains.\n\nIf SimpleCode was unable to properly model the bifurcations, there are still approaches that would allow for system identification. In Bury et. al (2023), an application identifying the period-doubling bifurcation in chicken heart rates was performed with a deep-learning classifier involving an LSTM. The approach presented involved system inputs that were not directly related as in the SimpleCode-LAMP case, so it stands to reason that with more qualitative knowledge, a similar approach could succeed in the SimpleCode-LAMP framework.\n\nQuestion 2: One major driver in the success of an LSTM network is the relation between the input and output. In the presented case, the high level of correlation between SimpleCode and LAMP resulted in a network that performed well. However, an LSTM network can still perform well even without a process as correlated to LAMP as SimpleCode. In Levine et.al (2024), ship motion statistics generated in LAMP were\n\naccurately captured by an LSTM approach that only used the incident wave profile as input. In this data-driven approach, the standard deviations of heave, roll, and pitch were well estimated ‚Äì most predictions were at least 95% accurate - for various ship speeds, sea states, and relative wave headings.\n\nThat being said, it is unlikely this same approach could be directly applied to the rare event prediction application. In this approach, there must be a way to identify when the large pitch events occur in LAMP. To apply this method to nonlinear processes like extreme bottom slamming loads, an input process that is related and has at least some level of correlation in extremes would need to be identified. One possible candidate for the extreme bottom slamming load response could be relative velocity as predicted by SimpleCode. Of course, further study would need to be performed to investigate the level of correlation and number of events that would have to be considered, as in Figure 7.', 'similarity': 0.8690547347068787}]}, 'Methodology': {'cnn1': [{'text': 'Convolutional Neural Networks differ to other forms of Artifical Neural Network in that instead of focusing on the entirety of the problem domain, knowledge about the specific type of input is exploited. This in turn allows for a much simpler network architecture to be set up.\n\nThis paper has outlined the basic concepts of Convolutional Neural Networks, explaining the layers required to build one and detailing how best to structure the network in most image analysis tasks.\n\nResearch in the field of image analysis using neural networks has somewhat slowed in recent times. This is partly due to the incorrect belief surrounding the level of complexity and knowledge required to begin modelling these superbly powerful machine learning algorithms. The authors hope that this paper has in some way reduced this confusion, and made the field more accessible to beginners.', 'similarity': 0.8373116850852966}], 'cnn3': [{'text': 'This section will first discuss our new technique for labeling the positive and negative data sets, before explaining our implementation of the FF algorithm in detail.', 'similarity': 0.8417863249778748}], 'cnn5': [{'text': '', 'similarity': 0.9286127686500549}], 'pdf2': [{'text': 'Next, we briefly showcase the use of our framework for a simple programmatic access to proposed tasks. In Figure 1, we show how practitioners can access our datasets from Python code, automatically downloading them from Zenodo, choosing a representation (in this example a Pytorch Geometric graph) and directly accessing the data in a simple and reproducible fashion. Additionally, by passing a single flag to our loaders, users can choose to execute all processing logic described here to build to build each task from scratch (end-to-end reproducibility).\n\nDue to the rapid advances in the field, we can expect that additional interesting challenges will arise in the near future, complementary to the seven tasks introduced here. Thanks to the modularity of our tool, additional tasks on RNA can be easily integrated in our framework for future releases. This is illustrated in the documentation at rnaglib.org.\n\nBenchmark for RNA 3D Structure Modeling\n\n```python\nfrom rnaglib.tasks import get_task\nfrom rnaglib.representations import GraphRepresentation\n\ntask = get_task(task_id=\'rna_site\',root=\'example\')\ntask.add_representation(GraphRepresentation(framework="pyg"))\ntask.get_split_loaders()\n\nfor batch in task.train_dataloader:\nrna_graph = batch["graph"]\ntarget = rna_graph.y\n```\n\nFigure 1: Obtaining a machine learning-ready split dataset only requires a few lines of code.', 'similarity': 0.8403574228286743}], 'pdf4': [{'text': 'We consider a nonlinear model of the following form:\n\n$$y_{i,j} = f_j(B^‚ä§x_i) + \\epsilon_{i,j}, j \\in [q], i \\in [n].$$\n\nThroughout the experiment, we fix the rank of B to be r and assume that r is known. The matrix B is generated in two steps: first, we generate B_o ‚àà R^(p√óq), with entries that are i.i.d. samples from a normal distribution N(Œº_o, œÉ_o¬≤); second, we set B = SVD_l,r (B_o). We consider three different multivariate distributions for the input vectors x: multivariate normal distribution N(0, Œ£_N), multivariate hyperbolic distribution H_œá,œà(0, Œ£_H)¬π and multivariate t-distribution t_ŒΩ(0, Œ£_t). Furthermore, we assume that the distributions of x are non-degenerate, meaning the dispersion matrices Œ£_N, Œ£_H, and Œ£_t are all positive definite. The random errors œµ_i,j are independently drawn from N(0, œÉ_œµ¬≤).\n\nWe consider three different mechanisms for generating the link functions. In the first case, we consider linear link functions. Specifically, we let f_j(z) = a_j^‚ä§z, j ‚àà [q].\n\nThen, we investigate two ways of generating nonlinear link functions. We let f_j(z) = a_j^‚ä§m_j(z), j ‚àà [q]¬≤, where each m_j(¬∑) represents a certain element-wise nonlinear function, such as sin(x‚àí1) and (x‚àí1)¬≥. In the second case, for the first half of q functions, we select various functions m_1, ..., m_q/2. For the second half of q functions, we define m_q/2+j as m_j mod (q/2) + m_j mod (q/2)+1, for j ‚àà [q/2].\n\nFinally, we consider a generalized case of the second one. For the first half of q functions, we choose different functions m_1, ..., m_q/2 as in the second case. For the second half of q functions m_q/2+j, j ‚àà [q/2], we sample j‚ÇÅ uniformly from [q/2] and j‚ÇÇ uniformly from [q/2] \\ {j‚ÇÅ}, then we let m_q/2+j := m_j‚ÇÅ + m_j‚ÇÇ.\n\nFor details on the parameters and other elementary functions, please refer to Section II.1 of the Supplement.\n\n¬πMultivariate hyperbolic distribution is often used in economics, with particular application in the fields of modeling financial markets and risk management. We refer to Section in the Supplement II.2 for more details.\n\n¬≤For simplicity, we suppose q is even.', 'similarity': 0.8294923901557922}], 'cnn2': [{'text': 'In this paper, we tried to analyze the properties of convolutional neural networks. A simplified model, the scattering transform was introduced as a first step towards understanding CNN operations. We saw that the feature transformation is built on top of wavelet transforms which separate variations at different scales using a wavelet transform. The analysis of general CNN architectures was not considered in this paper, but even this analysis is only a first step towards a full mathematical understanding of convolutional neural networks.', 'similarity': 0.8467366695404053}], 'cnn4': [{'text': 'In order to develop a dynamically expanding convolutional neural-network architecture, we need an expansion criteria that triggers when to expand the model. The criteria we use is the natural expansion score as defined in section 2.1.', 'similarity': 0.9301211833953857}], 'pdf1': [{'text': 'This work introduced a cross-correlation-aware deep INS/DVL fusion framework that integrates the strengths of both data-driven and model-based approaches. First, we built upon a previous work called BeamsNet and showed its robustness to unseen data. Then, by incorporating deep learning-based velocity estimates into an error-state EKF with an explicit cross-covariance model, we achieved a solution that is not only superior in terms of accuracy when compared to the model-based least squares approach but also more consistent and theoretically grounded. The proposed method addresses a critical limitation of traditional EKF formulations, namely the assumption of uncorrelated process and measurement noise, a condition often violated when using data-driven measurements. Our results demonstrate that accounting for these correlations yields improved confidence in state estimates and reduced uncertainty over time.\n\nBeyond its empirical advantages, this approach offers a principled pathway for integrating modern deep learning techniques within the well-established Kalman filtering framework. This synergy is especially crucial in real-time underwater navigation applications, where reliability, robustness, and theoretical soundness are essential for operational success.', 'similarity': 0.849423348903656}], 'pdf3': [{'text': '', 'similarity': 0.8449831604957581}]}, 'Results': {'cnn1': [{'text': '1. Ciresan, D., Meier, U., Schmidhuber, J.: Multi-column deep neural networks for image classification. In: Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. pp. 3642‚Äì3649. IEEE (2012)\n\n2. Cire≈üan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J.: Mitosis detection in breast cancer histology images with deep neural networks. In: Medical Image Computing and Computer-Assisted Intervention‚ÄìMICCAI 2013, pp. 411‚Äì418. Springer (2013)\n\n3. Ciresan, D.C., Meier, U., Masci, J., Maria Gambardella, L., Schmidhuber, J.: Flexible, high performance convolutional neural networks for image classification. In: IJCAI Proceedings-International Joint Conference on Artificial Intelligence. vol. 22, p. 1237 (2011)\n\nIntroduction to Convolutional Neural Networks         11\n\n4. Cire≈üan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J.: Convolutional neural network committees for handwritten character classification. In: Document Analysis and Recognition (ICDAR), 2011 International Conference on. pp. 1135‚Äì1139. IEEE (2011)\n\n5. Egmont-Petersen, M., de Ridder, D., Handels, H.: Image processing with neural networks a review. Pattern recognition 35(10), 2279‚Äì2301 (2002)\n\n6. Farabet, C., Martini, B., Akselrod, P., Talay, S., LeCun, Y., Culurciello, E.: Hardware accelerated convolutional neural networks for synthetic vision systems. In: Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on. pp. 257‚Äì260. IEEE (2010)\n\n7. Hinton, G.: A practical guide to training restricted boltzmann machines. Momentum 9(1), 926 (2010)\n\n8. Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R.: Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580 (2012)\n\n9. Ji, S., Xu, W., Yang, M., Yu, K.: 3d convolutional neural networks for human action recognition. Pattern Analysis and Machine Intelligence, IEEE Transactions on 35(1), 221‚Äì231 (2013)\n\n10. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L.: Large-scale video classification with convolutional neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. pp. 1725‚Äì1732. IEEE (2014)\n\n11. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Advances in neural information processing systems. pp. 1097‚Äì1105 (2012)\n\n12. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural computation 1(4), 541‚Äì551 (1989)\n\n13. LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11), 2278‚Äì2324 (1998)\n\n14. Nebauer, C.: Evaluation of convolutional neural networks for visual recognition. Neural Networks, IEEE Transactions on 9(4), 685‚Äì696 (1998)\n\n15. Simard, P.Y., Steinkraus, D., Platt, J.C.: Best practices for convolutional neural networks applied to visual document analysis. In: null. p. 958. IEEE (2003)\n\n16. Srivastava, N.: Improving neural networks with dropout. Ph.D. thesis, University of Toronto (2013)\n\n17. Szarvas, M., Yoshizawa, A., Yamamoto, M., Ogata, J.: Pedestrian detection with convolutional neural networks. In: Intelligent Vehicles Symposium, 2005. Proceedings. IEEE. pp. 224‚Äì229. IEEE (2005)\n\n18. Szegedy, C., Toshev, A., Erhan, D.: Deep neural networks for object detection. In: Advances in Neural Information Processing Systems. pp. 2553‚Äì2561 (2013)\n\n19. Tivive, F.H.C., Bouzerdoum, A.: A new class of convolutional neural networks (siconnets) and their application of face detection. In: Neural Networks, 2003. Proceedings of the International Joint Conference on. vol. 3, pp. 2157‚Äì2162. IEEE (2003)\n\n20. Zeiler, M.D., Fergus, R.: Stochastic pooling for regularization of deep convolutional neural networks. arXiv preprint arXiv:1301.3557 (2013)\n\n21. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks. In: Computer Vision‚ÄìECCV 2014, pp. 818‚Äì833. Springer (2014)', 'similarity': 0.8521066904067993}], 'cnn3': [{'text': 'We first report the configuration which achieved the highest accuracy, followed by the search through the space of hyperparameters (using only our validation data set) leading to the optimal configuration. We close by demonstrating the ability of FF trained CNNs to implement Class Activation Maps, which is a method from the explainable AI toolbox.', 'similarity': 0.9046024084091187}], 'cnn5': [{'text': '1. Cheng, Qisen and Qu, Shuhui and Lee, Janghwan. "72-3: Deep Learning Based Visual Defect Detection in Noisy and Imbalanced Data." SID Symposium Digest of Technical Papers, vol. 53, no. 1, pp. 971-974, 2022.\n\n2. Cheng, Qisen and Zhang, Chang and Shen, Xiang. "Estimation of Energy and Time Usage in 3D Printing With Multimodal Neural Network." 2022 4th International Conference on Frontiers Technology of Information and Computer (ICFTIC), pp. 900-903, 2022.\n\n3. Cifar10 Dataset. [online]. Avaiable:https://www.cs.toronto.edu/ kriz/cifar.html.\n\n4. Xing, Jinming. "Enhancing Link Prediction with Fuzzy Graph Attention Networks and Dynamic Negative Sampling." arXiv preprint arXiv:2411.07482 (2024).\n\n5. Veliƒçkoviƒá, Petar, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. "Graph attention networks." arXiv preprint arXiv:1710.10903 (2017).\n\n6. Hamilton, Will, Zhitao Ying, and Jure Leskovec. "Inductive representation learning on large graphs." Advances in neural information processing systems 30 (2017).\n\n7. Xing, Jinming, Can Gao, and Jie Zhou. "Weighted fuzzy rough sets-based tri-training and its application to medical diagnosis." Applied Soft Computing 124 (2022): 109025.\n\n8. Gao, Can, Jie Zhou, Jinming Xing, and Xiaodong Yue. "Parameterized maximum-entropy-based three-way approximate attribute reduction." International Journal of Approximate Reasoning 151 (2022): 85-100.\n\n9. Xing, Jinming, Ruilin Xing, and Yan Sun. "FGATT: A Robust Framework for Wireless Data Imputation Using Fuzzy Graph Attention Networks and Transformer Encoders." arXiv preprint arXiv:2412.01979 (2024).\n\n10. S. R. Livingstone and F. A. Russo, "The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)," PloS one, vol. 13, no. 5, p. e0196391, 2018. Available: https://zenodo.org/record/1188976\n\n11. Xing, Jinming, Dongwen Luo, Qisen Cheng, Chang Xue, and Ruilin Xing. "Multi-view Fuzzy Graph Attention Networks for Enhanced Graph Learning." arXiv preprint arXiv:2412.17271 (2024).\n\n12. G. Heigold, I. L. Moreno, S. Bengio, and N. Shazeer, "End-to-End Text-Dependent Speaker Verification," in Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2016, pp. 5115‚Äì5119.\n\n13. S. Hochreiter and J. Schmidhuber, "Long Short-Term Memory," Neural Computation, vol. 9, no. 8, pp. 1735‚Äì1780, 1997.\n\n14. F. A. Gers, J. Schmidhuber, and F. Cummins, "Learning to Forget: Continual Prediction with LSTM," Neural Computation, vol. 12, no. 10, pp. 2451‚Äì2471, 2000.\n\n15. Xing, Jinming, Ruilin Xing, and Yan Sun. "Comparative Analysis of Pooling Mechanisms in LLMs: A Sentiment Analysis Perspective." arXiv preprint arXiv:2411.14654 (2024).', 'similarity': 0.8521066904067993}], 'pdf2': [{'text': 'Table A.1: Test performance metrics for various RNA-related tasks.\n\n| Task       | Test F1-Score | Test AUC | Test Global Balanced Accuracy | Test MCC | Test Jaccard |\n|------------|---------------|----------|-------------------------------|----------|--------------|\n| RNA_Ligand | 0.2771        | 0.6751   | 0.4678                        |          |              |\n| RNA_CM     | 0.1957        | 0.7393   | 0.6615                        | 0.1695   |              |\n| RNA_Site   | 0.3346        | 0.5929   | 0.6309                        | 0.3098   |              |\n| RNA_Prot   | 0.4545        | 0.6654   | 0.6254                        | 0.2469   |              |\n| RNA_IF     | 0.3326        | 0.6201   | 0.3523*                       | 0.1319   |              |\n| RNA_VS     |               | 0.855    |                               |          |              |\n| RNA_GO     | 0.4074        | 0.8406   | 0.7067                        |          | 0.3167       |\n\nHyperparameters used:\n- RNA_Ligand: n_layers=4, hidden_dim=128, lr=0.00001, dropout=0.5\n- RNA_CM: n_layers=3, hidden_dim=128, lr=0.001, dropout=0.5\n- RNA_Site: n_layers=4, hidden_dim=256, lr=0.001, dropout=0.5\n- RNA_Prot: n_layers=4, hidden_dim=64, lr=0.01, dropout=0.2\n- RNA_IF: n_layers=3, hidden_dim=128, lr=0.0001, dropout=0.5\n- RNA_VS: n_layers=3, hidden_dim=64/32, lr=0.001, dropout=0.2\n- RNA_GO: n_layers=3, hidden_dim=64, lr=0.001, dropout=0.5\n\n\\* For RNA_IF, the reported value in "Global Balanced Accuracy" is sequence recovery.\n\nTable A.2: We compare a standard RGCN using the rnaglib\'s task module with various published results using the TR60/TE18 split. Note: Binding site definitions may vary slightly between models.\n\n| Methods                   | MCC   | AUC   |\n|---------------------------|-------|-------|\n| Rsite2 (Zeng & Cui, 2016) | 0.010 | 0.474 |\n| Rsite (Zeng et al., 2015) | 0.055 | 0.496 |\n| RBind (Wang et al., 2018) | 0.141 | 0.540 |\n| RNAsite_seq (Su et al., 2021) | 0.160 | 0.641 |\n| RNAsite_str (Su et al., 2021) | 0.185 | 0.695 |\n| RNAsite (Su et al., 2021) | 0.186 | 0.703 |\n| rnaglib RNA-Site          | 0.113 | 0.606 |\n\nTable A.3: Sequence recovery scores for RNA inverse folding models. We use a standard two layer RGCN part of rnaglib\'s task module on the dataset and split published by Joshi et al. (2024)\n\n| Method                         | Sequence Recovery |\n|--------------------------------|-------------------|\n| gRNAde (Joshi et al., 2024)    | 0.568             |\n| Rosetta (Leman et al., 2020b)  | 0.450             |\n| RDesign (Tan et al., 2023)     | 0.430             |\n| FARNA (Alam et al., 2017)      | 0.321             |\n| ViennaRNA (Lorenz et al., 2011)| 0.269             |\n| rnaglib RNA-IF                 | 0.410             |', 'similarity': 0.8574557304382324}], 'pdf4': [{'text': 'Balasubramanian, K., Fan, J. and Yang, Z. (2018). Tensor methods for additive index models under discordance and heterogeneity. arXiv preprint arXiv:1807.06693 .\n\nBauer, B. and Kohler, M. (2019). On deep learning as a remedy for the curse of dimensionality in nonparametric regression. The Annals of Statistics 47 2261‚Äì2285.\n\nBauer, F., Pereverzev, S. and Rosasco, L. (2007). On regularization algorithms in learning theory. Journal of complexity 23 52‚Äì72.\n\nBreymann, W. and L√ºthi, D. (2013). ghyp: A package on generalized hyperbolic distributions. Manual for R Package ghyp .\n\nCandes, E. J., Li, X., Ma, Y. and Wright, J. (2009). Robust principal component analysis? arXiv preprint arXiv: 0912.3599 .\n\nChangliang Zou, Y. K. and Zhang, W. (2022). Estimation of low rank high-dimensional multivariate linear models for multi-response data. Journal of the American Statistical Association 117 693‚Äì703.\n\nChen, K., Dong, H. and Chan, K.-S. (2012). Reduced rank regression via adaptive nuclear norm penalization. arXiv preprint arXiv:1201.0381 .\n\nChen, X., Zou, C. and Cook, R. D. (2010). Coordinate-independent sparse sufficient dimension reduction and variable selection. The Annals of Statistics 38 3696 ‚Äì 3723.\n\nDamian, A., Lee, J. and Soltanolkotabi, M. (2022). Neural networks can learn representations with gradient descent. In Conference on Learning Theory.\n\nFriedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American Statistical Association 76 817‚Äì823.\n\nHui Zou, T. H. and Tibshirani, R. (2006). Sparse principal component analysis. Journal of Computational and Graphical Statistics 15 265‚Äì286.\n\nHyv√§rinen, A. and Dayan, P. (2005). Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research 6 695‚Äì709.\n\nJanzamin, M., Sedghi, H. and Anandkumar, A. (2014). Score function features for discriminative learning: Matrix and tensor framework. arXiv preprint arXiv:1412.2863 .\n\nKobak, D., Bernaerts, Y., Weis, M. A., Scala, F., Tolias, A. S. and Berens, P. (2021). Sparse reduced-rank regression for exploratory visualisation of paired multivariate data. Journal of the Royal Statistical Society Series C: Applied Statistics 70 980‚Äì1000.\n\nLee, W. and Liu, Y. (2012). Simultaneous multiple response regression and inverse covariance matrix estimation via penalized gaussian maximum likelihood. Journal of Multivariate Analysis 111 241‚Äì255.\n\nLi, K.-C. (1991). Sliced inverse regression for dimension reduction. Journal of the American Statistical Association 86 316‚Äì327.\n\nLi, K.-C. (1992). On principal hessian directions for data visualization and dimension reduction: Another application of stein\'s lemma. Journal of the American Statistical Association 87 1025‚Äì1039.\n\nLi, K.-C. and Duan, N. (1989). Regression analysis under link violation. The Annals of Statistics 1009‚Äì1052.\n\nLi, Y. and Turner, R. E. (2017). Gradient estimators for implicit models. arXiv preprint arXiv:1705.07107 .\n\nLu, Z., Monteiro, R. D. and Yuan, M. (2012). Convex optimization methods for dimension reduction and coefficient estimation in multivariate linear regression. Mathematical Programming 131 163‚Äì194.\n\nMakhzani, A. and Frey, B. (2013). K-sparse autoencoders. arXiv preprint arXiv:1312.5663 .\n\nMeng, C., Song, Y., Li, W. and Ermon, S. (2021). Estimating high order gradients of the data distribution by denoising. Advances in Neural Information Processing Systems 34 25359‚Äì25369.\n\nMousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. and Erdogdu, M. A. (2022).\nNeural networks efficiently learn low-dimensional representations with sgd. arXiv preprint\narXiv:2209.14863 .\n\nMukherjee, A. and Zhu, J. (2011). Reduced rank ridge regression and its kernel extensions.\nStatistical analysis and data mining: the ASA data science journal 4 612‚Äì622.\n\nO\'Rourke, S., Vu, V. and Wang, K. (2018). Random perturbation of low rank matrices:\nImproving classical bounds. Linear Algebra and its Applications 540 26‚Äì59.\n\nPearson, K. (1901). Liii. on lines and planes of closest fit to systems of points in space. The\nLondon, Edinburgh, and Dublin philosophical magazine and journal of science 2 559‚Äì572.\n\nRifai, S., Vincent, P., Muller, X., Glorot, X. and Bengio, Y. (2011). Contractive auto-\nencoders: Explicit invariance during feature extraction. In Proceedings of the 28th international\nconference on international conference on machine learning.\n\nScala, F., Kobak, D., Bernabucci, M., Bernaerts, Y., Cadwell, C. R., Castro, J. R.,\nHartmanis, L., Jiang, X., Laturnus, S., Miranda, E. et al. (2021). Phenotypic variation\nof transcriptomic cell types in mouse motor cortex. Nature 598 144‚Äì150.\n\nShi, J., Sun, S. and Zhu, J. (2018). A spectral approach to gradient estimation for implicit\ndistributions. In International Conference on Machine Learning.\n\nSimon, N., Friedman, J. and Hastie, T. (2013). A blockwise descent algorithm for group-\npenalized multiresponse and multinomial regression. arXiv preprint arXiv:1311.6529 .\n\nSong, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data\ndistribution. Advances in neural information processing systems 32.\n\nSong, Y., Garg, S., Shi, J. and Ermon, S. (2020). Sliced score matching: A scalable approach\nto density and score estimation. In Uncertainty in Artificial Intelligence.\n\nStrathmann, H., Sejdinovic, D., Livingstone, S., Szabo, Z. and Gretton, A. (2015).\nGradient-free hamiltonian monte carlo with efficient kernel exponential families. Advances in\nNeural Information Processing Systems 28 955‚Äì963.\n\nTan, K. M., Wang, Z., Zhang, T., Liu, H. and Cook, R. D. (2018). A convex formulation for\nhigh-dimensional sparse sliced inverse regression. Biometrika 105 769‚Äì782.\n\nVershynin, R. (2018a). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVershynin, R. (2018b). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVincent, P. (2011). A connection between score matching and denoising autoencoders. Neural\ncomputation 23 1661‚Äì1674.\n\nVincent, P., Larochelle, H., Bengio, Y. and Manzagol, P.-A. (2008). Extracting and\ncomposing robust features with denoising autoencoders. In Proceedings of the 25th international\nconference on Machine learning.\n\nWANG, W., LIANG, Y. and XING, E. (2013). Block regularized lasso for multivariate multi-response linear regression. In Artificial intelligence and statistics.\n\nXU, X. (2020). On the perturbation of the moore‚Äìpenrose inverse of a matrix. Applied Mathematics and Computation 374 124920.\n\nYANG, Z., BALASUBRAMANIAN, K. and LIU, H. (2017a). High-dimensional non-Gaussian single index models via thresholded score function estimation. In Proceedings of the 34th International Conference on Machine Learning, vol. 70.\n\nYANG, Z., BALASUBRAMANIAN, K., WANG, Z. and LIU, H. (2017b). Learning non-gaussian multi-index model via second-order stein\'s method. Advances in Neural Information Processing Systems 30 6097‚Äì6106.\n\nYU, Y., WANG, T. and SAMWORTH, R. J. (2015). A useful variant of the davis‚Äìkahan theorem for statisticians. Biometrika 102 315‚Äì323.\n\nYUAN, M., EKICI, A., LU, Z. and MONTEIRO, R. (2007). Dimension reduction and coefficient estimation in multivariate linear regression. Journal of the Royal Statistical Society Series B: Statistical Methodology 69 329‚Äì346.\n\nZHOU, Y., SHI, J. and ZHU, J. (2020). Nonparametric score estimators. In International Conference on Machine Learning.\n\n17\n\nSupplementary Material for\n"Nonlinear Multiple Response Regression and Learning of Latent Spaces"\n\nYe Tian, Sanyou Wu and Long Feng', 'similarity': 0.8521066904067993}], 'cnn2': [{'text': '[1] Joakim And√©n and St√©phane Mallat. Deep scattering spectrum. Signal Processing, IEEE Transactions on, 62(16):4114‚Äì4128, 2014.\n\n[2] Joan Bruna and St√©phane Mallat. Invariant scattering convolution networks. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 35(8):1872‚Äì1886, 2013.\n\n[3] Corinna Cortes and Vladimir Vapnik. Support-vector networks. Machine learning, 20(3): 273‚Äì297, 1995.\n\n[4] Joan Bruna Estrach. Scattering representations for recognition.\n\n[5] Kaiser Gerald. A friendly guide to wavelets, 1994.\n\n[6] B Boser Le Cun, John S Denker, D Henderson, Richard E Howard, W Hubbard, and Lawrence D Jackel. Handwritten digit recognition with a back-propagation network. In Advances in neural information processing systems. Citeseer, 1990.\n\n[7] Yann LeCun, L√©on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278‚Äì2324, 1998.\n\n[8] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436‚Äì444, 2015.\n\n[9] St√©phane Mallat. Group invariant scattering. Communications on Pure and Applied Mathematics, 65(10):1331‚Äì1398, 2012.\n\n[10] St√©phane Mallat. Understanding deep convolutional networks. arXiv preprint arXiv:1601.04920, 2016.', 'similarity': 0.8521066904067993}], 'cnn4': [{'text': 'The results of our trials can be found in Figure 3 and a comparison of our model with other models on CIFAR-10 image classification can be found in Figure 4.\n\nFigure 3: Table displaying the number of parameters required to achieve different validation accuracies on CIFAR-10 over 5 different trials with the same hyperparameters.\n\n| Metric | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n|--------|---------|---------|---------|---------|---------|------|\n| Val Accuracy (at 70%) | 13696 | 11360 | 11360 | 11360 | 9024 | 11360.0 |\n| Val Accuracy (at 80%) | 27852 | 51880 | 22636 | 37320 | 28588 | 33655.2 |\n| Highest Val Accuracy (%) | 83.4 | 84.6 | 84.6 | 84.5 | 83.2 | 84.1 |\n| Parameters at Highest Accuracy | 74564 | 73720 | 57808 | 66440 | 40960 | 62698.4 |', 'similarity': 0.9121243953704834}], 'pdf1': [{'text': '[1] J. Nicholson and A. Healey, "The present state of autonomous underwater vehicle (AUV) applications and technologies," Marine Technology Society Journal, vol. 42, no. 1, pp. 44‚Äì51, 2008.\n\n[2] G. Griffiths, Technology and applications of autonomous underwater vehicles, vol. 2. CRC Press, 2002.\n\n[3] P. A. Miller, J. A. Farrell, Y. Zhao, and V. Djapic, "Autonomous underwater vehicle navigation," IEEE Journal of Oceanic Engineering, vol. 35, no. 3, pp. 663‚Äì678, 2010.\n\n[4] D. Rudolph and T. A. Wilson, "Doppler Velocity Log theory and preliminary considerations for design and construction," in 2012 Proceedings of IEEE Southeastcon, pp. 1‚Äì7, IEEE, 2012.\n\n[5] N. Cohen and I. Klein, "Inertial navigation meets deep learning: A survey of current trends and future directions," Results in Engineering, p. 103565, 2024.\n\n[6] F. Zhang, S. Zhao, L. Li, and C. Cao, "Underwater DVL Optimization Network (UDON): A Learning-Based DVL Velocity Optimizing Method for Underwater Navigation," Drones, vol. 9, no. 1, p. 56, 2025.\n\n[7] Liu, Peijia and Wang, Bo and Li, Guanghua and Hou, Dongdong and Zhu, Zhengyu and Wang, Zhongyong, "Sins/dvl integrated navigation method with current compensation using rbf neural network," IEEE Sensors Journal, vol. 22, no. 14, pp. 14366‚Äì14377, 2022.\n\n[8] E. Topini, F. Fanelli, A. Topini, M. Pebody, A. Ridolfi, A. B. Phillips, and B. Allotta, "An experimental comparison of Deep Learning strategies for AUV navigation in DVL-denied environments," Ocean Engineering, vol. 274, p. 114034, 2023.\n\n[9] R. Makam, M. Pramuk, S. Thomas, and S. Sundaram, "Spectrally Normalized Memory Neuron Network Based Navigation for Autonomous Underwater Vehicles in DVL-Denied Environment," in OCEANS 2024-Singapore, pp. 1‚Äì6, IEEE, 2024.\n\n[10] Z. Yampolsky and I. Klein, "DCNet: A data-driven framework for DVL calibration," Applied Ocean Research, vol. 158, p. 104525, 2025.\n\n[11] M. Yona and I. Klein, "MissBeamNet: Learning missing Doppler velocity log beam measurements," Neural Computing and Applications, vol. 36, no. 9, pp. 4947‚Äì4958, 2024.\n\n[12] N. Cohen, Z. Yampolsky, and I. Klein, "Set-transformer BeamsNet for AUV velocity forecasting in complete DVL outage scenarios," in 2023 IEEE Underwater Technology (UT), pp. 1‚Äì6, IEEE, 2023.\n\n[13] N. Cohen and I. Klein, "BeamsNet: A data-driven approach enhancing Doppler velocity log measurements for autonomous underwater vehicle navigation," Engineering Applications of Artificial Intelligence, vol. 114, p. 105216, 2022.\n\n[14] N. Cohen and I. Klein, "Adaptive Kalman-Informed Transformer," Engineering Applications of Artificial Intelligence, vol. 146, p. 110221, 2025.\n\n[15] A. Levy and I. Klein, "Adaptive Neural Unscented Kalman Filter," arXiv preprint arXiv:2503.05490, 2025.\n\n[16] Y. Stolero and I. Klein, "AUV Acceleration Prediction Using DVL and Deep Learning ," arXiv preprint arXiv: 2503.16573, 2025.\n\n[17] D. Simon, Optimal state estimation: Kalman, H infinity, and nonlinear approaches. John Wiley & Sons, 2006.\n\n[18] Y. Bar-Shalom, X. R. Li, and T. Kirubarajan, Estimation with applications to tracking and navigation: theory algorithms and software. John Wiley & Sons, 2004.\n\n[19] P. Groves, Principles of GNSS, Inertial, and Multisensor Integrated Navigation Systems, Second Edition. GNSS/GPS, Artech House, 2013.\n\n[20] J. Farrell, Aided navigation: GPS with high rate sensors. McGraw-Hill, Inc., 2008.', 'similarity': 0.8521066904067993}], 'pdf3': [{'text': '', 'similarity': 0.8973236083984375}]}}, 'content_results': {'cnn3': [{'text': 'The recent successes in analyzing images with deep neural networks are almost exclusively achieved with Convolutional Neural Networks (CNNs). The training of these CNNs, and in fact of all deep neural network architectures, uses the backpropagation algorithm, where the output of the network is compared with the desired result, and the difference is then used to tune the weights of the network towards the desired outcome. In a 2022 preprint, Geoffrey Hinton suggested an alternative way of training which passes the desired results together with the images at the input of the network. This so called Forward-Forward (FF) algorithm has up to now only been used in fully connected networks. In this paper, we show how the FF paradigm can be extended to CNNs. Our FF-trained CNN, featuring a novel spatially-extended labeling technique, achieves a classification accuracy of 99.16% on the MNIST hand-written digits data set. We show how different hyperparameters affect the performance of the proposed algorithm and compare the results with CNNs trained with the standard backpropagation approach. Furthermore, we demonstrate that Class Activation Maps can be used to investigate which type of features are learnt by the FF algorithm.\n\n**Keywords:** forward-forward, backpropagation, convolutional neural networks, class activation maps, MNIST classification.\n\n1. * corresponding authors\n2. ‚Ä† equal contribution\n\n¬©20xx Scodellaro, Kulkarni, Alves and Schr√∂ter.\n\nLicense: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. Attribution requirements are provided at http://jmlr.org/papers/vxx/21-0000.html.\n\nSCODELLARO, KULKARNI, ALVES AND SCHR√ñTER\n\n\nMachine learning using deep neural networks (DNN) continues to transform human life in areas as different as art (DALL-E, stable diffusion), medicine (Alpha-Fold), transport (self-driving cars, any time now), or information retrieval (ChatGPT, Bard). Here, the adjective deep refers to the number of layers of artificial neurons, which can go up to the hundreds. Training these networks means shifting the weights connecting the layers from their initial, random values to values which produce the correct predictions at the output layer of the DNN. This is achieved with the help of a loss function that computes the aggregate difference between the predicted output and the accurate results, which must be known for the training examples. The algorithm behind the training is some variant of gradient descent: in each round of training each weight is shifted a bit into the direction minimizing the loss by using the derivative of the loss function with respect to that weight. Taking the derivative of a loss function with respect to a given weight is straightforward for a single, output layer. Training the weights of the earlier layers in DNNs requires the gradient computation to be performed iteratively by applying the chain rule (Rumelhart et al., 1986). This process is called backpropagation (BP). Due to its importance, the term BP is also often used loosely to refer to the entire learning algorithm including the gradient descent.\n\nBackpropagation, respectively multi-layer gradient descent, has a number of downsides: first, it requires the storage of intermediate results. Depending on the optimizer, the memory consumption of BP is up to 5 times larger than the requirement for storing the weights alone (Hugging Face Community, 2023). This becomes a problem when training large models on GPU cards with limited memory. Second, under the name neuromorphic computing, there is an ongoing search of hardware alternatives to CMOS semiconductors, driven by the desire to decrease power consumption and increase processing speed (Christensen et al., 2022). On these new hardware platforms, it is often impossible to implement an analog of BP, raising the need for alternative training algorithm. Finally, evolution has clearly developed learning algorithms for neural networks such as our brain. However, those algorithms seem to be quite (but maybe not completely, see e.g. Lillicrap et al., 2020) different from BP. Given the in general high performance of evolutionary solutions to problems, this raises the question if deep learning could also gain from biologically plausible alternatives to BP.\n\nDue to these limitations, there is an ongoing search for alternative training methods. The most radical approach is to abandon the loss function completely and use a new learning paradigm. Neural networks trained with variants of the locally acting Hebbian learning rule (neurons that fire together wire together) have been shown to be competitive with BP (Journ√© et al., 2023; Zhou, 2022). Another approach, Equilibrium Propagation (Scellier and Bengio, 2017) is a learning framework for energy based models with symmetric connections between neurons. Layer-wise Feedback Propagation (Weber et al., 2023) removes the need for a gradient computation by replacing the objective of reducing the loss with computing a reward signal from the network output, and propagating that signal backward into the net. In contrast, the most conservative approach is to keep gradient descent, but to replace the required gradients with an estimate computed from the difference in loss of two forward passes with slightly modified weights. While the naive version of this approach, labeled zeroth order optimization, can be expected to be extremely inefficient, modern variants\n\nseem to be competitive (Baydin et al., 2022; McCaughan et al., 2023; Malladi et al., 2023; ?).\n\nA third category of algorithms maintains the idea to update the weights using derivatives of some signal, which involves the difference between the present state of the network and the target state. But it relaxes the requirement to backpropagate that signal from the output layer towards the earlier layers. This can either be done by using exclusively an output-derived error signal for training each intermediate layer (N√∏kland, 2016; Fl√ºgel et al., 2023), or by training each layer with locally available information gathered in two consecutive forward passes. An example of the latter is the "Present the Error to Perturb the Input To modulate Activity technique" (PEPITA), which performs the second forward pass with the sum of the input signal used in the first pass and some random projection of the error signal from that pass (Dellaferrera and Kreiman, 2022; Farinha et al., 2023).\n\nAnother example of the use of local information gathered in consecutive runs to update the weights is the Forward-Forward (FF) algorithm (Hinton (2022)) proposed by Geoffrey Hinton in December 2022. FF training combines two ideas. First, the weights of a given layer are updated using gradients of a locally defined goodness function, which in Hinton (2022) is taken to be the sum of the squares of the activities in that layer. Second, the labels are included in the training data, which allows the neurons to learn them together. In order to understand which features of the data vote for a given label, half of the data set is comprised of labels combined with wrong images. For this negative data the weights are changed in order to minimize the goodness. In contrast, for the correctly labeled, positive data the weights are modified to maximize the goodness. Both these objectives can be achieved with a local gradient descent, with no need for BP. The term Forward-Forward now refers to having two subsequent training steps, one with positive and one with negative data.\n\nWhen generalizing this training method to multi-layer networks, it is important to assure that each subsequent layer needs to do more than just measure the length of the activity vector of the previous one. This is achieved by using layer normalization (Ba et al., 2016) which normalizes the activity vector for each sample. This is best summarized by the description in Hinton (2022): the activity vector in the first hidden layer has a length and an orientation. The length is used to define the goodness for that layer and only the orientation is passed to the next layer. There are two ways of using a FF trained network for inference. First, we can simultaneously train a linear classifier using the activities of the neurons in the different layers as input. Alternatively, we can create multiple copies of the data set under consideration and combine each copy with one of the possible labels. The correct label is then the one with the largest goodness during its forward pass. Note that this approach multiplies the amount of computation required for inference with a factor equal to the number of labels.\n\nGiven the repute of the proposer, it is not surprising that the Forward-Forward algorithm has inspired a number of groups to suggest modified and adapted versions. Examples include the combination with a generative model (Ororbia and Mali, 2023), multiple convolutional blocks (not trained with FF) (?), or extending FF training to graph neural networks (Paliotta et al., 2023) and spiking neural networks (Ororbia, 2023). In accordance with the neuromorphic computation motivation of moving beyond BP, the FF algorithm has also been used to train optical neural networks (Oguz et al., 2023) and microcontroller units\n\nSCODELLARO, KULKARNI, ALVES AND SCHR√ñTER\n\nwith low computational resources (De Vita et al., 2023). Another line of research tries to improve FF by modifying how the goodness is computed (Lee and Song, 2023; Lorberbom et al., 2023; Gandhi et al., 2023), by understanding the sparsity of activation in FF trained networks (Tosato et al., 2023; Yang, 2023), or by exploring the capabilities of FF for self-supervised learning (Brenig and Timofte, 2023). There has been less activity in terms of practical applications of the FF algorithm. Particularly, in the classification of real world images it has been noted that FF performs worse than BP (Reyes-Angulo and Paheding, 2023) or has to be combined with BP to achieve satisfying results (Paheding and Reyes-Angulo, 2023). We propose that this lack of applications is due to the absence of a method to train the mainstay of modern image processing, Convolutional Neural Networks (CNN) (Rawat and Wang, 2017), with the FF algorithm. The ideas presented here close this gap.\n\nThis paper is structured as following: in Section 2 we will first introduce our spatial-extended labeling technique, which is crucial to preserve the label information during convolution. Then we will discuss the details of our implementation of the FF-based learning and inference. The results in Section 3 start with a discussion of the optimal results we obtained on the MNIST hand written digits classification. In Section 3.2, we describe our search for the optimal hyperparameters (using validation data). Section 3.3 shows how Class Activation Maps (CAMs) can be used to get a better understanding of the features learned during training. We close in Section 4 with a short discussion.', 'image': 'No image available', 'collection_name': 'cnn3', 'similarity': 0.8190605044364929}], 'cnn5': [{'text': '1. Cheng, Qisen and Qu, Shuhui and Lee, Janghwan. "72-3: Deep Learning Based Visual Defect Detection in Noisy and Imbalanced Data." SID Symposium Digest of Technical Papers, vol. 53, no. 1, pp. 971-974, 2022.\n\n2. Cheng, Qisen and Zhang, Chang and Shen, Xiang. "Estimation of Energy and Time Usage in 3D Printing With Multimodal Neural Network." 2022 4th International Conference on Frontiers Technology of Information and Computer (ICFTIC), pp. 900-903, 2022.\n\n3. Cifar10 Dataset. [online]. Avaiable:https://www.cs.toronto.edu/ kriz/cifar.html.\n\n4. Xing, Jinming. "Enhancing Link Prediction with Fuzzy Graph Attention Networks and Dynamic Negative Sampling." arXiv preprint arXiv:2411.07482 (2024).\n\n5. Veliƒçkoviƒá, Petar, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. "Graph attention networks." arXiv preprint arXiv:1710.10903 (2017).\n\n6. Hamilton, Will, Zhitao Ying, and Jure Leskovec. "Inductive representation learning on large graphs." Advances in neural information processing systems 30 (2017).\n\n7. Xing, Jinming, Can Gao, and Jie Zhou. "Weighted fuzzy rough sets-based tri-training and its application to medical diagnosis." Applied Soft Computing 124 (2022): 109025.\n\n8. Gao, Can, Jie Zhou, Jinming Xing, and Xiaodong Yue. "Parameterized maximum-entropy-based three-way approximate attribute reduction." International Journal of Approximate Reasoning 151 (2022): 85-100.\n\n9. Xing, Jinming, Ruilin Xing, and Yan Sun. "FGATT: A Robust Framework for Wireless Data Imputation Using Fuzzy Graph Attention Networks and Transformer Encoders." arXiv preprint arXiv:2412.01979 (2024).\n\n10. S. R. Livingstone and F. A. Russo, "The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)," PloS one, vol. 13, no. 5, p. e0196391, 2018. Available: https://zenodo.org/record/1188976\n\n11. Xing, Jinming, Dongwen Luo, Qisen Cheng, Chang Xue, and Ruilin Xing. "Multi-view Fuzzy Graph Attention Networks for Enhanced Graph Learning." arXiv preprint arXiv:2412.17271 (2024).\n\n12. G. Heigold, I. L. Moreno, S. Bengio, and N. Shazeer, "End-to-End Text-Dependent Speaker Verification," in Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2016, pp. 5115‚Äì5119.\n\n13. S. Hochreiter and J. Schmidhuber, "Long Short-Term Memory," Neural Computation, vol. 9, no. 8, pp. 1735‚Äì1780, 1997.\n\n14. F. A. Gers, J. Schmidhuber, and F. Cummins, "Learning to Forget: Continual Prediction with LSTM," Neural Computation, vol. 12, no. 10, pp. 2451‚Äì2471, 2000.\n\n15. Xing, Jinming, Ruilin Xing, and Yan Sun. "Comparative Analysis of Pooling Mechanisms in LLMs: A Sentiment Analysis Perspective." arXiv preprint arXiv:2411.14654 (2024).', 'image': 'No image available', 'collection_name': 'cnn5', 'similarity': 0.7976483106613159}], 'pdf2': [{'text': 'Recent years have witnessed the advent of deep learning methods for structural biology culminating in the award of the Nobel Prize in Chemistry. AlphaFold (Jumper et al., 2021) revolutionized protein structure prediction, equipping the field with millions of new structures. Breakthroughs go beyond structure prediction, notably in protein design (Watson et al., 2023; Dauparas et al., 2022), drug discovery (Schneuing et al., 2024; Corso et al., 2022) or fundamental biology (van Kempen et al., 2022). While it is tempting to attribute the success of these methods to the increase in available structural data caused by AlphaFold, most of the methods are actually not reliant on them. Instead, it seems that these breakthroughs result from progress in training neural encoders that directly model protein structures (Jing et al., 2020; Zhang et al., 2022b; Gainza et al., 2020; Wang et al., 2022). This progress is in turn rooted in solid competitions (CASP, CAPRI), and benchmarks (Townshend et al., 2021a; Kucera et al., 2023; Zhu et al., 2022; Jamasb et al., 2024; Notin et al., 2023). By setting clear goals, such benchmarks are the foundation for the development of structure encoders. Yet to date, structure-function benchmarks have focused on proteins.\n\nRibonucleic acids (RNAs) are a large family of molecules which support biological functions along every branch of the tree of life. Besides messenger RNAs, non-coding RNAs carry out biological functions by adopting complex 3D folds (Cech & Steitz, 2014) like proteins do and take up diverse roles in cellular functions, including gene regulation, RNA processing, and protein synthesis (Statello et al., 2021). However, our understanding of non-coding RNAs and their functions remains limited. This can be largely attributed to the negatively charged nature of RNA backbones, which makes it flexible and limits the availability of high-resolution RNA structures, and imposes significant modeling challenges. Another predominant challenge to a functional understanding of RNA 3D structure lies in the lack of infrastructure for the development and evaluation of function prediction models. In this work, we propose a benchmarking suite to act as this facilitating framework.\n\nOur key contributions include:\n\n- Seven tasks related to RNA 3D structure that represent various biological challenges. Each task consists of a dataset, a splitting strategy, and an evaluation method, laying the ground for comparable, reproducible model development.\n\n- End-to-end reproducible and modular access to task data. Modular annotators, filters and splitting strategies, both novel and from existing literature, facilitate the addition of new tasks by other researchers across fields.\n\n*Equal contribution ‚Ä†Equal supervision 1Max Planck Institute of Biochemistry, Munich, Germany 2Mines Paris, PSL Research University, CBIO, Paris, France 3Vanderbilt University, Nashville, Tennessee, USA. Correspondence to: Luis Wyss <wyss@biochem.mpg.de>.\n\nA preprint.\n\nBenchmark for RNA 3D Structure Modeling', 'image': 'No image available', 'collection_name': 'pdf2', 'similarity': 0.8002073764801025}], 'pdf4': [{'text': 'For the neural network, we let $F_\\theta(\\cdot) = O^\\top\\phi\\{A^\\top\\phi(\\cdot)\\}$, where $A \\in \\mathbb{R}^{r\\times h}$, $O \\in \\mathbb{R}^{h\\times q}$, $\\phi(\\cdot)$ is the point-wise ReLU function and we let $h = 32$. We implement neural networks in Pytorch. For neural network estimator of B discussed in Section I.4, we minimize the loss function\n\n$$\\ell(\\theta, B) = \\frac{1}{n} \\sum_{i=1}^n \\|y_i - F_\\theta(B^\\top x_i)\\|_2^2,$$\n\nWe use the batch-training strategy to train the neural networks. We use Adam optimizer with Pytorch default parameters. We choose the batch size to be 0.5% of the sample size and train the neural networks for 200 epochs.', 'image': 'No image available', 'collection_name': 'pdf4', 'similarity': 0.8126975297927856}], 'cnn1': [{'text': 'Artificial Neural Networks (ANNs) are computational processing systems of which are heavily inspired by way biological nervous systems (such as the human brain) operate. ANNs are mainly comprised of a high number of interconnected computational nodes (referred to as neurons), of which work entwine in a distributed fashion to collectively learn from the input in order to optimise its final output.\n\nThe basic structure of a ANN can be modelled as shown in Figure 1. We would load the input, usually in the form of a multidimensional vector to the input layer of which will distribute it to the hidden layers. The hidden layers will then make decisions from the previous layer and weigh up how a stochastic change within itself detriments or improves the final output, and this is referred to as the process of learning. Having multiple hidden layers stacked upon each-other is commonly called deep learning.\n\n2      Keiron O‚ÄôShea et al.\n\nInput Layer    Hidden Layer   Output Layer\n\nInput 1\n\nInput 2\nOutput\n\nInput 3\n\nInput 4\n\nFig. 1: A simple three layered feedforward neural network (FNN), comprised\nof a input layer, a hidden layer and an output layer. This structure is the basis\nof a number of common ANN architectures, included but not limited to Feed-\nforward Neural Networks (FNN), Restricted Boltzmann Machines (RBMs) and\nRecurrent Neural Networks (RNNs).\n\nThe two key learning paradigms in image processing tasks are supervised and\nunsupervised learning. Supervised learning is learning through pre-labelled\ninputs, which act as targets. For each training example there will be a set of\ninput values (vectors) and one or more associated designated output values.\nThe goal of this form of training is to reduce the models overall classification\nerror, through correct calculation of the output value of training example by\ntraining.\n\nUnsupervised learning differs in that the training set does not include any la-\nbels. Success is usually determined by whether the network is able to reduce or\nincrease an associated cost function. However, it is important to note that most\nimage-focused pattern-recognition tasks usually depend on classification using\nsupervised learning.\n\nConvolutional Neural Networks (CNNs) are analogous to traditional ANNs\nin that they are comprised of neurons that self-optimise through learning. Each\nneuron will still receive an input and perform a operation (such as a scalar\nproduct followed by a non-linear function) - the basis of countless ANNs. From\nthe input raw image vectors to the final output of the class score, the entire of\nthe network will still express a single perceptive score function (the weight).\nThe last layer will contain loss functions associated with the classes, and all of\nthe regular tips and tricks developed for traditional ANNs still apply.\n\nThe only notable difference between CNNs and traditional ANNs is that CNNs\nare primarily used in the field of pattern recognition within images. This allows\nus to encode image-specific features into the architecture, making the network\n\nIntroduction to Convolutional Neural Networks    3\n\nmore suited for image-focused tasks - whilst further reducing the parameters required to set up the model.\n\nOne of the largest limitations of traditional forms of ANN is that they tend to struggle with the computational complexity required to compute image data. Common machine learning benchmarking datasets such as the MNIST database of handwritten digits are suitable for most forms of ANN, due to its relatively small image dimensionality of just 28 √ó 28. With this dataset a single neuron in the first hidden layer will contain 784 weights (28 √ó 28 √ó 1 where 1 bare in mind that MNIST is normalised to just black and white values), which is manageable for most forms of ANN.\n\nIf you consider a more substantial coloured image input of 64 √ó 64, the number of weights on just a single neuron of the first layer increases substantially to 12,288. Also take into account that to deal with this scale of input, the network will also need to be a lot larger than one used to classify colour-normalised MNIST digits, then you will understand the drawbacks of using such models.', 'image': 'No image available', 'collection_name': 'cnn1', 'similarity': 0.8257489204406738}], 'cnn4': [{'text': 'machine learning, self expanding neural networks, computational efficiency, convolutional neural networks.', 'image': 'No image available', 'collection_name': 'cnn4', 'similarity': 0.8661696314811707}], 'pdf1': [{'text': '[1] J. Nicholson and A. Healey, "The present state of autonomous underwater vehicle (AUV) applications and technologies," Marine Technology Society Journal, vol. 42, no. 1, pp. 44‚Äì51, 2008.\n\n[2] G. Griffiths, Technology and applications of autonomous underwater vehicles, vol. 2. CRC Press, 2002.\n\n[3] P. A. Miller, J. A. Farrell, Y. Zhao, and V. Djapic, "Autonomous underwater vehicle navigation," IEEE Journal of Oceanic Engineering, vol. 35, no. 3, pp. 663‚Äì678, 2010.\n\n[4] D. Rudolph and T. A. Wilson, "Doppler Velocity Log theory and preliminary considerations for design and construction," in 2012 Proceedings of IEEE Southeastcon, pp. 1‚Äì7, IEEE, 2012.\n\n[5] N. Cohen and I. Klein, "Inertial navigation meets deep learning: A survey of current trends and future directions," Results in Engineering, p. 103565, 2024.\n\n[6] F. Zhang, S. Zhao, L. Li, and C. Cao, "Underwater DVL Optimization Network (UDON): A Learning-Based DVL Velocity Optimizing Method for Underwater Navigation," Drones, vol. 9, no. 1, p. 56, 2025.\n\n[7] Liu, Peijia and Wang, Bo and Li, Guanghua and Hou, Dongdong and Zhu, Zhengyu and Wang, Zhongyong, "Sins/dvl integrated navigation method with current compensation using rbf neural network," IEEE Sensors Journal, vol. 22, no. 14, pp. 14366‚Äì14377, 2022.\n\n[8] E. Topini, F. Fanelli, A. Topini, M. Pebody, A. Ridolfi, A. B. Phillips, and B. Allotta, "An experimental comparison of Deep Learning strategies for AUV navigation in DVL-denied environments," Ocean Engineering, vol. 274, p. 114034, 2023.\n\n[9] R. Makam, M. Pramuk, S. Thomas, and S. Sundaram, "Spectrally Normalized Memory Neuron Network Based Navigation for Autonomous Underwater Vehicles in DVL-Denied Environment," in OCEANS 2024-Singapore, pp. 1‚Äì6, IEEE, 2024.\n\n[10] Z. Yampolsky and I. Klein, "DCNet: A data-driven framework for DVL calibration," Applied Ocean Research, vol. 158, p. 104525, 2025.\n\n[11] M. Yona and I. Klein, "MissBeamNet: Learning missing Doppler velocity log beam measurements," Neural Computing and Applications, vol. 36, no. 9, pp. 4947‚Äì4958, 2024.\n\n[12] N. Cohen, Z. Yampolsky, and I. Klein, "Set-transformer BeamsNet for AUV velocity forecasting in complete DVL outage scenarios," in 2023 IEEE Underwater Technology (UT), pp. 1‚Äì6, IEEE, 2023.\n\n[13] N. Cohen and I. Klein, "BeamsNet: A data-driven approach enhancing Doppler velocity log measurements for autonomous underwater vehicle navigation," Engineering Applications of Artificial Intelligence, vol. 114, p. 105216, 2022.\n\n[14] N. Cohen and I. Klein, "Adaptive Kalman-Informed Transformer," Engineering Applications of Artificial Intelligence, vol. 146, p. 110221, 2025.\n\n[15] A. Levy and I. Klein, "Adaptive Neural Unscented Kalman Filter," arXiv preprint arXiv:2503.05490, 2025.\n\n[16] Y. Stolero and I. Klein, "AUV Acceleration Prediction Using DVL and Deep Learning ," arXiv preprint arXiv: 2503.16573, 2025.\n\n[17] D. Simon, Optimal state estimation: Kalman, H infinity, and nonlinear approaches. John Wiley & Sons, 2006.\n\n[18] Y. Bar-Shalom, X. R. Li, and T. Kirubarajan, Estimation with applications to tracking and navigation: theory algorithms and software. John Wiley & Sons, 2004.\n\n[19] P. Groves, Principles of GNSS, Inertial, and Multisensor Integrated Navigation Systems, Second Edition. GNSS/GPS, Artech House, 2013.\n\n[20] J. Farrell, Aided navigation: GPS with high rate sensors. McGraw-Hill, Inc., 2008.', 'image': 'No image available', 'collection_name': 'pdf1', 'similarity': 0.8088333606719971}], 'pdf3': [{'text': 'Bury, T. M., Dylewsky, D., Bauch, C. T., Anand, M., Glass, L., Shrier, A., and Bub, G., "Prediction Discrete-Time Bifurcations with Deep Learning," Nature Communications, Vol 14, Article No. 6331, 2023.', 'image': 'No image available', 'collection_name': 'pdf3', 'similarity': 0.8121218085289001}], 'cnn2': [{'text': ' Figure 1: Architecture of a Convolutional Neural Network (from LeCun et al. [7]) ', 'image': 'C:\\Users\\Aditya\\OneDrive\\Desktop\\NvidiaTraining\\Training_Material_(2024-25)\\5th_March_2025\\output\\cnn2\\image94-page3.png', 'collection_name': 'cnn2', 'similarity': 0.8271554112434387}]}}